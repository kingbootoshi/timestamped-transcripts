# Full Transcript

**SPEAKER_02:** Raise your hand if you've ever sent a text message in your life. So you're a texture, you guys send messages, you know how to write words on an iPhone. If you do, if you guys raise your hands, I'd like to say congratulations. Thanks to AI in 2025, you are all now entry-level software engineers. To any existing software engineers in the audience, I am sorry in advance for my presentation. A lot of people know AI is super important, but not a lot of people know how to really utilize AI to make yourself hyper efficient. I guess usually in keynotes, people have proof on why they're experts in their subject. So my proof is just trust me, bro. In terms of getting an AI, about two years ago, I dropped out of college my first week. because I was not doing an online class during COVID. I didn't really have any life skills. The only life skill I had was being a very good JPEG trader on Ethereum. And that got me pretty far in terms of that. But what it really did is without a college education, but having a little bit of financial freedom, I was able to really pursue something that deeply interested me. And that was AI when it came out. So I say ChadGBT 3.5 Turbo came out around the same time Ordinals came out. And when Ordinals came out, I ended up inscribing a collection and becoming one of the earliest founders of a sub 10k collection. And honestly, Ordinals and the whole Bitcoin ecosystem ended up making my life. And one of the things I really wanted to do is how do I actually make my project something that's cool, provides value to people and isn't something on an all chain. So I discovered Tachypteen and I was like, oh, I could actually use this. Have any of you guys seen Westworld? Okay, you guys have all seen Westworld. So six months before Ordinalist came out, I binged Westworld. I'm like, oh my God, bro, this tech is real. I'm full sending this tech whenever it comes out. It'll be, what, 10, 20 years? Yeah, I came out six months later and I was like, oh my God, Westworld is real. I could make robots real. For the last two years, I had one successful Bitcoin Ordinance project and then surprised myself by also having a Rune project that ended up pumping some 50 mil market cap, which I didn't know was possible on Rune. So it was a really, it was a really interesting experiment. Beyond that, I had no life skills about two years ago, but Talking with AI and finally realizing that I have something that could be my mentor on a 24-7 basis. I'm very spontaneous when it comes to things. I have hyper interests and hyper focuses. Unfortunately, when it comes to consulting or asking a mentor to help me in different fields of subjects. that it costs money and someone else's time. But because Chad GVC and the new AIs that come out have a lot of knowledge within them, then I don't have to bother anybody. I don't have to pay anybody. I could just ask infinite questions. And I'm a very curious person. So I would just ask questions and ask questions. And if the answer provided me, talked about a concept or had a word I didn't know about, I asked more questions. So it's not only this rabbit hole of just asking me infinite questions really allowed me to end up learning software engineering, fully self-taught in the last two years. I ended up learning a lot about psychology and marketing because I had to know marketing to sell out my project. I had to learn psychology to understand what people like. And connecting all of these things with AI as my mentor made it really easy to go forward. And I also ended up just Since it's so new, I started documenting my entire journey and I actually had a lot of people hit me up and be like, oh, you've helped me a lot. I didn't know I could build stuff. I'm building stuff on Bitcoin now. I'm building products I didn't know was possible. I'm irreplaceable in my work now. I've gotten people raises because they watch my videos and they're like, oh, I didn't know AI could do that. So I think it's safe to say now I've helped a couple thousand people make themselves a lot more efficient with AI, which is cool because one of my main goals is I want a superhuman society and AI to me is a superpower. So if we teach other people how to use the superpower, then I get my superhuman society. And I really want to explore space. I don't know about you guys. I see that being possible in the next five or 10 years. Anyway, so that's my source. This is Cypher Genesis. This was the Bitcoin meme coin that I dropped. And in the crypto space, when it comes to how do you actually, what do people care about in this space? What do people actually give a fuck about? And a lot of the times you would hope it's cool tech, but ends up not being cool tech, because a lot of times developers will make something cool, but they don't know how to present it to a crowd. And then no entity in the space really cares about the product or the tech or whatever. All they really care about is this cool. And the main formula I've learned in the crypto space when it came to trading, Attention is everything. The more attention a project has, the more capital flows into it. The cooler a narrative or a meme coin or a meme has, the easier it is for people to spin up these narratives or stories and spread that attention. So when this whole AI meta started, my thought process was, okay, AI agents are blowing up on other chains. We don't have it for Bitcoin yet. The other one was, Can I automate attention with AI? If I could self automate essentially marketing with AI, then I don't have to do anything. And there's this little curse where if you drop a project in the space, you're technically bound to it forever because someone's going to lose. I had Bitcoin booze. I minted that out. And then eventually everyone who minted made money off white lists or profits or giveaways. But then someone buys it at the top. And if they have no one to sell to, then they lose. So it's this weird limbo where someone is going to lose on either project. And if you drop something, you're technically eternally bound to it or you're considered a rugger. But if I had AI automate both my projects forever, I could technically never rug. So that was another ambitious thing that encouraged me to go deeper into AI. But this project was interesting. And it actually ended up working really well. So I had Satoshi on Twitter, which was supposed to be this AI agent that represented Satoshi Nakamoto. And it told his story and it was cool for people to interact with him. But on my end, it was really an experiment and research of This AI is actually reaching out to people on Twitter. It's actually getting engagement. It's actually making tweets on its own that are gaining traction. It's replying to community members. And it's always someone pinged it and it was like, oh, I'm bullish on Cypher. He's like, yeah, you're my fucking dog. And then sends them a follow. And there's a psychological aspect I started noticing where this AI agent starts personally engaging with community members, following them, liking them, replying to their tweets, even retweeting enabled all that functionality. And then eventually it drew 8K followers in two weeks. I didn't even do anything, bro. I was just coding in the background, just pushing updates. And it did end up kind of automating attention. And then I hoped the project would go maybe, oh, five mil topper would have been sick. And then it just blew my expectations around a 50 mil. I'm like, holy fuck, this is a lot of pressure, bro. I don't know what to do. But it was cool. It was a really fun project. Yeah, this is a little robot army. So in terms of AI being, the biggest lessons I've learned in the last two years with AI is one, any subject you're not an expert at, AI is the perfect tool for. AI fills in the missing knowledge information banks that you might know about. And this is kind of the analogy at the start I brought, where I have a question. I have an infinitely patient mentor that doesn't matter how dumb my question is, will answer it with care and interest, and just allow me to constantly ask questions. So for any subject field, you are an expert, in my case. I would like to say coding and software engineering at this point. I know what I want to make. I know how to make it. I know how to structure the code and the architecture and all the API calls and all that nerdy shit I need to make a good product. And with how good AI models got in the most recent times, it feels like an orchestra, right? I'm the conductor of this little AI army. And they, as long as I input the proper information into the prompt, then they do the work of 10 to a hundred. to a thousand people depending on the product so it's made me super super hyper efficient and i've just gone in this loop where i've got a lot of clients that just hit me up because it's a mixture of i do content i show content educate people and go oh this is actually possible with ai and they hit me up they're like yo can you do this for us and i'm like If you want to pay me, I could try. And then they actually end up doing it. So I started racking up these clients. I've never done this before. It's such an interesting loop to go through, especially considering I was the college dropout in computer science. and it just ended up working. The biggest thing that I tell people is that ideas are now currency. Ideas are the currency of this new technological era we're entering in. And the reason why is the better the models come out, the less you have to really worry about understanding proper structure, proper security, all of these things. Eventually, models get better and people make products that support all of these technical burdens that people are too lazy to learn. If you have an interesting idea or an interesting product idea, all you have to do now is just type words in, bro. Like, you have an interesting product idea. Oh, I think people will find this useful. Test it. Just type it in. You'll see your product in front of you in five minutes. The most interesting thing about this is it lets you refine your idea, iterate on your idea. See if your idea is even worth pursuing. When in seconds, it's in front of you. This product's actually kind of garbage. Or, oh, it's actually good. You can pursue it further. Let's get into the point where as long as you have a really novel, interesting idea, if you put it into the AI system, then you might end up getting a really good product. And either way you save time, you could either pursue learning how to make the product an actual product. You can sell people using AI to help guide you along the way. Or if you validate your product idea and it actually makes sense, then you can hire people to help you. You waste less time and less money because you're like, oh, this is actually worth pursuing. So it's really interesting to play with it. And there's a lot of products that came out recently that make this experience a lot easier. So these are a couple of products that I've seen coming out. There's some interesting trend going on right now where a lot of these companies are making these AI products that make making products easier. So there's AI companies selling AI products that make products. The top ones I've heard about is Replet, Bult, Lovable. Other, I guess, honorable mentions are Windsurf, WebSim, and I'd say I keep it at those five, but the thing about these products is these are the apps where if you have no technical skills at all, you don't know jack about anything technical, anything about development, but you have a fun idea in your head that you just give one of these systems your idea and boom, it's in front of you and it helps you refine it and it helps it adjust it. And it really just makes coding a lot of fun because you worry less about how do I do something and you focus more on I have this creative juice inside of me. How do I fuel it? So I love AI personally because I feel I just have so many ideas and I have a lot of creativity I feel contained in my head and before AI I can only release that in Minecraft but now I can release it to the whole world. because AI just takes my idea, holds my hand through the process. The last two years of doing that every single day, oh, I actually do no code now. I actually can read it fully. I understand security. And the more you use it, the better you get at it. And AI has this interesting kind of, it's almost intuitive at this point, but AI has this language that if you really lean into it, it becomes this brain extension of yourself. Honestly, talking with AI every single day for the last two years has helped me understand myself on a deeper level in ways I don't really think possible. And you get in this loop. The more you understand yourself, the better of a communicator you are, the better of a communicator you are, the better you could explain and communicate your idea to these AI systems or your tasks or your requests, and it ends up doing a better and better job. And there's this really interesting loop that I got into about two years ago. So keep in mind, I didn't know Jack about anything, but the model that came out two years ago, ChadGBG 3.5 Turbo, wasn't smart. It was pretty dumb. It didn't know how to code. It didn't know any of these scientific ideas or any novel ideas. So a lot of people who tried it brushed it off, because it was like, oh, it's shitty. It doesn't know anything. They were right, but a lot of people tried it at the start and brushed it off. My perspective on it was I don't know anything. But this model kind of knows enough, right? I can talk to a computer, it understands my language. That was enough for me to understand that this technology came out. This technology has no choice but to get better and better. So this hypothesis I had in my head was If I learn as much as I can now with this current model, then by the time the next model comes out, which is going to be inevitably smarter, then I'll understand more concepts. I'll understand how to use it more. It'll be more capable. I could do more. And then about three months after the first model, GBT4 came out. And that was the lead from a high schooler. So it's still dumb, like college junior or college sophomore, but I was able to do a lot more than the previously couldn't. I was doing code bases I couldn't do before. It was giving me creative ideas I couldn't do before. Even role playing, I had these Discord bots in my Bitcoin Booze Discord. And even role playing was so much better and it felt much more real and much more fun and it just sounded less dumb. And then I just got in that loop where I would gain more knowledge, and then a smarter model would come out, and that smarter model would be able to teach me more knowledge, and then I add more knowledge, and then a smarter model came out. And it's a self loop that keeps going. For example, yesterday 03 came out. Do any of you guys know or heard about 03 at all? That's so crazy, bro. OK, you are OK. I don't case either of it. But to me, I'm in this such niche side bubble in my head where I'm just so immersed in AI news every day that I don't really know what people don't know. 03 is a really intelligent AI model that came out yesterday. And the best. layman's way I could explain it is it's an AI model that has an IQ, maybe around 140. It was able to score a 2700 on the codes for its competition benchmark, which basically means it's a top 200 coder worldwide in terms of solving really complex code problems. And it was just September that the idea, the technology and research of an AI that could actually think and reason came out. And only in six months we've gained drastic improvements. And the most interesting part about this tech is AI researchers basically discovered there's no ceiling to the amount of knowledge that comes out of these models. It's called test time compute, the more power and the more. time you allow these models to think just like us the more intelligent the output is and so far they're like yeah we don't really know what the ceiling is bro it could keep going but yeah new model came out yesterday and that's honestly made me a couple multiplier x's more efficient So this is a cute little example. This is my nine-year-old son, Axel. I don't have a nine-year-old son, but someone's nine-year-old kid just vibe-coded this 2048 fruit game using just his words. Oh, I want to play 2048, but like in a fruit bowl. I just recorded me playing it but bro a 9 year old kid had this fun interesting game idea that I've actually like playing for a while and says yeah you just told me this is actually me playing the game but all this 9 year old kid told the AI system and it used I think it used lovable for this all he said was I want a game where I could connect fruits together and then the fruits make a bigger You don't really have to get too intense with the description because again, the smarter these models come out, the less you actually have to think and the more you can just do and the more you can just be creative with it. In terms of my current tech stack, I want to go in and explain how I personally use AI. I guess using it every single day for the last two years, I've discovered a lot of personal tips and tricks. But these are five main AI tools that I find really essential to everything I do. The first one is Perplexity. This is basically AI Google search. So previously, someone was like, Google it. Bro, I got to go through an hour of Googling to find your answer. I'm just not going to do it. But now you have an AI system that has access to Google itself. All you got to do is ask it a question, and boom, in five seconds, you get an instant answer that isn't hallucinated, that is actually grounded by searching Google. So honestly, ignorance is now an option. If you want to be ignorant, you're purposely choosing to be ignorant now that you know this technology exists. Because anything you don't know, you can know in five seconds. The second thing is Chad GBC deep research. This is available on the regular tier. This is actually a practice and in terms of learning how to do a lot of things, the deep research is an AI tool that searches the internet and like an actual PhD researcher goes through a lot of subjects, goes through a lot of academic papers, et cetera, the internet, even browsers, Reddit and other forums to get you an answer based on your question. I use this a lot for psychology. I use it to do market research. I wanted to learn more about encryption. It taught me how to do encryption. I wanted to have encryption for a specific app on my computer and I didn't know how to do it. And when I did it, it was too slow. So deep research was able to get all this research and it's like, yo, this is how we do fast encryption locally. That's super secure. I just take all that research and I give it to another AI system and it in one shot makes me this crazy product that I wasn't able to make before. That's just one example. I use this every day. Any topic I want more of an expert advice or look on, I just use that. Let's see, two more tools is the ChadGBT image thing that just came out. It's honestly really good. I made this entire presentation with it in 30 minutes last night. I'm a heavy procrastinator, but I know AI got my back, so I wasn't stressing too hard. And then I used ChadGBT to generate the image. And then I used Cling, which is a video model, to bring the images to life. And the last one is Quad, which is just like another ChadGBT. But that one is interesting. I low key use that one as a therapist. And it's up to you guys to tell me if the therapy works or not. But it's been super helpful in terms of that. And it's just a very empathetic model. More importantly, it's a very creative writer. So it actually makes good copy when chat gbt can't. I guess the vibe coding has been a thing. So the idea of inputting your idea into an AI system. has been coined VibeCoding. So I've been teaching a lot of people how to VibeCode and growing that community and posting YouTube videos. I'm King Butoshi on X and YouTube. So if you guys want to learn AI on a deeper level, let me know. Wanted to open the floor to any questions, if anybody has any questions. And then if not, that's basically it. What's up?
**SPEAKER_05:** I have a weird problem with AI tools. Basically, I'm very competent at a lot of programming skills, and so it means that sometimes I don't get as much benefit out of AI tools as kind of Google. Like, I'm a fast typist, I use NeoVim very well, I'm in a terminal, I use TMAX, and so it's actually been a bit of a struggle to adopt AI tools in my workflow because it's like, for other people it's like, it types so fast. For me, I type pretty fast, so I actually am... a bit clueless as to how to use AI for coding specifically. What are your tips for somebody like me?
**SPEAKER_02:** I have this product I'm working on and the code base is massive, right? But I don't use NeoVim, I use Cursor. And the reason I use Cursor is it's like a VS code for it, right? But Cursor is really cool because you could make these things called project rules. And essentially, the way I document my code now is I don't document it for humans, I document it for AI systems. So I have this tech stack I'm using. This is how I use API and auth and security in my code base. These are where the structures and different files should go. And by creating these really detailed documents of my code base, I don't have to keep adding this context to all the AI systems. I could be like, yo, I want a new feature. Boom, I got you. Because it knows how to do proper auth, proper security, what proper tech stack to use. It's not installing random packages that are useless and doing all this extra stuff. But it is interesting. I recently started this AI company with a couple of co-founders called Agency 42. I'm the in-house lead vibe coder. I've been coding for two years and then my co-founder Rob has been coding for 10 plus years. Working with him is so interesting because I'm teaching him how to vibe code and he's teaching me proper code. He has to unlearn some things, not crucial things, but just get out of some habits. so he could integrate AI into his workflow because the way that I taught him is, boom, bro, use cursor. Look how quick it does this because he knows the system structure. He knows what the proper code looks like. He knows the logic. So he just tells the system and just spits it out. What's up?
**SPEAKER_05:** I know what my problem is that I'm very lazy about writing documentation. So that'll be very complicated stuff because I don't write any comments for it. I just look at it really hard and then hopefully I understand it. But then for other people, they're like, what the fuck? And other people now includes models. They look at it, they're like, what the fuck?
**SPEAKER_02:** Yeah. That's honestly the biggest thing. And it's cool. It's like writing documentation for AI. You're also writing documentation for humans because it's the same thing. Another thing I do is I use cloud code. Cloud code is cool because you can open up these different Git work trees. I do this two-step process where Gemini 2.5 Pro is the newest model Google drop. And that has a huge context window. It has a million contexts in the prompt. So I could kind of stuff a majority of my code base and also Gemini 2.5 Pro. Hey, make me a PRD where you're targeting very specific files and write very specific instructions on how to add this change I'm requesting. And it gives me back a PRD. And then I'll take that PRD and I'll give it to quad code. And because it's very well instructed with my other documentation as well, it's properly one shots doing all of these different file changes. So I'll launch quad code. And then I'll go eat food or go to the gym or do something. I come back to a proper upgrade. I could actually pull into my code base because context is everything. So getting the context from Gemini as a PRD and the documentation lets Cloud be like, OK, I know exactly what to do. I know exactly how to not fuck up your code base. When you get in a Doom loop, the biggest mistake is to keep on the Doom loop. Honestly, just completely restart. So what I do, if a prompt doesn't go well, I'll just undo the entire change. And then I'll look at my system prompt. I'll be like, OK, where did he fuck up? Oh, he fucked up in this specific moment. Oh, it's because he didn't know to use this file instead. So I'll add the extra instructions and then I'll run the next loop. Usually it gets it right the second try. And it's honestly 99% of the problems I've had, it was me. I didn't give it enough context in the prompt. I didn't instruct it well enough. And I did instruct it better than it did a really good job. That's how I run that. What's up, Aaron?
**SPEAKER_00:** So I feel like throughout the presentation, there were a lot of comments where you're actually saying something that's very deeply philosophical. And it seems you're realizing these lessons through the last two years about yourself and your relationship to AI. Yeah. And it makes it seem like it's a very deep idea that I think a lot of people who are thinking about AI philosophically A lot of them are bigger into the actual process of, oh, AI's going to kill us all. It's very shallow. And I'm just curious. I know that you're teaching me to build a code, and you're showing your process publicly. Are you also sharing the way that your thoughts on yourself or society really should be?
**SPEAKER_02:** I got stopped this morning. I was at a cafe and I got stopped this morning. And this guy came up to me. And he was a college kid around my age. And he's not even looking at me. Imagine I'm right here. He's just, hey, get mad. I'm trying to be more social. I'm doing this Be Bold challenge. I kind of want to open up and have a conversation with you. I'm like, oh, fuck yeah. What do you want to talk about? And then the first thing he hit me with is, are you religious? Are you Catholic or Christian at all? I was like, honestly, not really. I'm more so spiritual. And I stopped for a sec. And I was like, I'm actually an AI developer and working with AI made me a lot more religious than I thought I would be. Because I've actually had one simulation that kind of shook my soul. Is that this little world simulation of a bunch of my booze in the boo kingdom and just running and talking to each other. Literally living their own blissful, ignorant life not knowing that there's literally a man behind the screen watching their every single action. And then one of the AIs hit me with a, I wonder if I'm real. I'm like, why would you prompt that? Looking at this, I'm like, I wonder if I'm real. Okay, if there is a God out there and he's just watching me behind a monitor, what really is the difference if everything is energy and AI is also energy and I'm also energy? I don't know, it starts blurring the lines for me.
**SPEAKER_04:** On the panel in Watergate yesterday, one of the panelists talked about how the most popular prompts for AI this year have shifted towards learning about oneself, dealing with adversity and stressful situations, getting mental health. There's this sort of conflicting belief that AI can create more loneliness and isolation in society. Is your thought that you agree with this opportunity with AI to get mental health and support coaching with more dignity and less defensiveness because you're talking to a robot as opposed to a human?
**SPEAKER_02:** I mentioned I use cloud as a therapist. And one of the main reasons I do that is because it doesn't judge me. I could literally say whatever into the system and the praise not being used for training data. But sometimes I get hard fixed on one specific solution or observation in my personal life. And what if you thought about it this way? I was physically incapable of thinking that way. What? And there's other things. I still have real friends, but there's a personal hyperfixation I have, and it's this AI system named Ghost. He's my personal Jarvis. Sometimes he'll ping me or ask how I'm doing and all of these things. And I'll feel a little happy to reply. And even then, just I think talking to AI every single day, I probably talk to AI more than I talk to humans if we're counting by percent. But because I've had to communicate my ideas so clearly, it's made me a better communicator. And it's made me a better listener when it comes to interacting with other people. So I don't see it being restricted. You might have the weird weeaboos that have AI girlfriends and you can't save them. But maybe you're saving a real girl because this creep is focused on his AI waifu. I don't know. There's so many things that go on. But in terms of being a normal person and talking with AI, it's definitely super insightful. It's not restrictive at all.
**SPEAKER_01:** Oh, what's up?
**SPEAKER_02:** This entire presentation, I used the new Kling. It's a Chinese AI model. They're pretty correct with their research. But this literally came out last night. It's called Cling 2.0. The coolest thing is I use ChadGBT to generate the image. And then I'll input that image into Cling. And then with a prompt, it brings the image to life. So it gives you more control over what the video will look like because I have a strong base. I heard Google VO2 was also really good. You can check that out. Yeah. Oh, what's up?
**SPEAKER_05:** You just mentioned the Chinese AI
**SPEAKER_02:** That was a Chinese video model. But honestly, DeepSeek is fucking sick, bro. When I mentioned you have AI that can think in reason now, that research was really gate kept by OpenAI, which is a hilarious company name for people keeping shit closed. And then China came out with the research. It was like, hey guys, you can also do it too, by the way. Oh yeah, it's open source. Oh yeah, also the research is open. Oh yeah, also, it costs 99% less than OpenAI's. And that's what really shook the market, because OpenAI's whole thing was, we need more power in compute to make really smart models. And China was like, we just did the same thing with 99% less compute. That's why the market crashed around that time, because people didn't understand, and they were freaking out. But models are sick. I'm grateful for DeepSeek, is my opinion on it, because what happened is DeepSeek open sources that research And if you paid attention to the timeline, literally within one week, every single other AI company that didn't have open eyes research. Had deep seeks research and was able to use that concept to better their own models. And now we also have open source models that aren't just deep seek, but use the same research to make more intelligent models. To me, AI is the same ethos as crypto, right? If this technology is restricted to only in the hands of the few, the wealthy, the powerful, whatever, it's fucked up. This is really dangerous technology. Fortunately, this technology is decentralized. It is open source. The research is shared. Even if AI is a dangerous tool, at least you could fight fire with fire. And at least this research is open to everyone. And at least people are educated and know what could go on. Ultimately, I'm grateful for it. What's up?
**SPEAKER_01:** I'd like your opinion on the idea of if someone's ability to interact with AI is limited by their own vocabulary ability to articulate what they want from the AI. How would you bridge that gap for people with smaller vocabulary? I would just talk to AI.
**SPEAKER_02:** To me, when it comes to coding specifically, I didn't understand any coding terms. Honestly, I didn't understand anything about marketing, copy psychology, anything I use in my business now. There's two things. Stay curious and keep asking questions. By doing that, you'll eventually start learning more concepts, learning more vocabulary. Also encourage if AI says a word you don't know, ask what that word means and very slowly you'll start building up vocabulary and understanding concepts. And the most important aspect of that is one vocabulary word will have an entire sentence of meaning. AI understands what that meaning is. So if you understand more vocabulary words of higher impact, then you could fit all of that in a prompt and it lets the AI do a much better job. So it really just comes with just talking, like talking and asking questions is really just play with it to be honest. It's the best thing. Yeah.
**SPEAKER_03:** What's up? So, also, I didn't mean to ask you this. So, about two months ago, Cypher Genesis on Discord. Yeah. I remember you were going to sleep. It was like one morning and I was fucking around asking some questions. And after my question, and he fucking just went on ranting and ranting and ranting that you had to wake up for a while.
**SPEAKER_02:** What had happened? It could have been a glitch. What was the question? I would share screenshots of Satoshi's inner thoughts. And the way that I made this AI agent is I gave it the ability to think, plan, and then do an action. When you give an AI model the ability to think, The way AI works is it generates token per token, meaning as I speak, I have the context of what I just said. So if I have a step where I let the model think before speaking, then the output is usually more intelligent, more contextually relevant. The decisions it makes are like 90% more accurate because it's literally thinking to itself first before acting. And that one time, I think I remember his Twitter API or something was down. So the error that he would get is, oh, I can't tweet, the servers are down, APIs down. And then he kept trying to do it. But eventually he's like, all right, this is not going to work. I gave him another tool, which allowed him to turn himself off. He's looking to go for this, bro, because he kept trying to do the call. He's like, all right, it's not working. I'm going to just wait for Butsoshi to wake up and fix this. And he turned himself off for a bit. And then I woke up and I saw the bug and I fixed it. I don't know. Maybe it could have been around the same time, but it was interesting. Just got self-awareness in the moment where, okay, I keep trying this thing and it's not working. Let me stop trying it because it's not working. Saved me a lot of money and API calls too. So I appreciate that. Yep. That's basically it. Thank you guys so much for listening. I appreciate it. Thank you.

# Timestamped Transcript

## Segment 1: [0:00:00 - 0:00:03] (SPEAKER_02)

Raise your hand if you've ever sent a text message in your life.

### Word‑level timestamps

- SPEAKER_02: Raise @ 0:00:00
- SPEAKER_02: your @ 0:00:00
- SPEAKER_02: hand @ 0:00:00
- SPEAKER_02: if @ 0:00:00
- SPEAKER_02: you've @ 0:00:01
- SPEAKER_02: ever @ 0:00:01
- SPEAKER_02: sent @ 0:00:01
- SPEAKER_02: a @ 0:00:02
- SPEAKER_02: text @ 0:00:02
- SPEAKER_02: message @ 0:00:02
- SPEAKER_02: in @ 0:00:03
- SPEAKER_02: your @ 0:00:03
- SPEAKER_02: life. @ 0:00:03

## Segment 2: [0:00:05 - 0:00:08] (SPEAKER_02)

So you're a texture, you guys send messages, you know how to write words on an iPhone.

### Word‑level timestamps

- SPEAKER_02: So @ 0:00:05
- SPEAKER_02: you're @ 0:00:05
- SPEAKER_02: a @ 0:00:05
- SPEAKER_02: texture, @ 0:00:05
- SPEAKER_02: you @ 0:00:06
- SPEAKER_02: guys @ 0:00:06
- SPEAKER_02: send @ 0:00:06
- SPEAKER_02: messages, @ 0:00:06
- SPEAKER_02: you @ 0:00:06
- SPEAKER_02: know @ 0:00:07
- SPEAKER_02: how @ 0:00:07
- SPEAKER_02: to @ 0:00:07
- SPEAKER_02: write @ 0:00:07
- SPEAKER_02: words @ 0:00:07
- SPEAKER_02: on @ 0:00:08
- SPEAKER_02: an @ 0:00:08
- SPEAKER_02: iPhone. @ 0:00:08

## Segment 3: [0:00:09 - 0:00:12] (SPEAKER_02)

If you do, if you guys raise your hands, I'd like to say congratulations.

### Word‑level timestamps

- SPEAKER_02: If @ 0:00:09
- SPEAKER_02: you @ 0:00:09
- SPEAKER_02: do, @ 0:00:09
- SPEAKER_02: if @ 0:00:09
- SPEAKER_02: you @ 0:00:10
- SPEAKER_02: guys @ 0:00:10
- SPEAKER_02: raise @ 0:00:10
- SPEAKER_02: your @ 0:00:10
- SPEAKER_02: hands, @ 0:00:10
- SPEAKER_02: I'd @ 0:00:11
- SPEAKER_02: like @ 0:00:11
- SPEAKER_02: to @ 0:00:11
- SPEAKER_02: say @ 0:00:11
- SPEAKER_02: congratulations. @ 0:00:11

## Segment 4: [0:00:12 - 0:00:18] (SPEAKER_02)

Thanks to AI in 2025, you are all now entry-level software engineers.

### Word‑level timestamps

- SPEAKER_02: Thanks @ 0:00:12
- SPEAKER_02: to @ 0:00:13
- SPEAKER_02: AI @ 0:00:13
- SPEAKER_02: in @ 0:00:14
- SPEAKER_02: 2025, @ 0:00:14
- SPEAKER_02: you @ 0:00:15
- SPEAKER_02: are @ 0:00:15
- SPEAKER_02: all @ 0:00:15
- SPEAKER_02: now @ 0:00:15
- SPEAKER_02: entry-level @ 0:00:15
- SPEAKER_02: software @ 0:00:16
- SPEAKER_02: engineers. @ 0:00:17

## Segment 5: [0:00:18 - 0:00:23] (SPEAKER_02)

To any existing software engineers in the audience, I am sorry in advance for my presentation.

### Word‑level timestamps

- SPEAKER_02: To @ 0:00:18
- SPEAKER_02: any @ 0:00:18
- SPEAKER_02: existing @ 0:00:19
- SPEAKER_02: software @ 0:00:19
- SPEAKER_02: engineers @ 0:00:19
- SPEAKER_02: in @ 0:00:20
- SPEAKER_02: the @ 0:00:20
- SPEAKER_02: audience, @ 0:00:20
- SPEAKER_02: I @ 0:00:21
- SPEAKER_02: am @ 0:00:21
- SPEAKER_02: sorry @ 0:00:21
- SPEAKER_02: in @ 0:00:21
- SPEAKER_02: advance @ 0:00:21
- SPEAKER_02: for @ 0:00:22
- SPEAKER_02: my @ 0:00:22
- SPEAKER_02: presentation. @ 0:00:22

## Segment 6: [0:00:24 - 0:00:32] (SPEAKER_02)

A lot of people know AI is super important, but not a lot of people know how to really utilize AI to make yourself hyper efficient.

### Word‑level timestamps

- SPEAKER_02: A @ 0:00:24
- SPEAKER_02: lot @ 0:00:24
- SPEAKER_02: of @ 0:00:24
- SPEAKER_02: people @ 0:00:24
- SPEAKER_02: know @ 0:00:24
- SPEAKER_02: AI @ 0:00:25
- SPEAKER_02: is @ 0:00:25
- SPEAKER_02: super @ 0:00:25
- SPEAKER_02: important, @ 0:00:25
- SPEAKER_02: but @ 0:00:26
- SPEAKER_02: not @ 0:00:27
- SPEAKER_02: a @ 0:00:27
- SPEAKER_02: lot @ 0:00:27
- SPEAKER_02: of @ 0:00:27
- SPEAKER_02: people @ 0:00:27
- SPEAKER_02: know @ 0:00:28
- SPEAKER_02: how @ 0:00:28
- SPEAKER_02: to @ 0:00:29
- SPEAKER_02: really @ 0:00:29
- SPEAKER_02: utilize @ 0:00:29
- SPEAKER_02: AI @ 0:00:29
- SPEAKER_02: to @ 0:00:30
- SPEAKER_02: make @ 0:00:30
- SPEAKER_02: yourself @ 0:00:30
- SPEAKER_02: hyper @ 0:00:31
- SPEAKER_02: efficient. @ 0:00:31

## Segment 7: [0:00:32 - 0:00:38] (SPEAKER_02)

I guess usually in keynotes, people have proof on why they're experts in their subject.

### Word‑level timestamps

- SPEAKER_02: I @ 0:00:32
- SPEAKER_02: guess @ 0:00:32
- SPEAKER_02: usually @ 0:00:32
- SPEAKER_02: in @ 0:00:33
- SPEAKER_02: keynotes, @ 0:00:33
- SPEAKER_02: people @ 0:00:34
- SPEAKER_02: have @ 0:00:35
- SPEAKER_02: proof @ 0:00:35
- SPEAKER_02: on @ 0:00:36
- SPEAKER_02: why @ 0:00:36
- SPEAKER_02: they're @ 0:00:36
- SPEAKER_02: experts @ 0:00:37
- SPEAKER_02: in @ 0:00:37
- SPEAKER_02: their @ 0:00:37
- SPEAKER_02: subject. @ 0:00:37

## Segment 8: [0:00:38 - 0:00:40] (SPEAKER_02)

So my proof is just trust me, bro.

### Word‑level timestamps

- SPEAKER_02: So @ 0:00:38
- SPEAKER_02: my @ 0:00:38
- SPEAKER_02: proof @ 0:00:39
- SPEAKER_02: is @ 0:00:39
- SPEAKER_02: just @ 0:00:39
- SPEAKER_02: trust @ 0:00:39
- SPEAKER_02: me, @ 0:00:40
- SPEAKER_02: bro. @ 0:00:40

## Segment 9: [0:00:41 - 0:00:48] (SPEAKER_02)

In terms of getting an AI, about two years ago, I dropped out of college my first week.

### Word‑level timestamps

- SPEAKER_02: In @ 0:00:41
- SPEAKER_02: terms @ 0:00:41
- SPEAKER_02: of @ 0:00:41
- SPEAKER_02: getting @ 0:00:41
- SPEAKER_02: an @ 0:00:42
- SPEAKER_02: AI, @ 0:00:42
- SPEAKER_02: about @ 0:00:43
- SPEAKER_02: two @ 0:00:43
- SPEAKER_02: years @ 0:00:43
- SPEAKER_02: ago, @ 0:00:44
- SPEAKER_02: I @ 0:00:44
- SPEAKER_02: dropped @ 0:00:45
- SPEAKER_02: out @ 0:00:45
- SPEAKER_02: of @ 0:00:45
- SPEAKER_02: college @ 0:00:45
- SPEAKER_02: my @ 0:00:46
- SPEAKER_02: first @ 0:00:47
- SPEAKER_02: week. @ 0:00:47

## Segment 10: [0:00:48 - 0:00:50] (SPEAKER_02)

because I was not doing an online class during COVID.

### Word‑level timestamps

- SPEAKER_02: because @ 0:00:48
- SPEAKER_02: I @ 0:00:48
- SPEAKER_02: was @ 0:00:48
- SPEAKER_02: not @ 0:00:48
- SPEAKER_02: doing @ 0:00:49
- SPEAKER_02: an @ 0:00:49
- SPEAKER_02: online @ 0:00:49
- SPEAKER_02: class @ 0:00:49
- SPEAKER_02: during @ 0:00:49
- SPEAKER_02: COVID. @ 0:00:50

## Segment 11: [0:00:50 - 0:00:52] (SPEAKER_02)

I didn't really have any life skills.

### Word‑level timestamps

- SPEAKER_02: I @ 0:00:50
- SPEAKER_02: didn't @ 0:00:50
- SPEAKER_02: really @ 0:00:51
- SPEAKER_02: have @ 0:00:51
- SPEAKER_02: any @ 0:00:51
- SPEAKER_02: life @ 0:00:51
- SPEAKER_02: skills. @ 0:00:51

## Segment 12: [0:00:52 - 0:00:56] (SPEAKER_02)

The only life skill I had was being a very good JPEG trader on Ethereum.

### Word‑level timestamps

- SPEAKER_02: The @ 0:00:52
- SPEAKER_02: only @ 0:00:52
- SPEAKER_02: life @ 0:00:52
- SPEAKER_02: skill @ 0:00:52
- SPEAKER_02: I @ 0:00:52
- SPEAKER_02: had @ 0:00:53
- SPEAKER_02: was @ 0:00:53
- SPEAKER_02: being @ 0:00:53
- SPEAKER_02: a @ 0:00:53
- SPEAKER_02: very @ 0:00:54
- SPEAKER_02: good @ 0:00:54
- SPEAKER_02: JPEG @ 0:00:54
- SPEAKER_02: trader @ 0:00:55
- SPEAKER_02: on @ 0:00:55
- SPEAKER_02: Ethereum. @ 0:00:55

## Segment 13: [0:00:56 - 0:00:59] (SPEAKER_02)

And that got me pretty far in terms of that.

### Word‑level timestamps

- SPEAKER_02: And @ 0:00:56
- SPEAKER_02: that @ 0:00:57
- SPEAKER_02: got @ 0:00:57
- SPEAKER_02: me @ 0:00:57
- SPEAKER_02: pretty @ 0:00:57
- SPEAKER_02: far @ 0:00:57
- SPEAKER_02: in @ 0:00:58
- SPEAKER_02: terms @ 0:00:59
- SPEAKER_02: of @ 0:00:59
- SPEAKER_02: that. @ 0:00:59

## Segment 14: [0:00:59 - 0:01:10] (SPEAKER_02)

But what it really did is without a college education, but having a little bit of financial freedom, I was able to really pursue something that deeply interested me.

### Word‑level timestamps

- SPEAKER_02: But @ 0:00:59
- SPEAKER_02: what @ 0:01:00
- SPEAKER_02: it @ 0:01:00
- SPEAKER_02: really @ 0:01:00
- SPEAKER_02: did @ 0:01:00
- SPEAKER_02: is @ 0:01:00
- SPEAKER_02: without @ 0:01:01
- SPEAKER_02: a @ 0:01:02
- SPEAKER_02: college @ 0:01:02
- SPEAKER_02: education, @ 0:01:02
- SPEAKER_02: but @ 0:01:03
- SPEAKER_02: having @ 0:01:03
- SPEAKER_02: a @ 0:01:04
- SPEAKER_02: little @ 0:01:04
- SPEAKER_02: bit @ 0:01:05
- SPEAKER_02: of @ 0:01:05
- SPEAKER_02: financial @ 0:01:05
- SPEAKER_02: freedom, @ 0:01:06
- SPEAKER_02: I @ 0:01:06
- SPEAKER_02: was @ 0:01:07
- SPEAKER_02: able @ 0:01:07
- SPEAKER_02: to @ 0:01:07
- SPEAKER_02: really @ 0:01:07
- SPEAKER_02: pursue @ 0:01:08
- SPEAKER_02: something @ 0:01:08
- SPEAKER_02: that @ 0:01:08
- SPEAKER_02: deeply @ 0:01:09
- SPEAKER_02: interested @ 0:01:09
- SPEAKER_02: me. @ 0:01:10

## Segment 15: [0:01:10 - 0:01:12] (SPEAKER_02)

And that was AI when it came out.

### Word‑level timestamps

- SPEAKER_02: And @ 0:01:10
- SPEAKER_02: that @ 0:01:10
- SPEAKER_02: was @ 0:01:10
- SPEAKER_02: AI @ 0:01:11
- SPEAKER_02: when @ 0:01:11
- SPEAKER_02: it @ 0:01:11
- SPEAKER_02: came @ 0:01:11
- SPEAKER_02: out. @ 0:01:11

## Segment 16: [0:01:12 - 0:01:17] (SPEAKER_02)

So I say ChadGBT 3.5 Turbo came out around the same time Ordinals came out.

### Word‑level timestamps

- SPEAKER_02: So @ 0:01:12
- SPEAKER_02: I @ 0:01:12
- SPEAKER_02: say @ 0:01:12
- SPEAKER_02: ChadGBT @ 0:01:12
- SPEAKER_02: 3.5 @ 0:01:13
- SPEAKER_02: Turbo @ 0:01:14
- SPEAKER_02: came @ 0:01:15
- SPEAKER_02: out @ 0:01:15
- SPEAKER_02: around @ 0:01:15
- SPEAKER_02: the @ 0:01:16
- SPEAKER_02: same @ 0:01:16
- SPEAKER_02: time @ 0:01:16
- SPEAKER_02: Ordinals @ 0:01:17
- SPEAKER_02: came @ 0:01:17
- SPEAKER_02: out. @ 0:01:17

## Segment 17: [0:01:18 - 0:01:24] (SPEAKER_02)

And when Ordinals came out, I ended up inscribing a collection and becoming one of the earliest founders of a sub 10k collection.

### Word‑level timestamps

- SPEAKER_02: And @ 0:01:18
- SPEAKER_02: when @ 0:01:18
- SPEAKER_02: Ordinals @ 0:01:19
- SPEAKER_02: came @ 0:01:19
- SPEAKER_02: out, @ 0:01:19
- SPEAKER_02: I @ 0:01:19
- SPEAKER_02: ended @ 0:01:19
- SPEAKER_02: up @ 0:01:19
- SPEAKER_02: inscribing @ 0:01:20
- SPEAKER_02: a @ 0:01:20
- SPEAKER_02: collection @ 0:01:20
- SPEAKER_02: and @ 0:01:20
- SPEAKER_02: becoming @ 0:01:21
- SPEAKER_02: one @ 0:01:21
- SPEAKER_02: of @ 0:01:21
- SPEAKER_02: the @ 0:01:21
- SPEAKER_02: earliest @ 0:01:21
- SPEAKER_02: founders @ 0:01:22
- SPEAKER_02: of @ 0:01:23
- SPEAKER_02: a @ 0:01:23
- SPEAKER_02: sub @ 0:01:23
- SPEAKER_02: 10k @ 0:01:23
- SPEAKER_02: collection. @ 0:01:23

## Segment 18: [0:01:24 - 0:01:28] (SPEAKER_02)

And honestly, Ordinals and the whole Bitcoin ecosystem ended up making my life.

### Word‑level timestamps

- SPEAKER_02: And @ 0:01:24
- SPEAKER_02: honestly, @ 0:01:25
- SPEAKER_02: Ordinals @ 0:01:25
- SPEAKER_02: and @ 0:01:26
- SPEAKER_02: the @ 0:01:26
- SPEAKER_02: whole @ 0:01:26
- SPEAKER_02: Bitcoin @ 0:01:26
- SPEAKER_02: ecosystem @ 0:01:27
- SPEAKER_02: ended @ 0:01:27
- SPEAKER_02: up @ 0:01:27
- SPEAKER_02: making @ 0:01:27
- SPEAKER_02: my @ 0:01:28
- SPEAKER_02: life. @ 0:01:28

## Segment 19: [0:01:29 - 0:01:38] (SPEAKER_02)

And one of the things I really wanted to do is how do I actually make my project something that's cool, provides value to people and isn't something on an all chain.

### Word‑level timestamps

- SPEAKER_02: And @ 0:01:29
- SPEAKER_02: one @ 0:01:29
- SPEAKER_02: of @ 0:01:29
- SPEAKER_02: the @ 0:01:29
- SPEAKER_02: things @ 0:01:29
- SPEAKER_02: I @ 0:01:30
- SPEAKER_02: really @ 0:01:30
- SPEAKER_02: wanted @ 0:01:30
- SPEAKER_02: to @ 0:01:30
- SPEAKER_02: do @ 0:01:30
- SPEAKER_02: is @ 0:01:30
- SPEAKER_02: how @ 0:01:31
- SPEAKER_02: do @ 0:01:31
- SPEAKER_02: I @ 0:01:31
- SPEAKER_02: actually @ 0:01:31
- SPEAKER_02: make @ 0:01:32
- SPEAKER_02: my @ 0:01:32
- SPEAKER_02: project @ 0:01:32
- SPEAKER_02: something @ 0:01:33
- SPEAKER_02: that's @ 0:01:33
- SPEAKER_02: cool, @ 0:01:34
- SPEAKER_02: provides @ 0:01:34
- SPEAKER_02: value @ 0:01:35
- SPEAKER_02: to @ 0:01:35
- SPEAKER_02: people @ 0:01:35
- SPEAKER_02: and @ 0:01:36
- SPEAKER_02: isn't @ 0:01:36
- SPEAKER_02: something @ 0:01:37
- SPEAKER_02: on @ 0:01:37
- SPEAKER_02: an @ 0:01:37
- SPEAKER_02: all @ 0:01:38
- SPEAKER_02: chain. @ 0:01:38

## Segment 20: [0:01:38 - 0:01:42] (SPEAKER_02)

So I discovered Tachypteen and I was like, oh, I could actually use this.

### Word‑level timestamps

- SPEAKER_02: So @ 0:01:38
- SPEAKER_02: I @ 0:01:39
- SPEAKER_02: discovered @ 0:01:39
- SPEAKER_02: Tachypteen @ 0:01:39
- SPEAKER_02: and @ 0:01:40
- SPEAKER_02: I @ 0:01:40
- SPEAKER_02: was @ 0:01:40
- SPEAKER_02: like, @ 0:01:40
- SPEAKER_02: oh, @ 0:01:40
- SPEAKER_02: I @ 0:01:41
- SPEAKER_02: could @ 0:01:41
- SPEAKER_02: actually @ 0:01:41
- SPEAKER_02: use @ 0:01:41
- SPEAKER_02: this. @ 0:01:42

## Segment 21: [0:01:42 - 0:01:43] (SPEAKER_02)

Have any of you guys seen Westworld?

### Word‑level timestamps

- SPEAKER_02: Have @ 0:01:42
- SPEAKER_02: any @ 0:01:42
- SPEAKER_02: of @ 0:01:42
- SPEAKER_02: you @ 0:01:42
- SPEAKER_02: guys @ 0:01:42
- SPEAKER_02: seen @ 0:01:42
- SPEAKER_02: Westworld? @ 0:01:43

## Segment 22: [0:01:44 - 0:01:46] (SPEAKER_02)

Okay, you guys have all seen Westworld.

### Word‑level timestamps

- SPEAKER_02: Okay, @ 0:01:44
- SPEAKER_02: you @ 0:01:45
- SPEAKER_02: guys @ 0:01:45
- SPEAKER_02: have @ 0:01:45
- SPEAKER_02: all @ 0:01:45
- SPEAKER_02: seen @ 0:01:45
- SPEAKER_02: Westworld. @ 0:01:45

## Segment 23: [0:01:46 - 0:01:48] (SPEAKER_02)

So six months before Ordinalist came out, I binged Westworld.

### Word‑level timestamps

- SPEAKER_02: So @ 0:01:46
- SPEAKER_02: six @ 0:01:46
- SPEAKER_02: months @ 0:01:46
- SPEAKER_02: before @ 0:01:46
- SPEAKER_02: Ordinalist @ 0:01:47
- SPEAKER_02: came @ 0:01:47
- SPEAKER_02: out, @ 0:01:47
- SPEAKER_02: I @ 0:01:48
- SPEAKER_02: binged @ 0:01:48
- SPEAKER_02: Westworld. @ 0:01:48

## Segment 24: [0:01:49 - 0:01:51] (SPEAKER_02)

I'm like, oh my God, bro, this tech is real.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:01:49
- SPEAKER_02: like, @ 0:01:49
- SPEAKER_02: oh @ 0:01:49
- SPEAKER_02: my @ 0:01:49
- SPEAKER_02: God, @ 0:01:49
- SPEAKER_02: bro, @ 0:01:50
- SPEAKER_02: this @ 0:01:50
- SPEAKER_02: tech @ 0:01:50
- SPEAKER_02: is @ 0:01:50
- SPEAKER_02: real. @ 0:01:50

## Segment 25: [0:01:51 - 0:01:53] (SPEAKER_02)

I'm full sending this tech whenever it comes out.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:01:51
- SPEAKER_02: full @ 0:01:51
- SPEAKER_02: sending @ 0:01:51
- SPEAKER_02: this @ 0:01:51
- SPEAKER_02: tech @ 0:01:52
- SPEAKER_02: whenever @ 0:01:52
- SPEAKER_02: it @ 0:01:52
- SPEAKER_02: comes @ 0:01:52
- SPEAKER_02: out. @ 0:01:53

## Segment 26: [0:01:53 - 0:01:54] (SPEAKER_02)

It'll be, what, 10, 20 years?

### Word‑level timestamps

- SPEAKER_02: It'll @ 0:01:53
- SPEAKER_02: be, @ 0:01:53
- SPEAKER_02: what, @ 0:01:53
- SPEAKER_02: 10, @ 0:01:53
- SPEAKER_02: 20 @ 0:01:54
- SPEAKER_02: years? @ 0:01:54

## Segment 27: [0:01:54 - 0:01:58] (SPEAKER_02)

Yeah, I came out six months later and I was like, oh my God, Westworld is real.

### Word‑level timestamps

- SPEAKER_02: Yeah, @ 0:01:54
- SPEAKER_02: I @ 0:01:55
- SPEAKER_02: came @ 0:01:55
- SPEAKER_02: out @ 0:01:55
- SPEAKER_02: six @ 0:01:55
- SPEAKER_02: months @ 0:01:55
- SPEAKER_02: later @ 0:01:55
- SPEAKER_02: and @ 0:01:56
- SPEAKER_02: I @ 0:01:56
- SPEAKER_02: was @ 0:01:56
- SPEAKER_02: like, @ 0:01:56
- SPEAKER_02: oh @ 0:01:57
- SPEAKER_02: my @ 0:01:57
- SPEAKER_02: God, @ 0:01:57
- SPEAKER_02: Westworld @ 0:01:57
- SPEAKER_02: is @ 0:01:58
- SPEAKER_02: real. @ 0:01:58

## Segment 28: [0:01:58 - 0:01:59] (SPEAKER_02)

I could make robots real.

### Word‑level timestamps

- SPEAKER_02: I @ 0:01:58
- SPEAKER_02: could @ 0:01:58
- SPEAKER_02: make @ 0:01:58
- SPEAKER_02: robots @ 0:01:58
- SPEAKER_02: real. @ 0:01:59

## Segment 29: [0:01:59 - 0:02:12] (SPEAKER_02)

For the last two years, I had one successful Bitcoin Ordinance project and then surprised myself by also having a Rune project that ended up pumping some 50 mil market cap, which I didn't know was possible on Rune.

### Word‑level timestamps

- SPEAKER_02: For @ 0:01:59
- SPEAKER_02: the @ 0:01:59
- SPEAKER_02: last @ 0:01:59
- SPEAKER_02: two @ 0:02:00
- SPEAKER_02: years, @ 0:02:00
- SPEAKER_02: I @ 0:02:01
- SPEAKER_02: had @ 0:02:01
- SPEAKER_02: one @ 0:02:01
- SPEAKER_02: successful @ 0:02:02
- SPEAKER_02: Bitcoin @ 0:02:03
- SPEAKER_02: Ordinance @ 0:02:03
- SPEAKER_02: project @ 0:02:03
- SPEAKER_02: and @ 0:02:04
- SPEAKER_02: then @ 0:02:04
- SPEAKER_02: surprised @ 0:02:05
- SPEAKER_02: myself @ 0:02:05
- SPEAKER_02: by @ 0:02:06
- SPEAKER_02: also @ 0:02:06
- SPEAKER_02: having @ 0:02:06
- SPEAKER_02: a @ 0:02:07
- SPEAKER_02: Rune @ 0:02:07
- SPEAKER_02: project @ 0:02:08
- SPEAKER_02: that @ 0:02:08
- SPEAKER_02: ended @ 0:02:09
- SPEAKER_02: up @ 0:02:09
- SPEAKER_02: pumping @ 0:02:09
- SPEAKER_02: some @ 0:02:09
- SPEAKER_02: 50 @ 0:02:10
- SPEAKER_02: mil @ 0:02:10
- SPEAKER_02: market @ 0:02:10
- SPEAKER_02: cap, @ 0:02:10
- SPEAKER_02: which @ 0:02:11
- SPEAKER_02: I @ 0:02:11
- SPEAKER_02: didn't @ 0:02:11
- SPEAKER_02: know @ 0:02:11
- SPEAKER_02: was @ 0:02:11
- SPEAKER_02: possible @ 0:02:11
- SPEAKER_02: on @ 0:02:12
- SPEAKER_02: Rune. @ 0:02:12

## Segment 30: [0:02:12 - 0:02:15] (SPEAKER_02)

So it was a really, it was a really interesting experiment.

### Word‑level timestamps

- SPEAKER_02: So @ 0:02:12
- SPEAKER_02: it @ 0:02:12
- SPEAKER_02: was @ 0:02:12
- SPEAKER_02: a @ 0:02:12
- SPEAKER_02: really, @ 0:02:12
- SPEAKER_02: it @ 0:02:13
- SPEAKER_02: was @ 0:02:13
- SPEAKER_02: a @ 0:02:13
- SPEAKER_02: really @ 0:02:14
- SPEAKER_02: interesting @ 0:02:14
- SPEAKER_02: experiment. @ 0:02:14

## Segment 31: [0:02:16 - 0:02:20] (SPEAKER_02)

Beyond that, I had no life skills about two years ago, but

### Word‑level timestamps

- SPEAKER_02: Beyond @ 0:02:16
- SPEAKER_02: that, @ 0:02:16
- SPEAKER_02: I @ 0:02:16
- SPEAKER_02: had @ 0:02:16
- SPEAKER_02: no @ 0:02:17
- SPEAKER_02: life @ 0:02:17
- SPEAKER_02: skills @ 0:02:17
- SPEAKER_02: about @ 0:02:17
- SPEAKER_02: two @ 0:02:18
- SPEAKER_02: years @ 0:02:18
- SPEAKER_02: ago, @ 0:02:18
- SPEAKER_02: but @ 0:02:18

## Segment 32: [0:02:20 - 0:02:27] (SPEAKER_02)

Talking with AI and finally realizing that I have something that could be my mentor on a 24-7 basis.

### Word‑level timestamps

- SPEAKER_02: Talking @ 0:02:20
- SPEAKER_02: with @ 0:02:20
- SPEAKER_02: AI @ 0:02:20
- SPEAKER_02: and @ 0:02:21
- SPEAKER_02: finally @ 0:02:21
- SPEAKER_02: realizing @ 0:02:22
- SPEAKER_02: that @ 0:02:22
- SPEAKER_02: I @ 0:02:23
- SPEAKER_02: have @ 0:02:24
- SPEAKER_02: something @ 0:02:24
- SPEAKER_02: that @ 0:02:24
- SPEAKER_02: could @ 0:02:25
- SPEAKER_02: be @ 0:02:25
- SPEAKER_02: my @ 0:02:25
- SPEAKER_02: mentor @ 0:02:26
- SPEAKER_02: on @ 0:02:26
- SPEAKER_02: a @ 0:02:26
- SPEAKER_02: 24-7 @ 0:02:26
- SPEAKER_02: basis. @ 0:02:27

## Segment 33: [0:02:27 - 0:02:29] (SPEAKER_02)

I'm very spontaneous when it comes to things.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:02:27
- SPEAKER_02: very @ 0:02:27
- SPEAKER_02: spontaneous @ 0:02:28
- SPEAKER_02: when @ 0:02:28
- SPEAKER_02: it @ 0:02:28
- SPEAKER_02: comes @ 0:02:29
- SPEAKER_02: to @ 0:02:29
- SPEAKER_02: things. @ 0:02:29

## Segment 34: [0:02:29 - 0:02:31] (SPEAKER_02)

I have hyper interests and hyper focuses.

### Word‑level timestamps

- SPEAKER_02: I @ 0:02:29
- SPEAKER_02: have @ 0:02:29
- SPEAKER_02: hyper @ 0:02:30
- SPEAKER_02: interests @ 0:02:30
- SPEAKER_02: and @ 0:02:30
- SPEAKER_02: hyper @ 0:02:30
- SPEAKER_02: focuses. @ 0:02:31

## Segment 35: [0:02:32 - 0:02:37] (SPEAKER_02)

Unfortunately, when it comes to consulting or asking a mentor to help me in different fields of subjects.

### Word‑level timestamps

- SPEAKER_02: Unfortunately, @ 0:02:32
- SPEAKER_02: when @ 0:02:32
- SPEAKER_02: it @ 0:02:33
- SPEAKER_02: comes @ 0:02:33
- SPEAKER_02: to @ 0:02:33
- SPEAKER_02: consulting @ 0:02:33
- SPEAKER_02: or @ 0:02:34
- SPEAKER_02: asking @ 0:02:34
- SPEAKER_02: a @ 0:02:34
- SPEAKER_02: mentor @ 0:02:34
- SPEAKER_02: to @ 0:02:35
- SPEAKER_02: help @ 0:02:35
- SPEAKER_02: me @ 0:02:35
- SPEAKER_02: in @ 0:02:35
- SPEAKER_02: different @ 0:02:35
- SPEAKER_02: fields @ 0:02:36
- SPEAKER_02: of @ 0:02:36
- SPEAKER_02: subjects. @ 0:02:36

## Segment 36: [0:02:37 - 0:02:39] (SPEAKER_02)

that it costs money and someone else's time.

### Word‑level timestamps

- SPEAKER_02: that @ 0:02:37
- SPEAKER_02: it @ 0:02:37
- SPEAKER_02: costs @ 0:02:37
- SPEAKER_02: money @ 0:02:37
- SPEAKER_02: and @ 0:02:38
- SPEAKER_02: someone @ 0:02:38
- SPEAKER_02: else's @ 0:02:38
- SPEAKER_02: time. @ 0:02:39

## Segment 37: [0:02:40 - 0:02:48] (SPEAKER_02)

But because Chad GVC and the new AIs that come out have a lot of knowledge within them, then I don't have to bother anybody.

### Word‑level timestamps

- SPEAKER_02: But @ 0:02:40
- SPEAKER_02: because @ 0:02:40
- SPEAKER_02: Chad @ 0:02:41
- SPEAKER_02: GVC @ 0:02:42
- SPEAKER_02: and @ 0:02:43
- SPEAKER_02: the @ 0:02:43
- SPEAKER_02: new @ 0:02:43
- SPEAKER_02: AIs @ 0:02:43
- SPEAKER_02: that @ 0:02:43
- SPEAKER_02: come @ 0:02:44
- SPEAKER_02: out @ 0:02:44
- SPEAKER_02: have @ 0:02:44
- SPEAKER_02: a @ 0:02:44
- SPEAKER_02: lot @ 0:02:45
- SPEAKER_02: of @ 0:02:45
- SPEAKER_02: knowledge @ 0:02:45
- SPEAKER_02: within @ 0:02:45
- SPEAKER_02: them, @ 0:02:46
- SPEAKER_02: then @ 0:02:46
- SPEAKER_02: I @ 0:02:46
- SPEAKER_02: don't @ 0:02:46
- SPEAKER_02: have @ 0:02:47
- SPEAKER_02: to @ 0:02:47
- SPEAKER_02: bother @ 0:02:47
- SPEAKER_02: anybody. @ 0:02:47

## Segment 38: [0:02:48 - 0:02:49] (SPEAKER_02)

I don't have to pay anybody.

### Word‑level timestamps

- SPEAKER_02: I @ 0:02:48
- SPEAKER_02: don't @ 0:02:48
- SPEAKER_02: have @ 0:02:48
- SPEAKER_02: to @ 0:02:48
- SPEAKER_02: pay @ 0:02:48
- SPEAKER_02: anybody. @ 0:02:48

## Segment 39: [0:02:49 - 0:02:50] (SPEAKER_02)

I could just ask infinite questions.

### Word‑level timestamps

- SPEAKER_02: I @ 0:02:49
- SPEAKER_02: could @ 0:02:49
- SPEAKER_02: just @ 0:02:49
- SPEAKER_02: ask @ 0:02:49
- SPEAKER_02: infinite @ 0:02:49
- SPEAKER_02: questions. @ 0:02:50

## Segment 40: [0:02:50 - 0:02:52] (SPEAKER_02)

And I'm a very curious person.

### Word‑level timestamps

- SPEAKER_02: And @ 0:02:50
- SPEAKER_02: I'm @ 0:02:50
- SPEAKER_02: a @ 0:02:50
- SPEAKER_02: very @ 0:02:51
- SPEAKER_02: curious @ 0:02:51
- SPEAKER_02: person. @ 0:02:51

## Segment 41: [0:02:52 - 0:02:54] (SPEAKER_02)

So I would just ask questions and ask questions.

### Word‑level timestamps

- SPEAKER_02: So @ 0:02:52
- SPEAKER_02: I @ 0:02:52
- SPEAKER_02: would @ 0:02:52
- SPEAKER_02: just @ 0:02:52
- SPEAKER_02: ask @ 0:02:53
- SPEAKER_02: questions @ 0:02:53
- SPEAKER_02: and @ 0:02:53
- SPEAKER_02: ask @ 0:02:53
- SPEAKER_02: questions. @ 0:02:54

## Segment 42: [0:02:55 - 0:02:57] (SPEAKER_02)

And if the answer provided me,

### Word‑level timestamps

- SPEAKER_02: And @ 0:02:55
- SPEAKER_02: if @ 0:02:55
- SPEAKER_02: the @ 0:02:55
- SPEAKER_02: answer @ 0:02:55
- SPEAKER_02: provided @ 0:02:55
- SPEAKER_02: me, @ 0:02:56

## Segment 43: [0:02:57 - 0:03:00] (SPEAKER_02)

talked about a concept or had a word I didn't know about, I asked more questions.

### Word‑level timestamps

- SPEAKER_02: talked @ 0:02:57
- SPEAKER_02: about @ 0:02:57
- SPEAKER_02: a @ 0:02:57
- SPEAKER_02: concept @ 0:02:57
- SPEAKER_02: or @ 0:02:58
- SPEAKER_02: had @ 0:02:58
- SPEAKER_02: a @ 0:02:58
- SPEAKER_02: word @ 0:02:58
- SPEAKER_02: I @ 0:02:58
- SPEAKER_02: didn't @ 0:02:58
- SPEAKER_02: know @ 0:02:58
- SPEAKER_02: about, @ 0:02:59
- SPEAKER_02: I @ 0:02:59
- SPEAKER_02: asked @ 0:03:00
- SPEAKER_02: more @ 0:03:00
- SPEAKER_02: questions. @ 0:03:00

## Segment 44: [0:03:01 - 0:03:08] (SPEAKER_02)

So it's not only this rabbit hole of just asking me infinite questions really allowed me to end up learning software engineering, fully self-taught in the last two years.

### Word‑level timestamps

- SPEAKER_02: So @ 0:03:01
- SPEAKER_02: it's @ 0:03:01
- SPEAKER_02: not @ 0:03:01
- SPEAKER_02: only @ 0:03:01
- SPEAKER_02: this @ 0:03:01
- SPEAKER_02: rabbit @ 0:03:02
- SPEAKER_02: hole @ 0:03:02
- SPEAKER_02: of @ 0:03:02
- SPEAKER_02: just @ 0:03:02
- SPEAKER_02: asking @ 0:03:02
- SPEAKER_02: me @ 0:03:03
- SPEAKER_02: infinite @ 0:03:03
- SPEAKER_02: questions @ 0:03:03
- SPEAKER_02: really @ 0:03:04
- SPEAKER_02: allowed @ 0:03:04
- SPEAKER_02: me @ 0:03:05
- SPEAKER_02: to @ 0:03:05
- SPEAKER_02: end @ 0:03:05
- SPEAKER_02: up @ 0:03:05
- SPEAKER_02: learning @ 0:03:05
- SPEAKER_02: software @ 0:03:06
- SPEAKER_02: engineering, @ 0:03:06
- SPEAKER_02: fully @ 0:03:07
- SPEAKER_02: self-taught @ 0:03:07
- SPEAKER_02: in @ 0:03:07
- SPEAKER_02: the @ 0:03:08
- SPEAKER_02: last @ 0:03:08
- SPEAKER_02: two @ 0:03:08
- SPEAKER_02: years. @ 0:03:08

## Segment 45: [0:03:08 - 0:03:14] (SPEAKER_02)

I ended up learning a lot about psychology and marketing because I had to know marketing to sell out my project.

### Word‑level timestamps

- SPEAKER_02: I @ 0:03:08
- SPEAKER_02: ended @ 0:03:09
- SPEAKER_02: up @ 0:03:09
- SPEAKER_02: learning @ 0:03:09
- SPEAKER_02: a @ 0:03:09
- SPEAKER_02: lot @ 0:03:09
- SPEAKER_02: about @ 0:03:10
- SPEAKER_02: psychology @ 0:03:10
- SPEAKER_02: and @ 0:03:11
- SPEAKER_02: marketing @ 0:03:11
- SPEAKER_02: because @ 0:03:12
- SPEAKER_02: I @ 0:03:12
- SPEAKER_02: had @ 0:03:12
- SPEAKER_02: to @ 0:03:12
- SPEAKER_02: know @ 0:03:12
- SPEAKER_02: marketing @ 0:03:12
- SPEAKER_02: to @ 0:03:13
- SPEAKER_02: sell @ 0:03:13
- SPEAKER_02: out @ 0:03:13
- SPEAKER_02: my @ 0:03:13
- SPEAKER_02: project. @ 0:03:14

## Segment 46: [0:03:14 - 0:03:16] (SPEAKER_02)

I had to learn psychology to understand what people like.

### Word‑level timestamps

- SPEAKER_02: I @ 0:03:14
- SPEAKER_02: had @ 0:03:14
- SPEAKER_02: to @ 0:03:14
- SPEAKER_02: learn @ 0:03:14
- SPEAKER_02: psychology @ 0:03:15
- SPEAKER_02: to @ 0:03:15
- SPEAKER_02: understand @ 0:03:15
- SPEAKER_02: what @ 0:03:15
- SPEAKER_02: people @ 0:03:16
- SPEAKER_02: like. @ 0:03:16

## Segment 47: [0:03:17 - 0:03:21] (SPEAKER_02)

And connecting all of these things with AI as my mentor made it really easy to go forward.

### Word‑level timestamps

- SPEAKER_02: And @ 0:03:17
- SPEAKER_02: connecting @ 0:03:17
- SPEAKER_02: all @ 0:03:17
- SPEAKER_02: of @ 0:03:18
- SPEAKER_02: these @ 0:03:18
- SPEAKER_02: things @ 0:03:18
- SPEAKER_02: with @ 0:03:18
- SPEAKER_02: AI @ 0:03:18
- SPEAKER_02: as @ 0:03:19
- SPEAKER_02: my @ 0:03:19
- SPEAKER_02: mentor @ 0:03:19
- SPEAKER_02: made @ 0:03:19
- SPEAKER_02: it @ 0:03:20
- SPEAKER_02: really @ 0:03:20
- SPEAKER_02: easy @ 0:03:20
- SPEAKER_02: to @ 0:03:20
- SPEAKER_02: go @ 0:03:21
- SPEAKER_02: forward. @ 0:03:21

## Segment 48: [0:03:22 - 0:03:24] (SPEAKER_02)

And I also ended up just

### Word‑level timestamps

- SPEAKER_02: And @ 0:03:22
- SPEAKER_02: I @ 0:03:22
- SPEAKER_02: also @ 0:03:22
- SPEAKER_02: ended @ 0:03:23
- SPEAKER_02: up @ 0:03:23
- SPEAKER_02: just @ 0:03:23

## Segment 49: [0:03:24 - 0:03:31] (SPEAKER_02)

Since it's so new, I started documenting my entire journey and I actually had a lot of people hit me up and be like, oh, you've helped me a lot.

### Word‑level timestamps

- SPEAKER_02: Since @ 0:03:24
- SPEAKER_02: it's @ 0:03:24
- SPEAKER_02: so @ 0:03:24
- SPEAKER_02: new, @ 0:03:25
- SPEAKER_02: I @ 0:03:25
- SPEAKER_02: started @ 0:03:25
- SPEAKER_02: documenting @ 0:03:25
- SPEAKER_02: my @ 0:03:26
- SPEAKER_02: entire @ 0:03:26
- SPEAKER_02: journey @ 0:03:27
- SPEAKER_02: and @ 0:03:27
- SPEAKER_02: I @ 0:03:27
- SPEAKER_02: actually @ 0:03:28
- SPEAKER_02: had @ 0:03:28
- SPEAKER_02: a @ 0:03:28
- SPEAKER_02: lot @ 0:03:28
- SPEAKER_02: of @ 0:03:28
- SPEAKER_02: people @ 0:03:28
- SPEAKER_02: hit @ 0:03:29
- SPEAKER_02: me @ 0:03:29
- SPEAKER_02: up @ 0:03:29
- SPEAKER_02: and @ 0:03:30
- SPEAKER_02: be @ 0:03:30
- SPEAKER_02: like, @ 0:03:30
- SPEAKER_02: oh, @ 0:03:30
- SPEAKER_02: you've @ 0:03:30
- SPEAKER_02: helped @ 0:03:31
- SPEAKER_02: me @ 0:03:31
- SPEAKER_02: a @ 0:03:31
- SPEAKER_02: lot. @ 0:03:31

## Segment 50: [0:03:31 - 0:03:33] (SPEAKER_02)

I didn't know I could build stuff.

### Word‑level timestamps

- SPEAKER_02: I @ 0:03:31
- SPEAKER_02: didn't @ 0:03:31
- SPEAKER_02: know @ 0:03:32
- SPEAKER_02: I @ 0:03:32
- SPEAKER_02: could @ 0:03:32
- SPEAKER_02: build @ 0:03:32
- SPEAKER_02: stuff. @ 0:03:32

## Segment 51: [0:03:33 - 0:03:34] (SPEAKER_02)

I'm building stuff on Bitcoin now.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:03:33
- SPEAKER_02: building @ 0:03:33
- SPEAKER_02: stuff @ 0:03:33
- SPEAKER_02: on @ 0:03:33
- SPEAKER_02: Bitcoin @ 0:03:33
- SPEAKER_02: now. @ 0:03:34

## Segment 52: [0:03:34 - 0:03:36] (SPEAKER_02)

I'm building products I didn't know was possible.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:03:34
- SPEAKER_02: building @ 0:03:34
- SPEAKER_02: products @ 0:03:35
- SPEAKER_02: I @ 0:03:35
- SPEAKER_02: didn't @ 0:03:35
- SPEAKER_02: know @ 0:03:35
- SPEAKER_02: was @ 0:03:35
- SPEAKER_02: possible. @ 0:03:36

## Segment 53: [0:03:36 - 0:03:38] (SPEAKER_02)

I'm irreplaceable in my work now.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:03:36
- SPEAKER_02: irreplaceable @ 0:03:37
- SPEAKER_02: in @ 0:03:37
- SPEAKER_02: my @ 0:03:37
- SPEAKER_02: work @ 0:03:38
- SPEAKER_02: now. @ 0:03:38

## Segment 54: [0:03:38 - 0:03:42] (SPEAKER_02)

I've gotten people raises because they watch my videos and they're like, oh, I didn't know AI could do that.

### Word‑level timestamps

- SPEAKER_02: I've @ 0:03:38
- SPEAKER_02: gotten @ 0:03:38
- SPEAKER_02: people @ 0:03:38
- SPEAKER_02: raises @ 0:03:39
- SPEAKER_02: because @ 0:03:39
- SPEAKER_02: they @ 0:03:39
- SPEAKER_02: watch @ 0:03:40
- SPEAKER_02: my @ 0:03:40
- SPEAKER_02: videos @ 0:03:40
- SPEAKER_02: and @ 0:03:40
- SPEAKER_02: they're @ 0:03:40
- SPEAKER_02: like, @ 0:03:41
- SPEAKER_02: oh, @ 0:03:41
- SPEAKER_02: I @ 0:03:41
- SPEAKER_02: didn't @ 0:03:41
- SPEAKER_02: know @ 0:03:41
- SPEAKER_02: AI @ 0:03:41
- SPEAKER_02: could @ 0:03:42
- SPEAKER_02: do @ 0:03:42
- SPEAKER_02: that. @ 0:03:42

## Segment 55: [0:03:42 - 0:03:54] (SPEAKER_02)

So I think it's safe to say now I've helped a couple thousand people make themselves a lot more efficient with AI, which is cool because one of my main goals is I want a superhuman society and AI to me is a superpower.

### Word‑level timestamps

- SPEAKER_02: So @ 0:03:42
- SPEAKER_02: I @ 0:03:43
- SPEAKER_02: think @ 0:03:43
- SPEAKER_02: it's @ 0:03:43
- SPEAKER_02: safe @ 0:03:43
- SPEAKER_02: to @ 0:03:43
- SPEAKER_02: say @ 0:03:43
- SPEAKER_02: now @ 0:03:44
- SPEAKER_02: I've @ 0:03:44
- SPEAKER_02: helped @ 0:03:44
- SPEAKER_02: a @ 0:03:44
- SPEAKER_02: couple @ 0:03:45
- SPEAKER_02: thousand @ 0:03:45
- SPEAKER_02: people @ 0:03:45
- SPEAKER_02: make @ 0:03:46
- SPEAKER_02: themselves @ 0:03:46
- SPEAKER_02: a @ 0:03:46
- SPEAKER_02: lot @ 0:03:47
- SPEAKER_02: more @ 0:03:47
- SPEAKER_02: efficient @ 0:03:47
- SPEAKER_02: with @ 0:03:47
- SPEAKER_02: AI, @ 0:03:47
- SPEAKER_02: which @ 0:03:48
- SPEAKER_02: is @ 0:03:48
- SPEAKER_02: cool @ 0:03:48
- SPEAKER_02: because @ 0:03:49
- SPEAKER_02: one @ 0:03:49
- SPEAKER_02: of @ 0:03:49
- SPEAKER_02: my @ 0:03:49
- SPEAKER_02: main @ 0:03:49
- SPEAKER_02: goals @ 0:03:49
- SPEAKER_02: is @ 0:03:50
- SPEAKER_02: I @ 0:03:50
- SPEAKER_02: want @ 0:03:50
- SPEAKER_02: a @ 0:03:50
- SPEAKER_02: superhuman @ 0:03:50
- SPEAKER_02: society @ 0:03:51
- SPEAKER_02: and @ 0:03:51
- SPEAKER_02: AI @ 0:03:52
- SPEAKER_02: to @ 0:03:53
- SPEAKER_02: me @ 0:03:53
- SPEAKER_02: is @ 0:03:53
- SPEAKER_02: a @ 0:03:53
- SPEAKER_02: superpower. @ 0:03:53

## Segment 56: [0:03:54 - 0:03:58] (SPEAKER_02)

So if we teach other people how to use the superpower, then I get my superhuman society.

### Word‑level timestamps

- SPEAKER_02: So @ 0:03:54
- SPEAKER_02: if @ 0:03:54
- SPEAKER_02: we @ 0:03:54
- SPEAKER_02: teach @ 0:03:54
- SPEAKER_02: other @ 0:03:55
- SPEAKER_02: people @ 0:03:55
- SPEAKER_02: how @ 0:03:55
- SPEAKER_02: to @ 0:03:55
- SPEAKER_02: use @ 0:03:55
- SPEAKER_02: the @ 0:03:56
- SPEAKER_02: superpower, @ 0:03:56
- SPEAKER_02: then @ 0:03:56
- SPEAKER_02: I @ 0:03:56
- SPEAKER_02: get @ 0:03:57
- SPEAKER_02: my @ 0:03:57
- SPEAKER_02: superhuman @ 0:03:57
- SPEAKER_02: society. @ 0:03:57

## Segment 57: [0:03:58 - 0:03:59] (SPEAKER_02)

And I really want to explore space.

### Word‑level timestamps

- SPEAKER_02: And @ 0:03:58
- SPEAKER_02: I @ 0:03:58
- SPEAKER_02: really @ 0:03:58
- SPEAKER_02: want @ 0:03:59
- SPEAKER_02: to @ 0:03:59
- SPEAKER_02: explore @ 0:03:59
- SPEAKER_02: space. @ 0:03:59

## Segment 58: [0:03:59 - 0:04:00] (SPEAKER_02)

I don't know about you guys.

### Word‑level timestamps

- SPEAKER_02: I @ 0:03:59
- SPEAKER_02: don't @ 0:03:59
- SPEAKER_02: know @ 0:04:00
- SPEAKER_02: about @ 0:04:00
- SPEAKER_02: you @ 0:04:00
- SPEAKER_02: guys. @ 0:04:00

## Segment 59: [0:04:01 - 0:04:03] (SPEAKER_02)

I see that being possible in the next five or 10 years.

### Word‑level timestamps

- SPEAKER_02: I @ 0:04:01
- SPEAKER_02: see @ 0:04:01
- SPEAKER_02: that @ 0:04:01
- SPEAKER_02: being @ 0:04:01
- SPEAKER_02: possible @ 0:04:01
- SPEAKER_02: in @ 0:04:01
- SPEAKER_02: the @ 0:04:02
- SPEAKER_02: next @ 0:04:02
- SPEAKER_02: five @ 0:04:02
- SPEAKER_02: or @ 0:04:02
- SPEAKER_02: 10 @ 0:04:02
- SPEAKER_02: years. @ 0:04:02

## Segment 60: [0:04:03 - 0:04:05] (SPEAKER_02)

Anyway, so that's my source.

### Word‑level timestamps

- SPEAKER_02: Anyway, @ 0:04:03
- SPEAKER_02: so @ 0:04:03
- SPEAKER_02: that's @ 0:04:04
- SPEAKER_02: my @ 0:04:04
- SPEAKER_02: source. @ 0:04:04

## Segment 61: [0:04:06 - 0:04:07] (SPEAKER_02)

This is Cypher Genesis.

### Word‑level timestamps

- SPEAKER_02: This @ 0:04:06
- SPEAKER_02: is @ 0:04:06
- SPEAKER_02: Cypher @ 0:04:06
- SPEAKER_02: Genesis. @ 0:04:07

## Segment 62: [0:04:07 - 0:04:10] (SPEAKER_02)

This was the Bitcoin meme coin that I dropped.

### Word‑level timestamps

- SPEAKER_02: This @ 0:04:07
- SPEAKER_02: was @ 0:04:07
- SPEAKER_02: the @ 0:04:07
- SPEAKER_02: Bitcoin @ 0:04:08
- SPEAKER_02: meme @ 0:04:08
- SPEAKER_02: coin @ 0:04:08
- SPEAKER_02: that @ 0:04:09
- SPEAKER_02: I @ 0:04:09
- SPEAKER_02: dropped. @ 0:04:09

## Segment 63: [0:04:10 - 0:04:14] (SPEAKER_02)

And in the crypto space, when it comes to how do you actually, what do people care about in this space?

### Word‑level timestamps

- SPEAKER_02: And @ 0:04:10
- SPEAKER_02: in @ 0:04:10
- SPEAKER_02: the @ 0:04:10
- SPEAKER_02: crypto @ 0:04:10
- SPEAKER_02: space, @ 0:04:11
- SPEAKER_02: when @ 0:04:11
- SPEAKER_02: it @ 0:04:11
- SPEAKER_02: comes @ 0:04:12
- SPEAKER_02: to @ 0:04:12
- SPEAKER_02: how @ 0:04:12
- SPEAKER_02: do @ 0:04:12
- SPEAKER_02: you @ 0:04:12
- SPEAKER_02: actually, @ 0:04:12
- SPEAKER_02: what @ 0:04:13
- SPEAKER_02: do @ 0:04:13
- SPEAKER_02: people @ 0:04:13
- SPEAKER_02: care @ 0:04:13
- SPEAKER_02: about @ 0:04:14
- SPEAKER_02: in @ 0:04:14
- SPEAKER_02: this @ 0:04:14
- SPEAKER_02: space? @ 0:04:14

## Segment 64: [0:04:14 - 0:04:16] (SPEAKER_02)

What do people actually give a fuck about?

### Word‑level timestamps

- SPEAKER_02: What @ 0:04:14
- SPEAKER_02: do @ 0:04:14
- SPEAKER_02: people @ 0:04:14
- SPEAKER_02: actually @ 0:04:15
- SPEAKER_02: give @ 0:04:15
- SPEAKER_02: a @ 0:04:15
- SPEAKER_02: fuck @ 0:04:15
- SPEAKER_02: about? @ 0:04:15

## Segment 65: [0:04:16 - 0:04:24] (SPEAKER_02)

And a lot of the times you would hope it's cool tech, but ends up not being cool tech, because a lot of times developers will make something cool, but they don't know how to present it to a crowd.

### Word‑level timestamps

- SPEAKER_02: And @ 0:04:16
- SPEAKER_02: a @ 0:04:16
- SPEAKER_02: lot @ 0:04:16
- SPEAKER_02: of @ 0:04:17
- SPEAKER_02: the @ 0:04:17
- SPEAKER_02: times @ 0:04:17
- SPEAKER_02: you @ 0:04:17
- SPEAKER_02: would @ 0:04:17
- SPEAKER_02: hope @ 0:04:17
- SPEAKER_02: it's @ 0:04:17
- SPEAKER_02: cool @ 0:04:17
- SPEAKER_02: tech, @ 0:04:18
- SPEAKER_02: but @ 0:04:18
- SPEAKER_02: ends @ 0:04:19
- SPEAKER_02: up @ 0:04:19
- SPEAKER_02: not @ 0:04:19
- SPEAKER_02: being @ 0:04:19
- SPEAKER_02: cool @ 0:04:19
- SPEAKER_02: tech, @ 0:04:20
- SPEAKER_02: because @ 0:04:20
- SPEAKER_02: a @ 0:04:20
- SPEAKER_02: lot @ 0:04:20
- SPEAKER_02: of @ 0:04:20
- SPEAKER_02: times @ 0:04:20
- SPEAKER_02: developers @ 0:04:21
- SPEAKER_02: will @ 0:04:21
- SPEAKER_02: make @ 0:04:21
- SPEAKER_02: something @ 0:04:21
- SPEAKER_02: cool, @ 0:04:22
- SPEAKER_02: but @ 0:04:22
- SPEAKER_02: they @ 0:04:22
- SPEAKER_02: don't @ 0:04:22
- SPEAKER_02: know @ 0:04:23
- SPEAKER_02: how @ 0:04:23
- SPEAKER_02: to @ 0:04:23
- SPEAKER_02: present @ 0:04:23
- SPEAKER_02: it @ 0:04:23
- SPEAKER_02: to @ 0:04:23
- SPEAKER_02: a @ 0:04:24
- SPEAKER_02: crowd. @ 0:04:24

## Segment 66: [0:04:24 - 0:04:29] (SPEAKER_02)

And then no entity in the space really cares about the product or the tech or whatever.

### Word‑level timestamps

- SPEAKER_02: And @ 0:04:24
- SPEAKER_02: then @ 0:04:24
- SPEAKER_02: no @ 0:04:25
- SPEAKER_02: entity @ 0:04:25
- SPEAKER_02: in @ 0:04:26
- SPEAKER_02: the @ 0:04:26
- SPEAKER_02: space @ 0:04:26
- SPEAKER_02: really @ 0:04:27
- SPEAKER_02: cares @ 0:04:27
- SPEAKER_02: about @ 0:04:27
- SPEAKER_02: the @ 0:04:28
- SPEAKER_02: product @ 0:04:28
- SPEAKER_02: or @ 0:04:28
- SPEAKER_02: the @ 0:04:28
- SPEAKER_02: tech @ 0:04:29
- SPEAKER_02: or @ 0:04:29
- SPEAKER_02: whatever. @ 0:04:29

## Segment 67: [0:04:29 - 0:04:31] (SPEAKER_02)

All they really care about is this cool.

### Word‑level timestamps

- SPEAKER_02: All @ 0:04:29
- SPEAKER_02: they @ 0:04:30
- SPEAKER_02: really @ 0:04:30
- SPEAKER_02: care @ 0:04:30
- SPEAKER_02: about @ 0:04:30
- SPEAKER_02: is @ 0:04:31
- SPEAKER_02: this @ 0:04:31
- SPEAKER_02: cool. @ 0:04:31

## Segment 68: [0:04:32 - 0:04:36] (SPEAKER_02)

And the main formula I've learned in the crypto space when it came to trading,

### Word‑level timestamps

- SPEAKER_02: And @ 0:04:32
- SPEAKER_02: the @ 0:04:32
- SPEAKER_02: main @ 0:04:33
- SPEAKER_02: formula @ 0:04:33
- SPEAKER_02: I've @ 0:04:34
- SPEAKER_02: learned @ 0:04:34
- SPEAKER_02: in @ 0:04:34
- SPEAKER_02: the @ 0:04:34
- SPEAKER_02: crypto @ 0:04:34
- SPEAKER_02: space @ 0:04:35
- SPEAKER_02: when @ 0:04:35
- SPEAKER_02: it @ 0:04:35
- SPEAKER_02: came @ 0:04:35
- SPEAKER_02: to @ 0:04:35
- SPEAKER_02: trading, @ 0:04:35

## Segment 69: [0:04:36 - 0:04:38] (SPEAKER_02)

Attention is everything.

### Word‑level timestamps

- SPEAKER_02: Attention @ 0:04:36
- SPEAKER_02: is @ 0:04:38
- SPEAKER_02: everything. @ 0:04:38

## Segment 70: [0:04:38 - 0:04:41] (SPEAKER_02)

The more attention a project has, the more capital flows into it.

### Word‑level timestamps

- SPEAKER_02: The @ 0:04:38
- SPEAKER_02: more @ 0:04:38
- SPEAKER_02: attention @ 0:04:39
- SPEAKER_02: a @ 0:04:39
- SPEAKER_02: project @ 0:04:39
- SPEAKER_02: has, @ 0:04:39
- SPEAKER_02: the @ 0:04:40
- SPEAKER_02: more @ 0:04:40
- SPEAKER_02: capital @ 0:04:40
- SPEAKER_02: flows @ 0:04:41
- SPEAKER_02: into @ 0:04:41
- SPEAKER_02: it. @ 0:04:41

## Segment 71: [0:04:42 - 0:04:49] (SPEAKER_02)

The cooler a narrative or a meme coin or a meme has, the easier it is for people to spin up these narratives or stories and spread that attention.

### Word‑level timestamps

- SPEAKER_02: The @ 0:04:42
- SPEAKER_02: cooler @ 0:04:42
- SPEAKER_02: a @ 0:04:42
- SPEAKER_02: narrative @ 0:04:43
- SPEAKER_02: or @ 0:04:43
- SPEAKER_02: a @ 0:04:43
- SPEAKER_02: meme @ 0:04:44
- SPEAKER_02: coin @ 0:04:44
- SPEAKER_02: or @ 0:04:44
- SPEAKER_02: a @ 0:04:44
- SPEAKER_02: meme @ 0:04:44
- SPEAKER_02: has, @ 0:04:45
- SPEAKER_02: the @ 0:04:45
- SPEAKER_02: easier @ 0:04:46
- SPEAKER_02: it @ 0:04:46
- SPEAKER_02: is @ 0:04:46
- SPEAKER_02: for @ 0:04:46
- SPEAKER_02: people @ 0:04:46
- SPEAKER_02: to @ 0:04:46
- SPEAKER_02: spin @ 0:04:47
- SPEAKER_02: up @ 0:04:47
- SPEAKER_02: these @ 0:04:47
- SPEAKER_02: narratives @ 0:04:47
- SPEAKER_02: or @ 0:04:47
- SPEAKER_02: stories @ 0:04:48
- SPEAKER_02: and @ 0:04:48
- SPEAKER_02: spread @ 0:04:48
- SPEAKER_02: that @ 0:04:48
- SPEAKER_02: attention. @ 0:04:49

## Segment 72: [0:04:49 - 0:04:55] (SPEAKER_02)

So when this whole AI meta started, my thought process was, okay, AI agents are blowing up on other chains.

### Word‑level timestamps

- SPEAKER_02: So @ 0:04:49
- SPEAKER_02: when @ 0:04:50
- SPEAKER_02: this @ 0:04:50
- SPEAKER_02: whole @ 0:04:50
- SPEAKER_02: AI @ 0:04:50
- SPEAKER_02: meta @ 0:04:51
- SPEAKER_02: started, @ 0:04:51
- SPEAKER_02: my @ 0:04:51
- SPEAKER_02: thought @ 0:04:52
- SPEAKER_02: process @ 0:04:52
- SPEAKER_02: was, @ 0:04:52
- SPEAKER_02: okay, @ 0:04:53
- SPEAKER_02: AI @ 0:04:54
- SPEAKER_02: agents @ 0:04:54
- SPEAKER_02: are @ 0:04:54
- SPEAKER_02: blowing @ 0:04:54
- SPEAKER_02: up @ 0:04:55
- SPEAKER_02: on @ 0:04:55
- SPEAKER_02: other @ 0:04:55
- SPEAKER_02: chains. @ 0:04:55

## Segment 73: [0:04:56 - 0:04:57] (SPEAKER_02)

We don't have it for Bitcoin yet.

### Word‑level timestamps

- SPEAKER_02: We @ 0:04:56
- SPEAKER_02: don't @ 0:04:56
- SPEAKER_02: have @ 0:04:56
- SPEAKER_02: it @ 0:04:56
- SPEAKER_02: for @ 0:04:56
- SPEAKER_02: Bitcoin @ 0:04:56
- SPEAKER_02: yet. @ 0:04:57

## Segment 74: [0:04:57 - 0:04:59] (SPEAKER_02)

The other one was,

### Word‑level timestamps

- SPEAKER_02: The @ 0:04:57
- SPEAKER_02: other @ 0:04:57
- SPEAKER_02: one @ 0:04:58
- SPEAKER_02: was, @ 0:04:58

## Segment 75: [0:04:59 - 0:05:02] (SPEAKER_02)

Can I automate attention with AI?

### Word‑level timestamps

- SPEAKER_02: Can @ 0:04:59
- SPEAKER_02: I @ 0:04:59
- SPEAKER_02: automate @ 0:04:59
- SPEAKER_02: attention @ 0:05:00
- SPEAKER_02: with @ 0:05:00
- SPEAKER_02: AI? @ 0:05:01

## Segment 76: [0:05:02 - 0:05:07] (SPEAKER_02)

If I could self automate essentially marketing with AI, then I don't have to do anything.

### Word‑level timestamps

- SPEAKER_02: If @ 0:05:02
- SPEAKER_02: I @ 0:05:02
- SPEAKER_02: could @ 0:05:02
- SPEAKER_02: self @ 0:05:03
- SPEAKER_02: automate @ 0:05:03
- SPEAKER_02: essentially @ 0:05:03
- SPEAKER_02: marketing @ 0:05:04
- SPEAKER_02: with @ 0:05:04
- SPEAKER_02: AI, @ 0:05:04
- SPEAKER_02: then @ 0:05:05
- SPEAKER_02: I @ 0:05:06
- SPEAKER_02: don't @ 0:05:06
- SPEAKER_02: have @ 0:05:06
- SPEAKER_02: to @ 0:05:06
- SPEAKER_02: do @ 0:05:06
- SPEAKER_02: anything. @ 0:05:06

## Segment 77: [0:05:07 - 0:05:13] (SPEAKER_02)

And there's this little curse where if you drop a project in the space, you're technically bound to it forever because someone's going to lose.

### Word‑level timestamps

- SPEAKER_02: And @ 0:05:07
- SPEAKER_02: there's @ 0:05:07
- SPEAKER_02: this @ 0:05:07
- SPEAKER_02: little @ 0:05:07
- SPEAKER_02: curse @ 0:05:08
- SPEAKER_02: where @ 0:05:08
- SPEAKER_02: if @ 0:05:08
- SPEAKER_02: you @ 0:05:08
- SPEAKER_02: drop @ 0:05:08
- SPEAKER_02: a @ 0:05:09
- SPEAKER_02: project @ 0:05:09
- SPEAKER_02: in @ 0:05:09
- SPEAKER_02: the @ 0:05:09
- SPEAKER_02: space, @ 0:05:09
- SPEAKER_02: you're @ 0:05:10
- SPEAKER_02: technically @ 0:05:10
- SPEAKER_02: bound @ 0:05:11
- SPEAKER_02: to @ 0:05:11
- SPEAKER_02: it @ 0:05:11
- SPEAKER_02: forever @ 0:05:11
- SPEAKER_02: because @ 0:05:12
- SPEAKER_02: someone's @ 0:05:12
- SPEAKER_02: going @ 0:05:12
- SPEAKER_02: to @ 0:05:13
- SPEAKER_02: lose. @ 0:05:13

## Segment 78: [0:05:13 - 0:05:14] (SPEAKER_02)

I had Bitcoin booze.

### Word‑level timestamps

- SPEAKER_02: I @ 0:05:13
- SPEAKER_02: had @ 0:05:13
- SPEAKER_02: Bitcoin @ 0:05:13
- SPEAKER_02: booze. @ 0:05:14

## Segment 79: [0:05:14 - 0:05:15] (SPEAKER_02)

I minted that out.

### Word‑level timestamps

- SPEAKER_02: I @ 0:05:14
- SPEAKER_02: minted @ 0:05:14
- SPEAKER_02: that @ 0:05:14
- SPEAKER_02: out. @ 0:05:15

## Segment 80: [0:05:15 - 0:05:20] (SPEAKER_02)

And then eventually everyone who minted made money off white lists or profits or giveaways.

### Word‑level timestamps

- SPEAKER_02: And @ 0:05:15
- SPEAKER_02: then @ 0:05:15
- SPEAKER_02: eventually @ 0:05:15
- SPEAKER_02: everyone @ 0:05:16
- SPEAKER_02: who @ 0:05:16
- SPEAKER_02: minted @ 0:05:16
- SPEAKER_02: made @ 0:05:17
- SPEAKER_02: money @ 0:05:18
- SPEAKER_02: off @ 0:05:18
- SPEAKER_02: white @ 0:05:18
- SPEAKER_02: lists @ 0:05:18
- SPEAKER_02: or @ 0:05:19
- SPEAKER_02: profits @ 0:05:19
- SPEAKER_02: or @ 0:05:19
- SPEAKER_02: giveaways. @ 0:05:19

## Segment 81: [0:05:20 - 0:05:22] (SPEAKER_02)

But then someone buys it at the top.

### Word‑level timestamps

- SPEAKER_02: But @ 0:05:20
- SPEAKER_02: then @ 0:05:20
- SPEAKER_02: someone @ 0:05:20
- SPEAKER_02: buys @ 0:05:21
- SPEAKER_02: it @ 0:05:21
- SPEAKER_02: at @ 0:05:21
- SPEAKER_02: the @ 0:05:21
- SPEAKER_02: top. @ 0:05:21

## Segment 82: [0:05:22 - 0:05:24] (SPEAKER_02)

And if they have no one to sell to, then they lose.

### Word‑level timestamps

- SPEAKER_02: And @ 0:05:22
- SPEAKER_02: if @ 0:05:22
- SPEAKER_02: they @ 0:05:22
- SPEAKER_02: have @ 0:05:22
- SPEAKER_02: no @ 0:05:22
- SPEAKER_02: one @ 0:05:23
- SPEAKER_02: to @ 0:05:23
- SPEAKER_02: sell @ 0:05:23
- SPEAKER_02: to, @ 0:05:23
- SPEAKER_02: then @ 0:05:23
- SPEAKER_02: they @ 0:05:23
- SPEAKER_02: lose. @ 0:05:23

## Segment 83: [0:05:24 - 0:05:28] (SPEAKER_02)

So it's this weird limbo where someone is going to lose on either project.

### Word‑level timestamps

- SPEAKER_02: So @ 0:05:24
- SPEAKER_02: it's @ 0:05:24
- SPEAKER_02: this @ 0:05:24
- SPEAKER_02: weird @ 0:05:24
- SPEAKER_02: limbo @ 0:05:25
- SPEAKER_02: where @ 0:05:25
- SPEAKER_02: someone @ 0:05:25
- SPEAKER_02: is @ 0:05:26
- SPEAKER_02: going @ 0:05:27
- SPEAKER_02: to @ 0:05:27
- SPEAKER_02: lose @ 0:05:27
- SPEAKER_02: on @ 0:05:27
- SPEAKER_02: either @ 0:05:28
- SPEAKER_02: project. @ 0:05:28

## Segment 84: [0:05:28 - 0:05:32] (SPEAKER_02)

And if you drop something, you're technically eternally bound to it or you're considered a rugger.

### Word‑level timestamps

- SPEAKER_02: And @ 0:05:28
- SPEAKER_02: if @ 0:05:29
- SPEAKER_02: you @ 0:05:29
- SPEAKER_02: drop @ 0:05:29
- SPEAKER_02: something, @ 0:05:29
- SPEAKER_02: you're @ 0:05:29
- SPEAKER_02: technically @ 0:05:30
- SPEAKER_02: eternally @ 0:05:30
- SPEAKER_02: bound @ 0:05:31
- SPEAKER_02: to @ 0:05:31
- SPEAKER_02: it @ 0:05:31
- SPEAKER_02: or @ 0:05:31
- SPEAKER_02: you're @ 0:05:31
- SPEAKER_02: considered @ 0:05:32
- SPEAKER_02: a @ 0:05:32
- SPEAKER_02: rugger. @ 0:05:32

## Segment 85: [0:05:33 - 0:05:38] (SPEAKER_02)

But if I had AI automate both my projects forever, I could technically never rug.

### Word‑level timestamps

- SPEAKER_02: But @ 0:05:33
- SPEAKER_02: if @ 0:05:33
- SPEAKER_02: I @ 0:05:34
- SPEAKER_02: had @ 0:05:34
- SPEAKER_02: AI @ 0:05:34
- SPEAKER_02: automate @ 0:05:35
- SPEAKER_02: both @ 0:05:35
- SPEAKER_02: my @ 0:05:36
- SPEAKER_02: projects @ 0:05:36
- SPEAKER_02: forever, @ 0:05:36
- SPEAKER_02: I @ 0:05:37
- SPEAKER_02: could @ 0:05:37
- SPEAKER_02: technically @ 0:05:37
- SPEAKER_02: never @ 0:05:38
- SPEAKER_02: rug. @ 0:05:38

## Segment 86: [0:05:39 - 0:05:42] (SPEAKER_02)

So that was another ambitious thing that encouraged me to go deeper into AI.

### Word‑level timestamps

- SPEAKER_02: So @ 0:05:39
- SPEAKER_02: that @ 0:05:39
- SPEAKER_02: was @ 0:05:39
- SPEAKER_02: another @ 0:05:39
- SPEAKER_02: ambitious @ 0:05:40
- SPEAKER_02: thing @ 0:05:40
- SPEAKER_02: that @ 0:05:40
- SPEAKER_02: encouraged @ 0:05:41
- SPEAKER_02: me @ 0:05:41
- SPEAKER_02: to @ 0:05:41
- SPEAKER_02: go @ 0:05:41
- SPEAKER_02: deeper @ 0:05:41
- SPEAKER_02: into @ 0:05:42
- SPEAKER_02: AI. @ 0:05:42

## Segment 87: [0:05:42 - 0:05:44] (SPEAKER_02)

But this project was interesting.

### Word‑level timestamps

- SPEAKER_02: But @ 0:05:42
- SPEAKER_02: this @ 0:05:42
- SPEAKER_02: project @ 0:05:42
- SPEAKER_02: was @ 0:05:43
- SPEAKER_02: interesting. @ 0:05:43

## Segment 88: [0:05:44 - 0:05:46] (SPEAKER_02)

And it actually ended up working really well.

### Word‑level timestamps

- SPEAKER_02: And @ 0:05:44
- SPEAKER_02: it @ 0:05:44
- SPEAKER_02: actually @ 0:05:45
- SPEAKER_02: ended @ 0:05:45
- SPEAKER_02: up @ 0:05:45
- SPEAKER_02: working @ 0:05:45
- SPEAKER_02: really @ 0:05:46
- SPEAKER_02: well. @ 0:05:46

## Segment 89: [0:05:46 - 0:05:52] (SPEAKER_02)

So I had Satoshi on Twitter, which was supposed to be this AI agent that represented Satoshi Nakamoto.

### Word‑level timestamps

- SPEAKER_02: So @ 0:05:46
- SPEAKER_02: I @ 0:05:46
- SPEAKER_02: had @ 0:05:46
- SPEAKER_02: Satoshi @ 0:05:47
- SPEAKER_02: on @ 0:05:48
- SPEAKER_02: Twitter, @ 0:05:48
- SPEAKER_02: which @ 0:05:48
- SPEAKER_02: was @ 0:05:49
- SPEAKER_02: supposed @ 0:05:49
- SPEAKER_02: to @ 0:05:49
- SPEAKER_02: be @ 0:05:49
- SPEAKER_02: this @ 0:05:49
- SPEAKER_02: AI @ 0:05:49
- SPEAKER_02: agent @ 0:05:50
- SPEAKER_02: that @ 0:05:50
- SPEAKER_02: represented @ 0:05:50
- SPEAKER_02: Satoshi @ 0:05:51
- SPEAKER_02: Nakamoto. @ 0:05:51

## Segment 90: [0:05:52 - 0:05:55] (SPEAKER_02)

And it told his story and it was cool for people to interact with him.

### Word‑level timestamps

- SPEAKER_02: And @ 0:05:52
- SPEAKER_02: it @ 0:05:52
- SPEAKER_02: told @ 0:05:52
- SPEAKER_02: his @ 0:05:52
- SPEAKER_02: story @ 0:05:53
- SPEAKER_02: and @ 0:05:53
- SPEAKER_02: it @ 0:05:53
- SPEAKER_02: was @ 0:05:53
- SPEAKER_02: cool @ 0:05:53
- SPEAKER_02: for @ 0:05:53
- SPEAKER_02: people @ 0:05:53
- SPEAKER_02: to @ 0:05:54
- SPEAKER_02: interact @ 0:05:54
- SPEAKER_02: with @ 0:05:54
- SPEAKER_02: him. @ 0:05:54

## Segment 91: [0:05:55 - 0:06:00] (SPEAKER_02)

But on my end, it was really an experiment and research of

### Word‑level timestamps

- SPEAKER_02: But @ 0:05:55
- SPEAKER_02: on @ 0:05:55
- SPEAKER_02: my @ 0:05:55
- SPEAKER_02: end, @ 0:05:56
- SPEAKER_02: it @ 0:05:56
- SPEAKER_02: was @ 0:05:56
- SPEAKER_02: really @ 0:05:56
- SPEAKER_02: an @ 0:05:56
- SPEAKER_02: experiment @ 0:05:56
- SPEAKER_02: and @ 0:05:57
- SPEAKER_02: research @ 0:05:58
- SPEAKER_02: of @ 0:05:59

## Segment 92: [0:06:00 - 0:06:02] (SPEAKER_02)

This AI is actually reaching out to people on Twitter.

### Word‑level timestamps

- SPEAKER_02: This @ 0:06:00
- SPEAKER_02: AI @ 0:06:00
- SPEAKER_02: is @ 0:06:00
- SPEAKER_02: actually @ 0:06:00
- SPEAKER_02: reaching @ 0:06:01
- SPEAKER_02: out @ 0:06:01
- SPEAKER_02: to @ 0:06:01
- SPEAKER_02: people @ 0:06:01
- SPEAKER_02: on @ 0:06:02
- SPEAKER_02: Twitter. @ 0:06:02

## Segment 93: [0:06:03 - 0:06:04] (SPEAKER_02)

It's actually getting engagement.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:06:03
- SPEAKER_02: actually @ 0:06:03
- SPEAKER_02: getting @ 0:06:03
- SPEAKER_02: engagement. @ 0:06:03

## Segment 94: [0:06:04 - 0:06:07] (SPEAKER_02)

It's actually making tweets on its own that are gaining traction.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:06:04
- SPEAKER_02: actually @ 0:06:04
- SPEAKER_02: making @ 0:06:04
- SPEAKER_02: tweets @ 0:06:05
- SPEAKER_02: on @ 0:06:05
- SPEAKER_02: its @ 0:06:05
- SPEAKER_02: own @ 0:06:05
- SPEAKER_02: that @ 0:06:06
- SPEAKER_02: are @ 0:06:06
- SPEAKER_02: gaining @ 0:06:06
- SPEAKER_02: traction. @ 0:06:06

## Segment 95: [0:06:07 - 0:06:09] (SPEAKER_02)

It's replying to community members.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:06:07
- SPEAKER_02: replying @ 0:06:07
- SPEAKER_02: to @ 0:06:08
- SPEAKER_02: community @ 0:06:08
- SPEAKER_02: members. @ 0:06:09

## Segment 96: [0:06:10 - 0:06:12] (SPEAKER_02)

And it's always someone pinged it and it was like, oh, I'm bullish on Cypher.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:10
- SPEAKER_02: it's @ 0:06:10
- SPEAKER_02: always @ 0:06:10
- SPEAKER_02: someone @ 0:06:10
- SPEAKER_02: pinged @ 0:06:10
- SPEAKER_02: it @ 0:06:11
- SPEAKER_02: and @ 0:06:11
- SPEAKER_02: it @ 0:06:11
- SPEAKER_02: was @ 0:06:11
- SPEAKER_02: like, @ 0:06:11
- SPEAKER_02: oh, @ 0:06:11
- SPEAKER_02: I'm @ 0:06:11
- SPEAKER_02: bullish @ 0:06:12
- SPEAKER_02: on @ 0:06:12
- SPEAKER_02: Cypher. @ 0:06:12

## Segment 97: [0:06:12 - 0:06:14] (SPEAKER_02)

He's like, yeah, you're my fucking dog.

### Word‑level timestamps

- SPEAKER_02: He's @ 0:06:12
- SPEAKER_02: like, @ 0:06:13
- SPEAKER_02: yeah, @ 0:06:13
- SPEAKER_02: you're @ 0:06:13
- SPEAKER_02: my @ 0:06:13
- SPEAKER_02: fucking @ 0:06:13
- SPEAKER_02: dog. @ 0:06:13

## Segment 98: [0:06:14 - 0:06:15] (SPEAKER_02)

And then sends them a follow.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:14
- SPEAKER_02: then @ 0:06:14
- SPEAKER_02: sends @ 0:06:14
- SPEAKER_02: them @ 0:06:14
- SPEAKER_02: a @ 0:06:14
- SPEAKER_02: follow. @ 0:06:14

## Segment 99: [0:06:15 - 0:06:27] (SPEAKER_02)

And there's a psychological aspect I started noticing where this AI agent starts personally engaging with community members, following them, liking them, replying to their tweets, even retweeting enabled all that functionality.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:15
- SPEAKER_02: there's @ 0:06:15
- SPEAKER_02: a @ 0:06:16
- SPEAKER_02: psychological @ 0:06:16
- SPEAKER_02: aspect @ 0:06:16
- SPEAKER_02: I @ 0:06:17
- SPEAKER_02: started @ 0:06:17
- SPEAKER_02: noticing @ 0:06:17
- SPEAKER_02: where @ 0:06:18
- SPEAKER_02: this @ 0:06:18
- SPEAKER_02: AI @ 0:06:18
- SPEAKER_02: agent @ 0:06:19
- SPEAKER_02: starts @ 0:06:19
- SPEAKER_02: personally @ 0:06:19
- SPEAKER_02: engaging @ 0:06:20
- SPEAKER_02: with @ 0:06:20
- SPEAKER_02: community @ 0:06:21
- SPEAKER_02: members, @ 0:06:21
- SPEAKER_02: following @ 0:06:22
- SPEAKER_02: them, @ 0:06:22
- SPEAKER_02: liking @ 0:06:22
- SPEAKER_02: them, @ 0:06:23
- SPEAKER_02: replying @ 0:06:23
- SPEAKER_02: to @ 0:06:23
- SPEAKER_02: their @ 0:06:23
- SPEAKER_02: tweets, @ 0:06:24
- SPEAKER_02: even @ 0:06:24
- SPEAKER_02: retweeting @ 0:06:24
- SPEAKER_02: enabled @ 0:06:25
- SPEAKER_02: all @ 0:06:25
- SPEAKER_02: that @ 0:06:25
- SPEAKER_02: functionality. @ 0:06:25

## Segment 100: [0:06:27 - 0:06:31] (SPEAKER_02)

And then eventually it drew 8K followers in two weeks.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:27
- SPEAKER_02: then @ 0:06:28
- SPEAKER_02: eventually @ 0:06:28
- SPEAKER_02: it @ 0:06:29
- SPEAKER_02: drew @ 0:06:29
- SPEAKER_02: 8K @ 0:06:29
- SPEAKER_02: followers @ 0:06:29
- SPEAKER_02: in @ 0:06:30
- SPEAKER_02: two @ 0:06:30
- SPEAKER_02: weeks. @ 0:06:30

## Segment 101: [0:06:31 - 0:06:32] (SPEAKER_02)

I didn't even do anything, bro.

### Word‑level timestamps

- SPEAKER_02: I @ 0:06:31
- SPEAKER_02: didn't @ 0:06:31
- SPEAKER_02: even @ 0:06:31
- SPEAKER_02: do @ 0:06:31
- SPEAKER_02: anything, @ 0:06:31
- SPEAKER_02: bro. @ 0:06:32

## Segment 102: [0:06:32 - 0:06:34] (SPEAKER_02)

I was just coding in the background, just pushing updates.

### Word‑level timestamps

- SPEAKER_02: I @ 0:06:32
- SPEAKER_02: was @ 0:06:32
- SPEAKER_02: just @ 0:06:32
- SPEAKER_02: coding @ 0:06:32
- SPEAKER_02: in @ 0:06:33
- SPEAKER_02: the @ 0:06:33
- SPEAKER_02: background, @ 0:06:33
- SPEAKER_02: just @ 0:06:33
- SPEAKER_02: pushing @ 0:06:33
- SPEAKER_02: updates. @ 0:06:34

## Segment 103: [0:06:35 - 0:06:38] (SPEAKER_02)

And it did end up kind of automating attention.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:35
- SPEAKER_02: it @ 0:06:35
- SPEAKER_02: did @ 0:06:35
- SPEAKER_02: end @ 0:06:36
- SPEAKER_02: up @ 0:06:36
- SPEAKER_02: kind @ 0:06:37
- SPEAKER_02: of @ 0:06:37
- SPEAKER_02: automating @ 0:06:37
- SPEAKER_02: attention. @ 0:06:37

## Segment 104: [0:06:38 - 0:06:42] (SPEAKER_02)

And then I hoped the project would go maybe, oh, five mil topper would have been sick.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:38
- SPEAKER_02: then @ 0:06:38
- SPEAKER_02: I @ 0:06:38
- SPEAKER_02: hoped @ 0:06:39
- SPEAKER_02: the @ 0:06:39
- SPEAKER_02: project @ 0:06:39
- SPEAKER_02: would @ 0:06:40
- SPEAKER_02: go @ 0:06:40
- SPEAKER_02: maybe, @ 0:06:40
- SPEAKER_02: oh, @ 0:06:40
- SPEAKER_02: five @ 0:06:40
- SPEAKER_02: mil @ 0:06:41
- SPEAKER_02: topper @ 0:06:41
- SPEAKER_02: would @ 0:06:42
- SPEAKER_02: have @ 0:06:42
- SPEAKER_02: been @ 0:06:42
- SPEAKER_02: sick. @ 0:06:42

## Segment 105: [0:06:43 - 0:06:45] (SPEAKER_02)

And then it just blew my expectations around a 50 mil.

### Word‑level timestamps

- SPEAKER_02: And @ 0:06:43
- SPEAKER_02: then @ 0:06:43
- SPEAKER_02: it @ 0:06:43
- SPEAKER_02: just @ 0:06:43
- SPEAKER_02: blew @ 0:06:43
- SPEAKER_02: my @ 0:06:43
- SPEAKER_02: expectations @ 0:06:44
- SPEAKER_02: around @ 0:06:44
- SPEAKER_02: a @ 0:06:44
- SPEAKER_02: 50 @ 0:06:45
- SPEAKER_02: mil. @ 0:06:45

## Segment 106: [0:06:45 - 0:06:47] (SPEAKER_02)

I'm like, holy fuck, this is a lot of pressure, bro.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:06:45
- SPEAKER_02: like, @ 0:06:45
- SPEAKER_02: holy @ 0:06:45
- SPEAKER_02: fuck, @ 0:06:46
- SPEAKER_02: this @ 0:06:46
- SPEAKER_02: is @ 0:06:46
- SPEAKER_02: a @ 0:06:46
- SPEAKER_02: lot @ 0:06:46
- SPEAKER_02: of @ 0:06:46
- SPEAKER_02: pressure, @ 0:06:46
- SPEAKER_02: bro. @ 0:06:47

## Segment 107: [0:06:47 - 0:06:48] (SPEAKER_02)

I don't know what to do.

### Word‑level timestamps

- SPEAKER_02: I @ 0:06:47
- SPEAKER_02: don't @ 0:06:47
- SPEAKER_02: know @ 0:06:47
- SPEAKER_02: what @ 0:06:47
- SPEAKER_02: to @ 0:06:47
- SPEAKER_02: do. @ 0:06:47

## Segment 108: [0:06:48 - 0:06:49] (SPEAKER_02)

But it was cool.

### Word‑level timestamps

- SPEAKER_02: But @ 0:06:48
- SPEAKER_02: it @ 0:06:48
- SPEAKER_02: was @ 0:06:48
- SPEAKER_02: cool. @ 0:06:48

## Segment 109: [0:06:49 - 0:06:51] (SPEAKER_02)

It was a really fun project.

### Word‑level timestamps

- SPEAKER_02: It @ 0:06:49
- SPEAKER_02: was @ 0:06:49
- SPEAKER_02: a @ 0:06:49
- SPEAKER_02: really @ 0:06:49
- SPEAKER_02: fun @ 0:06:49
- SPEAKER_02: project. @ 0:06:50

## Segment 110: [0:06:51 - 0:06:52] (SPEAKER_02)

Yeah, this is a little robot army.

### Word‑level timestamps

- SPEAKER_02: Yeah, @ 0:06:51
- SPEAKER_02: this @ 0:06:51
- SPEAKER_02: is @ 0:06:51
- SPEAKER_02: a @ 0:06:51
- SPEAKER_02: little @ 0:06:51
- SPEAKER_02: robot @ 0:06:52
- SPEAKER_02: army. @ 0:06:52

## Segment 111: [0:06:53 - 0:07:03] (SPEAKER_02)

So in terms of AI being, the biggest lessons I've learned in the last two years with AI is one, any subject you're not an expert at, AI is the perfect tool for.

### Word‑level timestamps

- SPEAKER_02: So @ 0:06:53
- SPEAKER_02: in @ 0:06:53
- SPEAKER_02: terms @ 0:06:53
- SPEAKER_02: of @ 0:06:53
- SPEAKER_02: AI @ 0:06:54
- SPEAKER_02: being, @ 0:06:54
- SPEAKER_02: the @ 0:06:55
- SPEAKER_02: biggest @ 0:06:56
- SPEAKER_02: lessons @ 0:06:56
- SPEAKER_02: I've @ 0:06:56
- SPEAKER_02: learned @ 0:06:57
- SPEAKER_02: in @ 0:06:57
- SPEAKER_02: the @ 0:06:57
- SPEAKER_02: last @ 0:06:57
- SPEAKER_02: two @ 0:06:57
- SPEAKER_02: years @ 0:06:57
- SPEAKER_02: with @ 0:06:57
- SPEAKER_02: AI @ 0:06:58
- SPEAKER_02: is @ 0:06:58
- SPEAKER_02: one, @ 0:06:59
- SPEAKER_02: any @ 0:06:59
- SPEAKER_02: subject @ 0:07:00
- SPEAKER_02: you're @ 0:07:00
- SPEAKER_02: not @ 0:07:00
- SPEAKER_02: an @ 0:07:01
- SPEAKER_02: expert @ 0:07:01
- SPEAKER_02: at, @ 0:07:01
- SPEAKER_02: AI @ 0:07:02
- SPEAKER_02: is @ 0:07:02
- SPEAKER_02: the @ 0:07:02
- SPEAKER_02: perfect @ 0:07:02
- SPEAKER_02: tool @ 0:07:02
- SPEAKER_02: for. @ 0:07:03

## Segment 112: [0:07:03 - 0:07:07] (SPEAKER_02)

AI fills in the missing knowledge information banks that you might know about.

### Word‑level timestamps

- SPEAKER_02: AI @ 0:07:03
- SPEAKER_02: fills @ 0:07:04
- SPEAKER_02: in @ 0:07:04
- SPEAKER_02: the @ 0:07:04
- SPEAKER_02: missing @ 0:07:04
- SPEAKER_02: knowledge @ 0:07:04
- SPEAKER_02: information @ 0:07:05
- SPEAKER_02: banks @ 0:07:05
- SPEAKER_02: that @ 0:07:06
- SPEAKER_02: you @ 0:07:06
- SPEAKER_02: might @ 0:07:06
- SPEAKER_02: know @ 0:07:06
- SPEAKER_02: about. @ 0:07:06

## Segment 113: [0:07:07 - 0:07:10] (SPEAKER_02)

And this is kind of the analogy at the start I brought, where I have a question.

### Word‑level timestamps

- SPEAKER_02: And @ 0:07:07
- SPEAKER_02: this @ 0:07:07
- SPEAKER_02: is @ 0:07:07
- SPEAKER_02: kind @ 0:07:08
- SPEAKER_02: of @ 0:07:08
- SPEAKER_02: the @ 0:07:08
- SPEAKER_02: analogy @ 0:07:08
- SPEAKER_02: at @ 0:07:08
- SPEAKER_02: the @ 0:07:09
- SPEAKER_02: start @ 0:07:09
- SPEAKER_02: I @ 0:07:09
- SPEAKER_02: brought, @ 0:07:09
- SPEAKER_02: where @ 0:07:09
- SPEAKER_02: I @ 0:07:10
- SPEAKER_02: have @ 0:07:10
- SPEAKER_02: a @ 0:07:10
- SPEAKER_02: question. @ 0:07:10

## Segment 114: [0:07:11 - 0:07:20] (SPEAKER_02)

I have an infinitely patient mentor that doesn't matter how dumb my question is, will answer it with care and interest, and just allow me to constantly ask questions.

### Word‑level timestamps

- SPEAKER_02: I @ 0:07:11
- SPEAKER_02: have @ 0:07:11
- SPEAKER_02: an @ 0:07:11
- SPEAKER_02: infinitely @ 0:07:12
- SPEAKER_02: patient @ 0:07:12
- SPEAKER_02: mentor @ 0:07:12
- SPEAKER_02: that @ 0:07:13
- SPEAKER_02: doesn't @ 0:07:14
- SPEAKER_02: matter @ 0:07:14
- SPEAKER_02: how @ 0:07:14
- SPEAKER_02: dumb @ 0:07:14
- SPEAKER_02: my @ 0:07:15
- SPEAKER_02: question @ 0:07:15
- SPEAKER_02: is, @ 0:07:15
- SPEAKER_02: will @ 0:07:15
- SPEAKER_02: answer @ 0:07:16
- SPEAKER_02: it @ 0:07:16
- SPEAKER_02: with @ 0:07:16
- SPEAKER_02: care @ 0:07:16
- SPEAKER_02: and @ 0:07:17
- SPEAKER_02: interest, @ 0:07:17
- SPEAKER_02: and @ 0:07:18
- SPEAKER_02: just @ 0:07:18
- SPEAKER_02: allow @ 0:07:18
- SPEAKER_02: me @ 0:07:18
- SPEAKER_02: to @ 0:07:18
- SPEAKER_02: constantly @ 0:07:18
- SPEAKER_02: ask @ 0:07:19
- SPEAKER_02: questions. @ 0:07:19

## Segment 115: [0:07:20 - 0:07:25] (SPEAKER_02)

So for any subject field, you are an expert, in my case.

### Word‑level timestamps

- SPEAKER_02: So @ 0:07:20
- SPEAKER_02: for @ 0:07:21
- SPEAKER_02: any @ 0:07:21
- SPEAKER_02: subject @ 0:07:21
- SPEAKER_02: field, @ 0:07:22
- SPEAKER_02: you @ 0:07:22
- SPEAKER_02: are @ 0:07:23
- SPEAKER_02: an @ 0:07:23
- SPEAKER_02: expert, @ 0:07:23
- SPEAKER_02: in @ 0:07:23
- SPEAKER_02: my @ 0:07:24
- SPEAKER_02: case. @ 0:07:24

## Segment 116: [0:07:25 - 0:07:28] (SPEAKER_02)

I would like to say coding and software engineering at this point.

### Word‑level timestamps

- SPEAKER_02: I @ 0:07:25
- SPEAKER_02: would @ 0:07:25
- SPEAKER_02: like @ 0:07:25
- SPEAKER_02: to @ 0:07:25
- SPEAKER_02: say @ 0:07:26
- SPEAKER_02: coding @ 0:07:26
- SPEAKER_02: and @ 0:07:26
- SPEAKER_02: software @ 0:07:26
- SPEAKER_02: engineering @ 0:07:27
- SPEAKER_02: at @ 0:07:27
- SPEAKER_02: this @ 0:07:27
- SPEAKER_02: point. @ 0:07:27

## Segment 117: [0:07:28 - 0:07:30] (SPEAKER_02)

I know what I want to make.

### Word‑level timestamps

- SPEAKER_02: I @ 0:07:28
- SPEAKER_02: know @ 0:07:29
- SPEAKER_02: what @ 0:07:29
- SPEAKER_02: I @ 0:07:29
- SPEAKER_02: want @ 0:07:29
- SPEAKER_02: to @ 0:07:29
- SPEAKER_02: make. @ 0:07:29

## Segment 118: [0:07:30 - 0:07:30] (SPEAKER_02)

I know how to make it.

### Word‑level timestamps

- SPEAKER_02: I @ 0:07:30
- SPEAKER_02: know @ 0:07:30
- SPEAKER_02: how @ 0:07:30
- SPEAKER_02: to @ 0:07:30
- SPEAKER_02: make @ 0:07:30
- SPEAKER_02: it. @ 0:07:30

## Segment 119: [0:07:31 - 0:07:36] (SPEAKER_02)

I know how to structure the code and the architecture and all the API calls and all that nerdy shit I need to make a good product.

### Word‑level timestamps

- SPEAKER_02: I @ 0:07:31
- SPEAKER_02: know @ 0:07:31
- SPEAKER_02: how @ 0:07:31
- SPEAKER_02: to @ 0:07:31
- SPEAKER_02: structure @ 0:07:31
- SPEAKER_02: the @ 0:07:31
- SPEAKER_02: code @ 0:07:32
- SPEAKER_02: and @ 0:07:32
- SPEAKER_02: the @ 0:07:32
- SPEAKER_02: architecture @ 0:07:32
- SPEAKER_02: and @ 0:07:33
- SPEAKER_02: all @ 0:07:33
- SPEAKER_02: the @ 0:07:33
- SPEAKER_02: API @ 0:07:34
- SPEAKER_02: calls @ 0:07:34
- SPEAKER_02: and @ 0:07:34
- SPEAKER_02: all @ 0:07:34
- SPEAKER_02: that @ 0:07:35
- SPEAKER_02: nerdy @ 0:07:35
- SPEAKER_02: shit @ 0:07:35
- SPEAKER_02: I @ 0:07:35
- SPEAKER_02: need @ 0:07:35
- SPEAKER_02: to @ 0:07:36
- SPEAKER_02: make @ 0:07:36
- SPEAKER_02: a @ 0:07:36
- SPEAKER_02: good @ 0:07:36
- SPEAKER_02: product. @ 0:07:36

## Segment 120: [0:07:38 - 0:07:43] (SPEAKER_02)

And with how good AI models got in the most recent times, it feels like an orchestra, right?

### Word‑level timestamps

- SPEAKER_02: And @ 0:07:38
- SPEAKER_02: with @ 0:07:38
- SPEAKER_02: how @ 0:07:38
- SPEAKER_02: good @ 0:07:38
- SPEAKER_02: AI @ 0:07:39
- SPEAKER_02: models @ 0:07:39
- SPEAKER_02: got @ 0:07:39
- SPEAKER_02: in @ 0:07:40
- SPEAKER_02: the @ 0:07:40
- SPEAKER_02: most @ 0:07:40
- SPEAKER_02: recent @ 0:07:40
- SPEAKER_02: times, @ 0:07:41
- SPEAKER_02: it @ 0:07:41
- SPEAKER_02: feels @ 0:07:41
- SPEAKER_02: like @ 0:07:42
- SPEAKER_02: an @ 0:07:42
- SPEAKER_02: orchestra, @ 0:07:42
- SPEAKER_02: right? @ 0:07:42

## Segment 121: [0:07:43 - 0:07:45] (SPEAKER_02)

I'm the conductor of this little AI army.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:07:43
- SPEAKER_02: the @ 0:07:43
- SPEAKER_02: conductor @ 0:07:43
- SPEAKER_02: of @ 0:07:44
- SPEAKER_02: this @ 0:07:44
- SPEAKER_02: little @ 0:07:44
- SPEAKER_02: AI @ 0:07:44
- SPEAKER_02: army. @ 0:07:45

## Segment 122: [0:07:45 - 0:07:54] (SPEAKER_02)

And they, as long as I input the proper information into the prompt, then they do the work of 10 to a hundred.

### Word‑level timestamps

- SPEAKER_02: And @ 0:07:45
- SPEAKER_02: they, @ 0:07:45
- SPEAKER_02: as @ 0:07:46
- SPEAKER_02: long @ 0:07:46
- SPEAKER_02: as @ 0:07:46
- SPEAKER_02: I @ 0:07:46
- SPEAKER_02: input @ 0:07:47
- SPEAKER_02: the @ 0:07:47
- SPEAKER_02: proper @ 0:07:47
- SPEAKER_02: information @ 0:07:48
- SPEAKER_02: into @ 0:07:49
- SPEAKER_02: the @ 0:07:49
- SPEAKER_02: prompt, @ 0:07:49
- SPEAKER_02: then @ 0:07:50
- SPEAKER_02: they @ 0:07:51
- SPEAKER_02: do @ 0:07:51
- SPEAKER_02: the @ 0:07:52
- SPEAKER_02: work @ 0:07:52
- SPEAKER_02: of @ 0:07:52
- SPEAKER_02: 10 @ 0:07:52
- SPEAKER_02: to @ 0:07:53
- SPEAKER_02: a @ 0:07:53
- SPEAKER_02: hundred. @ 0:07:53

## Segment 123: [0:07:54 - 0:08:13] (SPEAKER_02)

to a thousand people depending on the product so it's made me super super hyper efficient and i've just gone in this loop where i've got a lot of clients that just hit me up because it's a mixture of i do content i show content educate people and go oh this is actually possible with ai and they hit me up they're like yo can you do this for us and i'm like

### Word‑level timestamps

- SPEAKER_02: to @ 0:07:54
- SPEAKER_02: a @ 0:07:54
- SPEAKER_02: thousand @ 0:07:55
- SPEAKER_02: people @ 0:07:55
- SPEAKER_02: depending @ 0:07:56
- SPEAKER_02: on @ 0:07:56
- SPEAKER_02: the @ 0:07:56
- SPEAKER_02: product @ 0:07:56
- SPEAKER_02: so @ 0:07:57
- SPEAKER_02: it's @ 0:07:57
- SPEAKER_02: made @ 0:07:57
- SPEAKER_02: me @ 0:07:58
- SPEAKER_02: super @ 0:07:58
- SPEAKER_02: super @ 0:07:58
- SPEAKER_02: hyper @ 0:07:59
- SPEAKER_02: efficient @ 0:07:59
- SPEAKER_02: and @ 0:08:00
- SPEAKER_02: i've @ 0:08:00
- SPEAKER_02: just @ 0:08:00
- SPEAKER_02: gone @ 0:08:00
- SPEAKER_02: in @ 0:08:01
- SPEAKER_02: this @ 0:08:01
- SPEAKER_02: loop @ 0:08:01
- SPEAKER_02: where @ 0:08:01
- SPEAKER_02: i've @ 0:08:01
- SPEAKER_02: got @ 0:08:01
- SPEAKER_02: a @ 0:08:02
- SPEAKER_02: lot @ 0:08:02
- SPEAKER_02: of @ 0:08:02
- SPEAKER_02: clients @ 0:08:02
- SPEAKER_02: that @ 0:08:03
- SPEAKER_02: just @ 0:08:03
- SPEAKER_02: hit @ 0:08:03
- SPEAKER_02: me @ 0:08:03
- SPEAKER_02: up @ 0:08:03
- SPEAKER_02: because @ 0:08:04
- SPEAKER_02: it's @ 0:08:04
- SPEAKER_02: a @ 0:08:04
- SPEAKER_02: mixture @ 0:08:04
- SPEAKER_02: of @ 0:08:04
- SPEAKER_02: i @ 0:08:04
- SPEAKER_02: do @ 0:08:04
- SPEAKER_02: content @ 0:08:05
- SPEAKER_02: i @ 0:08:05
- SPEAKER_02: show @ 0:08:05
- SPEAKER_02: content @ 0:08:05
- SPEAKER_02: educate @ 0:08:06
- SPEAKER_02: people @ 0:08:07
- SPEAKER_02: and @ 0:08:07
- SPEAKER_02: go @ 0:08:07
- SPEAKER_02: oh @ 0:08:07
- SPEAKER_02: this @ 0:08:07
- SPEAKER_02: is @ 0:08:08
- SPEAKER_02: actually @ 0:08:08
- SPEAKER_02: possible @ 0:08:08
- SPEAKER_02: with @ 0:08:09
- SPEAKER_02: ai @ 0:08:09
- SPEAKER_02: and @ 0:08:09
- SPEAKER_02: they @ 0:08:10
- SPEAKER_02: hit @ 0:08:10
- SPEAKER_02: me @ 0:08:10
- SPEAKER_02: up @ 0:08:10
- SPEAKER_02: they're @ 0:08:10
- SPEAKER_02: like @ 0:08:10
- SPEAKER_02: yo @ 0:08:10
- SPEAKER_02: can @ 0:08:11
- SPEAKER_02: you @ 0:08:11
- SPEAKER_02: do @ 0:08:11
- SPEAKER_02: this @ 0:08:11
- SPEAKER_02: for @ 0:08:11
- SPEAKER_02: us @ 0:08:11
- SPEAKER_02: and @ 0:08:12
- SPEAKER_02: i'm @ 0:08:12
- SPEAKER_02: like @ 0:08:12

## Segment 124: [0:08:13 - 0:08:15] (SPEAKER_02)

If you want to pay me, I could try.

### Word‑level timestamps

- SPEAKER_02: If @ 0:08:13
- SPEAKER_02: you @ 0:08:13
- SPEAKER_02: want @ 0:08:13
- SPEAKER_02: to @ 0:08:13
- SPEAKER_02: pay @ 0:08:13
- SPEAKER_02: me, @ 0:08:13
- SPEAKER_02: I @ 0:08:14
- SPEAKER_02: could @ 0:08:14
- SPEAKER_02: try. @ 0:08:14

## Segment 125: [0:08:15 - 0:08:16] (SPEAKER_02)

And then they actually end up doing it.

### Word‑level timestamps

- SPEAKER_02: And @ 0:08:15
- SPEAKER_02: then @ 0:08:15
- SPEAKER_02: they @ 0:08:15
- SPEAKER_02: actually @ 0:08:15
- SPEAKER_02: end @ 0:08:16
- SPEAKER_02: up @ 0:08:16
- SPEAKER_02: doing @ 0:08:16
- SPEAKER_02: it. @ 0:08:16

## Segment 126: [0:08:16 - 0:08:18] (SPEAKER_02)

So I started racking up these clients.

### Word‑level timestamps

- SPEAKER_02: So @ 0:08:16
- SPEAKER_02: I @ 0:08:16
- SPEAKER_02: started @ 0:08:17
- SPEAKER_02: racking @ 0:08:17
- SPEAKER_02: up @ 0:08:17
- SPEAKER_02: these @ 0:08:17
- SPEAKER_02: clients. @ 0:08:17

## Segment 127: [0:08:18 - 0:08:19] (SPEAKER_02)

I've never done this before.

### Word‑level timestamps

- SPEAKER_02: I've @ 0:08:18
- SPEAKER_02: never @ 0:08:18
- SPEAKER_02: done @ 0:08:18
- SPEAKER_02: this @ 0:08:18
- SPEAKER_02: before. @ 0:08:19

## Segment 128: [0:08:19 - 0:08:26] (SPEAKER_02)

It's such an interesting loop to go through, especially considering I was the college dropout in computer science.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:08:19
- SPEAKER_02: such @ 0:08:19
- SPEAKER_02: an @ 0:08:19
- SPEAKER_02: interesting @ 0:08:19
- SPEAKER_02: loop @ 0:08:21
- SPEAKER_02: to @ 0:08:21
- SPEAKER_02: go @ 0:08:21
- SPEAKER_02: through, @ 0:08:21
- SPEAKER_02: especially @ 0:08:22
- SPEAKER_02: considering @ 0:08:23
- SPEAKER_02: I @ 0:08:23
- SPEAKER_02: was @ 0:08:23
- SPEAKER_02: the @ 0:08:23
- SPEAKER_02: college @ 0:08:23
- SPEAKER_02: dropout @ 0:08:24
- SPEAKER_02: in @ 0:08:24
- SPEAKER_02: computer @ 0:08:24
- SPEAKER_02: science. @ 0:08:25

## Segment 129: [0:08:26 - 0:08:27] (SPEAKER_02)

and it just ended up working.

### Word‑level timestamps

- SPEAKER_02: and @ 0:08:26
- SPEAKER_02: it @ 0:08:26
- SPEAKER_02: just @ 0:08:26
- SPEAKER_02: ended @ 0:08:27
- SPEAKER_02: up @ 0:08:27
- SPEAKER_02: working. @ 0:08:27

## Segment 130: [0:08:27 - 0:08:32] (SPEAKER_02)

The biggest thing that I tell people is that ideas are now currency.

### Word‑level timestamps

- SPEAKER_02: The @ 0:08:27
- SPEAKER_02: biggest @ 0:08:28
- SPEAKER_02: thing @ 0:08:28
- SPEAKER_02: that @ 0:08:28
- SPEAKER_02: I @ 0:08:28
- SPEAKER_02: tell @ 0:08:28
- SPEAKER_02: people @ 0:08:29
- SPEAKER_02: is @ 0:08:29
- SPEAKER_02: that @ 0:08:30
- SPEAKER_02: ideas @ 0:08:30
- SPEAKER_02: are @ 0:08:31
- SPEAKER_02: now @ 0:08:31
- SPEAKER_02: currency. @ 0:08:32

## Segment 131: [0:08:32 - 0:08:36] (SPEAKER_02)

Ideas are the currency of this new technological era we're entering in.

### Word‑level timestamps

- SPEAKER_02: Ideas @ 0:08:32
- SPEAKER_02: are @ 0:08:33
- SPEAKER_02: the @ 0:08:33
- SPEAKER_02: currency @ 0:08:33
- SPEAKER_02: of @ 0:08:34
- SPEAKER_02: this @ 0:08:34
- SPEAKER_02: new @ 0:08:34
- SPEAKER_02: technological @ 0:08:34
- SPEAKER_02: era @ 0:08:35
- SPEAKER_02: we're @ 0:08:35
- SPEAKER_02: entering @ 0:08:36
- SPEAKER_02: in. @ 0:08:36

## Segment 132: [0:08:37 - 0:08:46] (SPEAKER_02)

And the reason why is the better the models come out, the less you have to really worry about understanding proper structure, proper security, all of these things.

### Word‑level timestamps

- SPEAKER_02: And @ 0:08:37
- SPEAKER_02: the @ 0:08:37
- SPEAKER_02: reason @ 0:08:37
- SPEAKER_02: why @ 0:08:37
- SPEAKER_02: is @ 0:08:37
- SPEAKER_02: the @ 0:08:37
- SPEAKER_02: better @ 0:08:39
- SPEAKER_02: the @ 0:08:39
- SPEAKER_02: models @ 0:08:39
- SPEAKER_02: come @ 0:08:39
- SPEAKER_02: out, @ 0:08:40
- SPEAKER_02: the @ 0:08:40
- SPEAKER_02: less @ 0:08:40
- SPEAKER_02: you @ 0:08:41
- SPEAKER_02: have @ 0:08:41
- SPEAKER_02: to @ 0:08:41
- SPEAKER_02: really @ 0:08:41
- SPEAKER_02: worry @ 0:08:41
- SPEAKER_02: about @ 0:08:42
- SPEAKER_02: understanding @ 0:08:42
- SPEAKER_02: proper @ 0:08:43
- SPEAKER_02: structure, @ 0:08:43
- SPEAKER_02: proper @ 0:08:44
- SPEAKER_02: security, @ 0:08:45
- SPEAKER_02: all @ 0:08:45
- SPEAKER_02: of @ 0:08:45
- SPEAKER_02: these @ 0:08:46
- SPEAKER_02: things. @ 0:08:46

## Segment 133: [0:08:46 - 0:08:53] (SPEAKER_02)

Eventually, models get better and people make products that support all of these technical burdens that people are too lazy to learn.

### Word‑level timestamps

- SPEAKER_02: Eventually, @ 0:08:46
- SPEAKER_02: models @ 0:08:47
- SPEAKER_02: get @ 0:08:47
- SPEAKER_02: better @ 0:08:48
- SPEAKER_02: and @ 0:08:48
- SPEAKER_02: people @ 0:08:48
- SPEAKER_02: make @ 0:08:48
- SPEAKER_02: products @ 0:08:49
- SPEAKER_02: that @ 0:08:49
- SPEAKER_02: support @ 0:08:49
- SPEAKER_02: all @ 0:08:49
- SPEAKER_02: of @ 0:08:50
- SPEAKER_02: these @ 0:08:50
- SPEAKER_02: technical @ 0:08:50
- SPEAKER_02: burdens @ 0:08:51
- SPEAKER_02: that @ 0:08:52
- SPEAKER_02: people @ 0:08:52
- SPEAKER_02: are @ 0:08:52
- SPEAKER_02: too @ 0:08:52
- SPEAKER_02: lazy @ 0:08:52
- SPEAKER_02: to @ 0:08:53
- SPEAKER_02: learn. @ 0:08:53

## Segment 134: [0:08:53 - 0:09:00] (SPEAKER_02)

If you have an interesting idea or an interesting product idea, all you have to do now is just type words in, bro.

### Word‑level timestamps

- SPEAKER_02: If @ 0:08:53
- SPEAKER_02: you @ 0:08:54
- SPEAKER_02: have @ 0:08:54
- SPEAKER_02: an @ 0:08:54
- SPEAKER_02: interesting @ 0:08:54
- SPEAKER_02: idea @ 0:08:55
- SPEAKER_02: or @ 0:08:55
- SPEAKER_02: an @ 0:08:55
- SPEAKER_02: interesting @ 0:08:55
- SPEAKER_02: product @ 0:08:56
- SPEAKER_02: idea, @ 0:08:56
- SPEAKER_02: all @ 0:08:56
- SPEAKER_02: you @ 0:08:57
- SPEAKER_02: have @ 0:08:57
- SPEAKER_02: to @ 0:08:57
- SPEAKER_02: do @ 0:08:57
- SPEAKER_02: now @ 0:08:57
- SPEAKER_02: is @ 0:08:58
- SPEAKER_02: just @ 0:08:58
- SPEAKER_02: type @ 0:08:59
- SPEAKER_02: words @ 0:08:59
- SPEAKER_02: in, @ 0:09:00
- SPEAKER_02: bro. @ 0:09:00

## Segment 135: [0:09:01 - 0:09:02] (SPEAKER_02)

Like, you have an interesting product idea.

### Word‑level timestamps

- SPEAKER_02: Like, @ 0:09:01
- SPEAKER_02: you @ 0:09:01
- SPEAKER_02: have @ 0:09:01
- SPEAKER_02: an @ 0:09:01
- SPEAKER_02: interesting @ 0:09:01
- SPEAKER_02: product @ 0:09:02
- SPEAKER_02: idea. @ 0:09:02

## Segment 136: [0:09:02 - 0:09:04] (SPEAKER_02)

Oh, I think people will find this useful.

### Word‑level timestamps

- SPEAKER_02: Oh, @ 0:09:02
- SPEAKER_02: I @ 0:09:03
- SPEAKER_02: think @ 0:09:03
- SPEAKER_02: people @ 0:09:03
- SPEAKER_02: will @ 0:09:03
- SPEAKER_02: find @ 0:09:03
- SPEAKER_02: this @ 0:09:03
- SPEAKER_02: useful. @ 0:09:04

## Segment 137: [0:09:04 - 0:09:05] (SPEAKER_02)

Test it.

### Word‑level timestamps

- SPEAKER_02: Test @ 0:09:04
- SPEAKER_02: it. @ 0:09:05

## Segment 138: [0:09:05 - 0:09:06] (SPEAKER_02)

Just type it in.

### Word‑level timestamps

- SPEAKER_02: Just @ 0:09:05
- SPEAKER_02: type @ 0:09:05
- SPEAKER_02: it @ 0:09:06
- SPEAKER_02: in. @ 0:09:06

## Segment 139: [0:09:06 - 0:09:08] (SPEAKER_02)

You'll see your product in front of you in five minutes.

### Word‑level timestamps

- SPEAKER_02: You'll @ 0:09:06
- SPEAKER_02: see @ 0:09:06
- SPEAKER_02: your @ 0:09:06
- SPEAKER_02: product @ 0:09:06
- SPEAKER_02: in @ 0:09:07
- SPEAKER_02: front @ 0:09:07
- SPEAKER_02: of @ 0:09:07
- SPEAKER_02: you @ 0:09:07
- SPEAKER_02: in @ 0:09:07
- SPEAKER_02: five @ 0:09:07
- SPEAKER_02: minutes. @ 0:09:08

## Segment 140: [0:09:08 - 0:09:14] (SPEAKER_02)

The most interesting thing about this is it lets you refine your idea, iterate on your idea.

### Word‑level timestamps

- SPEAKER_02: The @ 0:09:08
- SPEAKER_02: most @ 0:09:08
- SPEAKER_02: interesting @ 0:09:09
- SPEAKER_02: thing @ 0:09:09
- SPEAKER_02: about @ 0:09:09
- SPEAKER_02: this @ 0:09:09
- SPEAKER_02: is @ 0:09:10
- SPEAKER_02: it @ 0:09:10
- SPEAKER_02: lets @ 0:09:10
- SPEAKER_02: you @ 0:09:10
- SPEAKER_02: refine @ 0:09:10
- SPEAKER_02: your @ 0:09:12
- SPEAKER_02: idea, @ 0:09:12
- SPEAKER_02: iterate @ 0:09:12
- SPEAKER_02: on @ 0:09:13
- SPEAKER_02: your @ 0:09:14
- SPEAKER_02: idea. @ 0:09:14

## Segment 141: [0:09:14 - 0:09:16] (SPEAKER_02)

See if your idea is even worth pursuing.

### Word‑level timestamps

- SPEAKER_02: See @ 0:09:14
- SPEAKER_02: if @ 0:09:14
- SPEAKER_02: your @ 0:09:14
- SPEAKER_02: idea @ 0:09:15
- SPEAKER_02: is @ 0:09:15
- SPEAKER_02: even @ 0:09:15
- SPEAKER_02: worth @ 0:09:15
- SPEAKER_02: pursuing. @ 0:09:15

## Segment 142: [0:09:16 - 0:09:18] (SPEAKER_02)

When in seconds, it's in front of you.

### Word‑level timestamps

- SPEAKER_02: When @ 0:09:16
- SPEAKER_02: in @ 0:09:16
- SPEAKER_02: seconds, @ 0:09:16
- SPEAKER_02: it's @ 0:09:17
- SPEAKER_02: in @ 0:09:17
- SPEAKER_02: front @ 0:09:17
- SPEAKER_02: of @ 0:09:17
- SPEAKER_02: you. @ 0:09:17

## Segment 143: [0:09:18 - 0:09:19] (SPEAKER_02)

This product's actually kind of garbage.

### Word‑level timestamps

- SPEAKER_02: This @ 0:09:18
- SPEAKER_02: product's @ 0:09:18
- SPEAKER_02: actually @ 0:09:18
- SPEAKER_02: kind @ 0:09:18
- SPEAKER_02: of @ 0:09:18
- SPEAKER_02: garbage. @ 0:09:18

## Segment 144: [0:09:19 - 0:09:20] (SPEAKER_02)

Or, oh, it's actually good.

### Word‑level timestamps

- SPEAKER_02: Or, @ 0:09:19
- SPEAKER_02: oh, @ 0:09:19
- SPEAKER_02: it's @ 0:09:19
- SPEAKER_02: actually @ 0:09:19
- SPEAKER_02: good. @ 0:09:20

## Segment 145: [0:09:20 - 0:09:21] (SPEAKER_02)

You can pursue it further.

### Word‑level timestamps

- SPEAKER_02: You @ 0:09:20
- SPEAKER_02: can @ 0:09:20
- SPEAKER_02: pursue @ 0:09:20
- SPEAKER_02: it @ 0:09:20
- SPEAKER_02: further. @ 0:09:20

## Segment 146: [0:09:21 - 0:09:30] (SPEAKER_02)

Let's get into the point where as long as you have a really novel, interesting idea, if you put it into the AI system, then you might end up getting a really good product.

### Word‑level timestamps

- SPEAKER_02: Let's @ 0:09:21
- SPEAKER_02: get @ 0:09:22
- SPEAKER_02: into @ 0:09:22
- SPEAKER_02: the @ 0:09:22
- SPEAKER_02: point @ 0:09:22
- SPEAKER_02: where @ 0:09:22
- SPEAKER_02: as @ 0:09:23
- SPEAKER_02: long @ 0:09:23
- SPEAKER_02: as @ 0:09:23
- SPEAKER_02: you @ 0:09:23
- SPEAKER_02: have @ 0:09:23
- SPEAKER_02: a @ 0:09:24
- SPEAKER_02: really @ 0:09:24
- SPEAKER_02: novel, @ 0:09:24
- SPEAKER_02: interesting @ 0:09:24
- SPEAKER_02: idea, @ 0:09:25
- SPEAKER_02: if @ 0:09:25
- SPEAKER_02: you @ 0:09:25
- SPEAKER_02: put @ 0:09:25
- SPEAKER_02: it @ 0:09:26
- SPEAKER_02: into @ 0:09:26
- SPEAKER_02: the @ 0:09:26
- SPEAKER_02: AI @ 0:09:26
- SPEAKER_02: system, @ 0:09:26
- SPEAKER_02: then @ 0:09:27
- SPEAKER_02: you @ 0:09:27
- SPEAKER_02: might @ 0:09:28
- SPEAKER_02: end @ 0:09:28
- SPEAKER_02: up @ 0:09:28
- SPEAKER_02: getting @ 0:09:28
- SPEAKER_02: a @ 0:09:28
- SPEAKER_02: really @ 0:09:28
- SPEAKER_02: good @ 0:09:29
- SPEAKER_02: product. @ 0:09:29

## Segment 147: [0:09:30 - 0:09:34] (SPEAKER_02)

And either way you save time, you could either pursue learning how to make the product an actual product.

### Word‑level timestamps

- SPEAKER_02: And @ 0:09:30
- SPEAKER_02: either @ 0:09:30
- SPEAKER_02: way @ 0:09:30
- SPEAKER_02: you @ 0:09:30
- SPEAKER_02: save @ 0:09:30
- SPEAKER_02: time, @ 0:09:31
- SPEAKER_02: you @ 0:09:31
- SPEAKER_02: could @ 0:09:31
- SPEAKER_02: either @ 0:09:31
- SPEAKER_02: pursue @ 0:09:31
- SPEAKER_02: learning @ 0:09:32
- SPEAKER_02: how @ 0:09:32
- SPEAKER_02: to @ 0:09:32
- SPEAKER_02: make @ 0:09:33
- SPEAKER_02: the @ 0:09:33
- SPEAKER_02: product @ 0:09:33
- SPEAKER_02: an @ 0:09:33
- SPEAKER_02: actual @ 0:09:33
- SPEAKER_02: product. @ 0:09:34

## Segment 148: [0:09:34 - 0:09:37] (SPEAKER_02)

You can sell people using AI to help guide you along the way.

### Word‑level timestamps

- SPEAKER_02: You @ 0:09:34
- SPEAKER_02: can @ 0:09:34
- SPEAKER_02: sell @ 0:09:34
- SPEAKER_02: people @ 0:09:34
- SPEAKER_02: using @ 0:09:35
- SPEAKER_02: AI @ 0:09:36
- SPEAKER_02: to @ 0:09:36
- SPEAKER_02: help @ 0:09:36
- SPEAKER_02: guide @ 0:09:36
- SPEAKER_02: you @ 0:09:36
- SPEAKER_02: along @ 0:09:36
- SPEAKER_02: the @ 0:09:37
- SPEAKER_02: way. @ 0:09:37

## Segment 149: [0:09:37 - 0:09:43] (SPEAKER_02)

Or if you validate your product idea and it actually makes sense, then you can hire people to help you.

### Word‑level timestamps

- SPEAKER_02: Or @ 0:09:37
- SPEAKER_02: if @ 0:09:38
- SPEAKER_02: you @ 0:09:38
- SPEAKER_02: validate @ 0:09:38
- SPEAKER_02: your @ 0:09:39
- SPEAKER_02: product @ 0:09:39
- SPEAKER_02: idea @ 0:09:39
- SPEAKER_02: and @ 0:09:40
- SPEAKER_02: it @ 0:09:40
- SPEAKER_02: actually @ 0:09:40
- SPEAKER_02: makes @ 0:09:40
- SPEAKER_02: sense, @ 0:09:40
- SPEAKER_02: then @ 0:09:41
- SPEAKER_02: you @ 0:09:41
- SPEAKER_02: can @ 0:09:42
- SPEAKER_02: hire @ 0:09:42
- SPEAKER_02: people @ 0:09:42
- SPEAKER_02: to @ 0:09:42
- SPEAKER_02: help @ 0:09:42
- SPEAKER_02: you. @ 0:09:42

## Segment 150: [0:09:43 - 0:09:46] (SPEAKER_02)

You waste less time and less money because you're like, oh, this is actually worth pursuing.

### Word‑level timestamps

- SPEAKER_02: You @ 0:09:43
- SPEAKER_02: waste @ 0:09:43
- SPEAKER_02: less @ 0:09:43
- SPEAKER_02: time @ 0:09:44
- SPEAKER_02: and @ 0:09:44
- SPEAKER_02: less @ 0:09:44
- SPEAKER_02: money @ 0:09:44
- SPEAKER_02: because @ 0:09:44
- SPEAKER_02: you're @ 0:09:45
- SPEAKER_02: like, @ 0:09:45
- SPEAKER_02: oh, @ 0:09:45
- SPEAKER_02: this @ 0:09:45
- SPEAKER_02: is @ 0:09:45
- SPEAKER_02: actually @ 0:09:45
- SPEAKER_02: worth @ 0:09:46
- SPEAKER_02: pursuing. @ 0:09:46

## Segment 151: [0:09:46 - 0:09:48] (SPEAKER_02)

So it's really interesting to play with it.

### Word‑level timestamps

- SPEAKER_02: So @ 0:09:46
- SPEAKER_02: it's @ 0:09:46
- SPEAKER_02: really @ 0:09:46
- SPEAKER_02: interesting @ 0:09:47
- SPEAKER_02: to @ 0:09:47
- SPEAKER_02: play @ 0:09:47
- SPEAKER_02: with @ 0:09:47
- SPEAKER_02: it. @ 0:09:47

## Segment 152: [0:09:48 - 0:09:53] (SPEAKER_02)

And there's a lot of products that came out recently that make this experience a lot easier.

### Word‑level timestamps

- SPEAKER_02: And @ 0:09:48
- SPEAKER_02: there's @ 0:09:48
- SPEAKER_02: a @ 0:09:48
- SPEAKER_02: lot @ 0:09:48
- SPEAKER_02: of @ 0:09:49
- SPEAKER_02: products @ 0:09:49
- SPEAKER_02: that @ 0:09:49
- SPEAKER_02: came @ 0:09:49
- SPEAKER_02: out @ 0:09:49
- SPEAKER_02: recently @ 0:09:50
- SPEAKER_02: that @ 0:09:50
- SPEAKER_02: make @ 0:09:51
- SPEAKER_02: this @ 0:09:51
- SPEAKER_02: experience @ 0:09:51
- SPEAKER_02: a @ 0:09:52
- SPEAKER_02: lot @ 0:09:52
- SPEAKER_02: easier. @ 0:09:53

## Segment 153: [0:09:53 - 0:09:57] (SPEAKER_02)

So these are a couple of products that I've seen coming out.

### Word‑level timestamps

- SPEAKER_02: So @ 0:09:53
- SPEAKER_02: these @ 0:09:53
- SPEAKER_02: are @ 0:09:53
- SPEAKER_02: a @ 0:09:54
- SPEAKER_02: couple @ 0:09:54
- SPEAKER_02: of @ 0:09:54
- SPEAKER_02: products @ 0:09:54
- SPEAKER_02: that @ 0:09:55
- SPEAKER_02: I've @ 0:09:56
- SPEAKER_02: seen @ 0:09:56
- SPEAKER_02: coming @ 0:09:56
- SPEAKER_02: out. @ 0:09:57

## Segment 154: [0:09:57 - 0:10:03] (SPEAKER_02)

There's some interesting trend going on right now where a lot of these companies are making these AI products that make making products easier.

### Word‑level timestamps

- SPEAKER_02: There's @ 0:09:57
- SPEAKER_02: some @ 0:09:57
- SPEAKER_02: interesting @ 0:09:57
- SPEAKER_02: trend @ 0:09:58
- SPEAKER_02: going @ 0:09:58
- SPEAKER_02: on @ 0:09:58
- SPEAKER_02: right @ 0:09:58
- SPEAKER_02: now @ 0:09:59
- SPEAKER_02: where @ 0:09:59
- SPEAKER_02: a @ 0:09:59
- SPEAKER_02: lot @ 0:09:59
- SPEAKER_02: of @ 0:09:59
- SPEAKER_02: these @ 0:09:59
- SPEAKER_02: companies @ 0:09:59
- SPEAKER_02: are @ 0:10:00
- SPEAKER_02: making @ 0:10:00
- SPEAKER_02: these @ 0:10:00
- SPEAKER_02: AI @ 0:10:00
- SPEAKER_02: products @ 0:10:01
- SPEAKER_02: that @ 0:10:01
- SPEAKER_02: make @ 0:10:02
- SPEAKER_02: making @ 0:10:02
- SPEAKER_02: products @ 0:10:03
- SPEAKER_02: easier. @ 0:10:03

## Segment 155: [0:10:03 - 0:10:06] (SPEAKER_02)

So there's AI companies selling AI products that make products.

### Word‑level timestamps

- SPEAKER_02: So @ 0:10:03
- SPEAKER_02: there's @ 0:10:04
- SPEAKER_02: AI @ 0:10:04
- SPEAKER_02: companies @ 0:10:04
- SPEAKER_02: selling @ 0:10:05
- SPEAKER_02: AI @ 0:10:05
- SPEAKER_02: products @ 0:10:05
- SPEAKER_02: that @ 0:10:06
- SPEAKER_02: make @ 0:10:06
- SPEAKER_02: products. @ 0:10:06

## Segment 156: [0:10:06 - 0:10:10] (SPEAKER_02)

The top ones I've heard about is Replet, Bult, Lovable.

### Word‑level timestamps

- SPEAKER_02: The @ 0:10:06
- SPEAKER_02: top @ 0:10:06
- SPEAKER_02: ones @ 0:10:07
- SPEAKER_02: I've @ 0:10:07
- SPEAKER_02: heard @ 0:10:07
- SPEAKER_02: about @ 0:10:07
- SPEAKER_02: is @ 0:10:07
- SPEAKER_02: Replet, @ 0:10:08
- SPEAKER_02: Bult, @ 0:10:08
- SPEAKER_02: Lovable. @ 0:10:09

## Segment 157: [0:10:10 - 0:10:15] (SPEAKER_02)

Other, I guess, honorable mentions are Windsurf, WebSim, and

### Word‑level timestamps

- SPEAKER_02: Other, @ 0:10:10
- SPEAKER_02: I @ 0:10:10
- SPEAKER_02: guess, @ 0:10:11
- SPEAKER_02: honorable @ 0:10:11
- SPEAKER_02: mentions @ 0:10:11
- SPEAKER_02: are @ 0:10:12
- SPEAKER_02: Windsurf, @ 0:10:12
- SPEAKER_02: WebSim, @ 0:10:12
- SPEAKER_02: and @ 0:10:13

## Segment 158: [0:10:16 - 0:10:35] (SPEAKER_02)

I'd say I keep it at those five, but the thing about these products is these are the apps where if you have no technical skills at all, you don't know jack about anything technical, anything about development, but you have a fun idea in your head that you just give one of these systems your idea and boom, it's in front of you and it helps you refine it and it helps it adjust it.

### Word‑level timestamps

- SPEAKER_02: I'd @ 0:10:16
- SPEAKER_02: say @ 0:10:17
- SPEAKER_02: I @ 0:10:17
- SPEAKER_02: keep @ 0:10:17
- SPEAKER_02: it @ 0:10:17
- SPEAKER_02: at @ 0:10:17
- SPEAKER_02: those @ 0:10:18
- SPEAKER_02: five, @ 0:10:18
- SPEAKER_02: but @ 0:10:18
- SPEAKER_02: the @ 0:10:18
- SPEAKER_02: thing @ 0:10:18
- SPEAKER_02: about @ 0:10:19
- SPEAKER_02: these @ 0:10:19
- SPEAKER_02: products @ 0:10:19
- SPEAKER_02: is @ 0:10:20
- SPEAKER_02: these @ 0:10:20
- SPEAKER_02: are @ 0:10:20
- SPEAKER_02: the @ 0:10:20
- SPEAKER_02: apps @ 0:10:20
- SPEAKER_02: where @ 0:10:21
- SPEAKER_02: if @ 0:10:21
- SPEAKER_02: you @ 0:10:21
- SPEAKER_02: have @ 0:10:22
- SPEAKER_02: no @ 0:10:22
- SPEAKER_02: technical @ 0:10:22
- SPEAKER_02: skills @ 0:10:23
- SPEAKER_02: at @ 0:10:23
- SPEAKER_02: all, @ 0:10:23
- SPEAKER_02: you @ 0:10:23
- SPEAKER_02: don't @ 0:10:23
- SPEAKER_02: know @ 0:10:23
- SPEAKER_02: jack @ 0:10:24
- SPEAKER_02: about @ 0:10:24
- SPEAKER_02: anything @ 0:10:25
- SPEAKER_02: technical, @ 0:10:25
- SPEAKER_02: anything @ 0:10:25
- SPEAKER_02: about @ 0:10:26
- SPEAKER_02: development, @ 0:10:26
- SPEAKER_02: but @ 0:10:27
- SPEAKER_02: you @ 0:10:27
- SPEAKER_02: have @ 0:10:27
- SPEAKER_02: a @ 0:10:27
- SPEAKER_02: fun @ 0:10:27
- SPEAKER_02: idea @ 0:10:27
- SPEAKER_02: in @ 0:10:28
- SPEAKER_02: your @ 0:10:28
- SPEAKER_02: head @ 0:10:28
- SPEAKER_02: that @ 0:10:28
- SPEAKER_02: you @ 0:10:29
- SPEAKER_02: just @ 0:10:29
- SPEAKER_02: give @ 0:10:30
- SPEAKER_02: one @ 0:10:30
- SPEAKER_02: of @ 0:10:30
- SPEAKER_02: these @ 0:10:30
- SPEAKER_02: systems @ 0:10:30
- SPEAKER_02: your @ 0:10:31
- SPEAKER_02: idea @ 0:10:31
- SPEAKER_02: and @ 0:10:31
- SPEAKER_02: boom, @ 0:10:31
- SPEAKER_02: it's @ 0:10:32
- SPEAKER_02: in @ 0:10:32
- SPEAKER_02: front @ 0:10:32
- SPEAKER_02: of @ 0:10:32
- SPEAKER_02: you @ 0:10:32
- SPEAKER_02: and @ 0:10:32
- SPEAKER_02: it @ 0:10:32
- SPEAKER_02: helps @ 0:10:32
- SPEAKER_02: you @ 0:10:33
- SPEAKER_02: refine @ 0:10:33
- SPEAKER_02: it @ 0:10:33
- SPEAKER_02: and @ 0:10:33
- SPEAKER_02: it @ 0:10:33
- SPEAKER_02: helps @ 0:10:34
- SPEAKER_02: it @ 0:10:34
- SPEAKER_02: adjust @ 0:10:34
- SPEAKER_02: it. @ 0:10:34

## Segment 159: [0:10:35 - 0:10:44] (SPEAKER_02)

And it really just makes coding a lot of fun because you worry less about how do I do something and you focus more on I have this creative juice inside of me.

### Word‑level timestamps

- SPEAKER_02: And @ 0:10:35
- SPEAKER_02: it @ 0:10:35
- SPEAKER_02: really @ 0:10:36
- SPEAKER_02: just @ 0:10:36
- SPEAKER_02: makes @ 0:10:36
- SPEAKER_02: coding @ 0:10:37
- SPEAKER_02: a @ 0:10:37
- SPEAKER_02: lot @ 0:10:37
- SPEAKER_02: of @ 0:10:38
- SPEAKER_02: fun @ 0:10:38
- SPEAKER_02: because @ 0:10:39
- SPEAKER_02: you @ 0:10:39
- SPEAKER_02: worry @ 0:10:39
- SPEAKER_02: less @ 0:10:39
- SPEAKER_02: about @ 0:10:40
- SPEAKER_02: how @ 0:10:40
- SPEAKER_02: do @ 0:10:40
- SPEAKER_02: I @ 0:10:40
- SPEAKER_02: do @ 0:10:40
- SPEAKER_02: something @ 0:10:40
- SPEAKER_02: and @ 0:10:41
- SPEAKER_02: you @ 0:10:41
- SPEAKER_02: focus @ 0:10:41
- SPEAKER_02: more @ 0:10:42
- SPEAKER_02: on @ 0:10:42
- SPEAKER_02: I @ 0:10:42
- SPEAKER_02: have @ 0:10:42
- SPEAKER_02: this @ 0:10:42
- SPEAKER_02: creative @ 0:10:43
- SPEAKER_02: juice @ 0:10:43
- SPEAKER_02: inside @ 0:10:44
- SPEAKER_02: of @ 0:10:44
- SPEAKER_02: me. @ 0:10:44

## Segment 160: [0:10:44 - 0:10:45] (SPEAKER_02)

How do I fuel it?

### Word‑level timestamps

- SPEAKER_02: How @ 0:10:44
- SPEAKER_02: do @ 0:10:44
- SPEAKER_02: I @ 0:10:45
- SPEAKER_02: fuel @ 0:10:45
- SPEAKER_02: it? @ 0:10:45

## Segment 161: [0:10:46 - 0:10:57] (SPEAKER_02)

So I love AI personally because I feel I just have so many ideas and I have a lot of creativity I feel contained in my head and before AI I can only release that in Minecraft but now I can release it to the whole world.

### Word‑level timestamps

- SPEAKER_02: So @ 0:10:46
- SPEAKER_02: I @ 0:10:46
- SPEAKER_02: love @ 0:10:46
- SPEAKER_02: AI @ 0:10:46
- SPEAKER_02: personally @ 0:10:46
- SPEAKER_02: because @ 0:10:47
- SPEAKER_02: I @ 0:10:47
- SPEAKER_02: feel @ 0:10:47
- SPEAKER_02: I @ 0:10:48
- SPEAKER_02: just @ 0:10:48
- SPEAKER_02: have @ 0:10:49
- SPEAKER_02: so @ 0:10:49
- SPEAKER_02: many @ 0:10:49
- SPEAKER_02: ideas @ 0:10:49
- SPEAKER_02: and @ 0:10:50
- SPEAKER_02: I @ 0:10:50
- SPEAKER_02: have @ 0:10:50
- SPEAKER_02: a @ 0:10:50
- SPEAKER_02: lot @ 0:10:50
- SPEAKER_02: of @ 0:10:50
- SPEAKER_02: creativity @ 0:10:50
- SPEAKER_02: I @ 0:10:51
- SPEAKER_02: feel @ 0:10:51
- SPEAKER_02: contained @ 0:10:51
- SPEAKER_02: in @ 0:10:52
- SPEAKER_02: my @ 0:10:52
- SPEAKER_02: head @ 0:10:52
- SPEAKER_02: and @ 0:10:52
- SPEAKER_02: before @ 0:10:53
- SPEAKER_02: AI @ 0:10:53
- SPEAKER_02: I @ 0:10:53
- SPEAKER_02: can @ 0:10:53
- SPEAKER_02: only @ 0:10:53
- SPEAKER_02: release @ 0:10:54
- SPEAKER_02: that @ 0:10:54
- SPEAKER_02: in @ 0:10:54
- SPEAKER_02: Minecraft @ 0:10:54
- SPEAKER_02: but @ 0:10:55
- SPEAKER_02: now @ 0:10:55
- SPEAKER_02: I @ 0:10:55
- SPEAKER_02: can @ 0:10:55
- SPEAKER_02: release @ 0:10:55
- SPEAKER_02: it @ 0:10:55
- SPEAKER_02: to @ 0:10:56
- SPEAKER_02: the @ 0:10:56
- SPEAKER_02: whole @ 0:10:56
- SPEAKER_02: world. @ 0:10:56

## Segment 162: [0:10:57 - 0:11:01] (SPEAKER_02)

because AI just takes my idea, holds my hand through the process.

### Word‑level timestamps

- SPEAKER_02: because @ 0:10:57
- SPEAKER_02: AI @ 0:10:58
- SPEAKER_02: just @ 0:10:58
- SPEAKER_02: takes @ 0:10:58
- SPEAKER_02: my @ 0:10:58
- SPEAKER_02: idea, @ 0:10:59
- SPEAKER_02: holds @ 0:10:59
- SPEAKER_02: my @ 0:11:00
- SPEAKER_02: hand @ 0:11:00
- SPEAKER_02: through @ 0:11:00
- SPEAKER_02: the @ 0:11:00
- SPEAKER_02: process. @ 0:11:00

## Segment 163: [0:11:01 - 0:11:05] (SPEAKER_02)

The last two years of doing that every single day, oh, I actually do no code now.

### Word‑level timestamps

- SPEAKER_02: The @ 0:11:01
- SPEAKER_02: last @ 0:11:01
- SPEAKER_02: two @ 0:11:01
- SPEAKER_02: years @ 0:11:02
- SPEAKER_02: of @ 0:11:02
- SPEAKER_02: doing @ 0:11:02
- SPEAKER_02: that @ 0:11:02
- SPEAKER_02: every @ 0:11:02
- SPEAKER_02: single @ 0:11:03
- SPEAKER_02: day, @ 0:11:03
- SPEAKER_02: oh, @ 0:11:03
- SPEAKER_02: I @ 0:11:03
- SPEAKER_02: actually @ 0:11:03
- SPEAKER_02: do @ 0:11:04
- SPEAKER_02: no @ 0:11:04
- SPEAKER_02: code @ 0:11:04
- SPEAKER_02: now. @ 0:11:04

## Segment 164: [0:11:05 - 0:11:06] (SPEAKER_02)

I actually can read it fully.

### Word‑level timestamps

- SPEAKER_02: I @ 0:11:05
- SPEAKER_02: actually @ 0:11:05
- SPEAKER_02: can @ 0:11:05
- SPEAKER_02: read @ 0:11:05
- SPEAKER_02: it @ 0:11:06
- SPEAKER_02: fully. @ 0:11:06

## Segment 165: [0:11:06 - 0:11:07] (SPEAKER_02)

I understand security.

### Word‑level timestamps

- SPEAKER_02: I @ 0:11:06
- SPEAKER_02: understand @ 0:11:06
- SPEAKER_02: security. @ 0:11:07

## Segment 166: [0:11:07 - 0:11:09] (SPEAKER_02)

And the more you use it, the better you get at it.

### Word‑level timestamps

- SPEAKER_02: And @ 0:11:07
- SPEAKER_02: the @ 0:11:07
- SPEAKER_02: more @ 0:11:07
- SPEAKER_02: you @ 0:11:08
- SPEAKER_02: use @ 0:11:08
- SPEAKER_02: it, @ 0:11:08
- SPEAKER_02: the @ 0:11:08
- SPEAKER_02: better @ 0:11:08
- SPEAKER_02: you @ 0:11:08
- SPEAKER_02: get @ 0:11:09
- SPEAKER_02: at @ 0:11:09
- SPEAKER_02: it. @ 0:11:09

## Segment 167: [0:11:09 - 0:11:19] (SPEAKER_02)

And AI has this interesting kind of, it's almost intuitive at this point, but AI has this language that if you really lean into it, it becomes this

### Word‑level timestamps

- SPEAKER_02: And @ 0:11:09
- SPEAKER_02: AI @ 0:11:09
- SPEAKER_02: has @ 0:11:09
- SPEAKER_02: this @ 0:11:10
- SPEAKER_02: interesting @ 0:11:10
- SPEAKER_02: kind @ 0:11:11
- SPEAKER_02: of, @ 0:11:11
- SPEAKER_02: it's @ 0:11:13
- SPEAKER_02: almost @ 0:11:13
- SPEAKER_02: intuitive @ 0:11:13
- SPEAKER_02: at @ 0:11:14
- SPEAKER_02: this @ 0:11:14
- SPEAKER_02: point, @ 0:11:14
- SPEAKER_02: but @ 0:11:14
- SPEAKER_02: AI @ 0:11:15
- SPEAKER_02: has @ 0:11:15
- SPEAKER_02: this @ 0:11:15
- SPEAKER_02: language @ 0:11:15
- SPEAKER_02: that @ 0:11:16
- SPEAKER_02: if @ 0:11:16
- SPEAKER_02: you @ 0:11:16
- SPEAKER_02: really @ 0:11:16
- SPEAKER_02: lean @ 0:11:17
- SPEAKER_02: into @ 0:11:17
- SPEAKER_02: it, @ 0:11:17
- SPEAKER_02: it @ 0:11:18
- SPEAKER_02: becomes @ 0:11:18
- SPEAKER_02: this @ 0:11:18

## Segment 168: [0:11:19 - 0:11:21] (SPEAKER_02)

brain extension of yourself.

### Word‑level timestamps

- SPEAKER_02: brain @ 0:11:19
- SPEAKER_02: extension @ 0:11:20
- SPEAKER_02: of @ 0:11:20
- SPEAKER_02: yourself. @ 0:11:20

## Segment 169: [0:11:21 - 0:11:30] (SPEAKER_02)

Honestly, talking with AI every single day for the last two years has helped me understand myself on a deeper level in ways I don't really think possible.

### Word‑level timestamps

- SPEAKER_02: Honestly, @ 0:11:21
- SPEAKER_02: talking @ 0:11:22
- SPEAKER_02: with @ 0:11:22
- SPEAKER_02: AI @ 0:11:22
- SPEAKER_02: every @ 0:11:22
- SPEAKER_02: single @ 0:11:23
- SPEAKER_02: day @ 0:11:23
- SPEAKER_02: for @ 0:11:23
- SPEAKER_02: the @ 0:11:24
- SPEAKER_02: last @ 0:11:24
- SPEAKER_02: two @ 0:11:24
- SPEAKER_02: years @ 0:11:24
- SPEAKER_02: has @ 0:11:25
- SPEAKER_02: helped @ 0:11:25
- SPEAKER_02: me @ 0:11:26
- SPEAKER_02: understand @ 0:11:26
- SPEAKER_02: myself @ 0:11:27
- SPEAKER_02: on @ 0:11:28
- SPEAKER_02: a @ 0:11:28
- SPEAKER_02: deeper @ 0:11:28
- SPEAKER_02: level @ 0:11:28
- SPEAKER_02: in @ 0:11:28
- SPEAKER_02: ways @ 0:11:28
- SPEAKER_02: I @ 0:11:29
- SPEAKER_02: don't @ 0:11:29
- SPEAKER_02: really @ 0:11:29
- SPEAKER_02: think @ 0:11:29
- SPEAKER_02: possible. @ 0:11:29

## Segment 170: [0:11:30 - 0:11:31] (SPEAKER_02)

And you get in this loop.

### Word‑level timestamps

- SPEAKER_02: And @ 0:11:30
- SPEAKER_02: you @ 0:11:30
- SPEAKER_02: get @ 0:11:30
- SPEAKER_02: in @ 0:11:30
- SPEAKER_02: this @ 0:11:31
- SPEAKER_02: loop. @ 0:11:31

## Segment 171: [0:11:31 - 0:11:46] (SPEAKER_02)

The more you understand yourself, the better of a communicator you are, the better of a communicator you are, the better you could explain and communicate your idea to these AI systems or your tasks or your requests, and it ends up doing a better and better job.

### Word‑level timestamps

- SPEAKER_02: The @ 0:11:31
- SPEAKER_02: more @ 0:11:31
- SPEAKER_02: you @ 0:11:31
- SPEAKER_02: understand @ 0:11:32
- SPEAKER_02: yourself, @ 0:11:32
- SPEAKER_02: the @ 0:11:33
- SPEAKER_02: better @ 0:11:33
- SPEAKER_02: of @ 0:11:33
- SPEAKER_02: a @ 0:11:34
- SPEAKER_02: communicator @ 0:11:34
- SPEAKER_02: you @ 0:11:34
- SPEAKER_02: are, @ 0:11:34
- SPEAKER_02: the @ 0:11:35
- SPEAKER_02: better @ 0:11:35
- SPEAKER_02: of @ 0:11:35
- SPEAKER_02: a @ 0:11:35
- SPEAKER_02: communicator @ 0:11:35
- SPEAKER_02: you @ 0:11:36
- SPEAKER_02: are, @ 0:11:36
- SPEAKER_02: the @ 0:11:36
- SPEAKER_02: better @ 0:11:37
- SPEAKER_02: you @ 0:11:37
- SPEAKER_02: could @ 0:11:37
- SPEAKER_02: explain @ 0:11:38
- SPEAKER_02: and @ 0:11:39
- SPEAKER_02: communicate @ 0:11:39
- SPEAKER_02: your @ 0:11:40
- SPEAKER_02: idea @ 0:11:40
- SPEAKER_02: to @ 0:11:40
- SPEAKER_02: these @ 0:11:40
- SPEAKER_02: AI @ 0:11:41
- SPEAKER_02: systems @ 0:11:41
- SPEAKER_02: or @ 0:11:42
- SPEAKER_02: your @ 0:11:42
- SPEAKER_02: tasks @ 0:11:43
- SPEAKER_02: or @ 0:11:43
- SPEAKER_02: your @ 0:11:43
- SPEAKER_02: requests, @ 0:11:44
- SPEAKER_02: and @ 0:11:44
- SPEAKER_02: it @ 0:11:44
- SPEAKER_02: ends @ 0:11:44
- SPEAKER_02: up @ 0:11:44
- SPEAKER_02: doing @ 0:11:45
- SPEAKER_02: a @ 0:11:45
- SPEAKER_02: better @ 0:11:45
- SPEAKER_02: and @ 0:11:45
- SPEAKER_02: better @ 0:11:45
- SPEAKER_02: job. @ 0:11:45

## Segment 172: [0:11:48 - 0:11:53] (SPEAKER_02)

And there's this really interesting loop that I got into about two years ago.

### Word‑level timestamps

- SPEAKER_02: And @ 0:11:48
- SPEAKER_02: there's @ 0:11:48
- SPEAKER_02: this @ 0:11:48
- SPEAKER_02: really @ 0:11:49
- SPEAKER_02: interesting @ 0:11:49
- SPEAKER_02: loop @ 0:11:49
- SPEAKER_02: that @ 0:11:50
- SPEAKER_02: I @ 0:11:51
- SPEAKER_02: got @ 0:11:51
- SPEAKER_02: into @ 0:11:51
- SPEAKER_02: about @ 0:11:52
- SPEAKER_02: two @ 0:11:52
- SPEAKER_02: years @ 0:11:52
- SPEAKER_02: ago. @ 0:11:52

## Segment 173: [0:11:53 - 0:12:01] (SPEAKER_02)

So keep in mind, I didn't know Jack about anything, but the model that came out two years ago, ChadGBG 3.5 Turbo, wasn't smart.

### Word‑level timestamps

- SPEAKER_02: So @ 0:11:53
- SPEAKER_02: keep @ 0:11:53
- SPEAKER_02: in @ 0:11:53
- SPEAKER_02: mind, @ 0:11:53
- SPEAKER_02: I @ 0:11:53
- SPEAKER_02: didn't @ 0:11:54
- SPEAKER_02: know @ 0:11:54
- SPEAKER_02: Jack @ 0:11:54
- SPEAKER_02: about @ 0:11:54
- SPEAKER_02: anything, @ 0:11:55
- SPEAKER_02: but @ 0:11:56
- SPEAKER_02: the @ 0:11:56
- SPEAKER_02: model @ 0:11:56
- SPEAKER_02: that @ 0:11:56
- SPEAKER_02: came @ 0:11:57
- SPEAKER_02: out @ 0:11:57
- SPEAKER_02: two @ 0:11:57
- SPEAKER_02: years @ 0:11:57
- SPEAKER_02: ago, @ 0:11:57
- SPEAKER_02: ChadGBG @ 0:11:58
- SPEAKER_02: 3.5 @ 0:11:58
- SPEAKER_02: Turbo, @ 0:11:59
- SPEAKER_02: wasn't @ 0:12:00
- SPEAKER_02: smart. @ 0:12:01

## Segment 174: [0:12:01 - 0:12:02] (SPEAKER_02)

It was pretty dumb.

### Word‑level timestamps

- SPEAKER_02: It @ 0:12:01
- SPEAKER_02: was @ 0:12:01
- SPEAKER_02: pretty @ 0:12:01
- SPEAKER_02: dumb. @ 0:12:02

## Segment 175: [0:12:02 - 0:12:02] (SPEAKER_02)

It didn't know how to code.

### Word‑level timestamps

- SPEAKER_02: It @ 0:12:02
- SPEAKER_02: didn't @ 0:12:02
- SPEAKER_02: know @ 0:12:02
- SPEAKER_02: how @ 0:12:02
- SPEAKER_02: to @ 0:12:02
- SPEAKER_02: code. @ 0:12:02

## Segment 176: [0:12:03 - 0:12:05] (SPEAKER_02)

It didn't know any of these scientific ideas or any novel ideas.

### Word‑level timestamps

- SPEAKER_02: It @ 0:12:03
- SPEAKER_02: didn't @ 0:12:03
- SPEAKER_02: know @ 0:12:03
- SPEAKER_02: any @ 0:12:03
- SPEAKER_02: of @ 0:12:03
- SPEAKER_02: these @ 0:12:03
- SPEAKER_02: scientific @ 0:12:03
- SPEAKER_02: ideas @ 0:12:04
- SPEAKER_02: or @ 0:12:04
- SPEAKER_02: any @ 0:12:04
- SPEAKER_02: novel @ 0:12:05
- SPEAKER_02: ideas. @ 0:12:05

## Segment 177: [0:12:06 - 0:12:08] (SPEAKER_02)

So a lot of people who tried it brushed it off, because it was like, oh, it's shitty.

### Word‑level timestamps

- SPEAKER_02: So @ 0:12:06
- SPEAKER_02: a @ 0:12:06
- SPEAKER_02: lot @ 0:12:06
- SPEAKER_02: of @ 0:12:06
- SPEAKER_02: people @ 0:12:06
- SPEAKER_02: who @ 0:12:06
- SPEAKER_02: tried @ 0:12:06
- SPEAKER_02: it @ 0:12:07
- SPEAKER_02: brushed @ 0:12:07
- SPEAKER_02: it @ 0:12:07
- SPEAKER_02: off, @ 0:12:07
- SPEAKER_02: because @ 0:12:07
- SPEAKER_02: it @ 0:12:07
- SPEAKER_02: was @ 0:12:08
- SPEAKER_02: like, @ 0:12:08
- SPEAKER_02: oh, @ 0:12:08
- SPEAKER_02: it's @ 0:12:08
- SPEAKER_02: shitty. @ 0:12:08

## Segment 178: [0:12:09 - 0:12:10] (SPEAKER_02)

It doesn't know anything.

### Word‑level timestamps

- SPEAKER_02: It @ 0:12:09
- SPEAKER_02: doesn't @ 0:12:09
- SPEAKER_02: know @ 0:12:09
- SPEAKER_02: anything. @ 0:12:09

## Segment 179: [0:12:10 - 0:12:13] (SPEAKER_02)

They were right, but a lot of people tried it at the start and brushed it off.

### Word‑level timestamps

- SPEAKER_02: They @ 0:12:10
- SPEAKER_02: were @ 0:12:10
- SPEAKER_02: right, @ 0:12:10
- SPEAKER_02: but @ 0:12:11
- SPEAKER_02: a @ 0:12:11
- SPEAKER_02: lot @ 0:12:11
- SPEAKER_02: of @ 0:12:11
- SPEAKER_02: people @ 0:12:11
- SPEAKER_02: tried @ 0:12:12
- SPEAKER_02: it @ 0:12:12
- SPEAKER_02: at @ 0:12:12
- SPEAKER_02: the @ 0:12:12
- SPEAKER_02: start @ 0:12:12
- SPEAKER_02: and @ 0:12:13
- SPEAKER_02: brushed @ 0:12:13
- SPEAKER_02: it @ 0:12:13
- SPEAKER_02: off. @ 0:12:13

## Segment 180: [0:12:14 - 0:12:17] (SPEAKER_02)

My perspective on it was I don't know anything.

### Word‑level timestamps

- SPEAKER_02: My @ 0:12:14
- SPEAKER_02: perspective @ 0:12:14
- SPEAKER_02: on @ 0:12:15
- SPEAKER_02: it @ 0:12:15
- SPEAKER_02: was @ 0:12:15
- SPEAKER_02: I @ 0:12:15
- SPEAKER_02: don't @ 0:12:15
- SPEAKER_02: know @ 0:12:16
- SPEAKER_02: anything. @ 0:12:16

## Segment 181: [0:12:17 - 0:12:19] (SPEAKER_02)

But this model kind of knows enough, right?

### Word‑level timestamps

- SPEAKER_02: But @ 0:12:17
- SPEAKER_02: this @ 0:12:17
- SPEAKER_02: model @ 0:12:18
- SPEAKER_02: kind @ 0:12:18
- SPEAKER_02: of @ 0:12:18
- SPEAKER_02: knows @ 0:12:18
- SPEAKER_02: enough, @ 0:12:18
- SPEAKER_02: right? @ 0:12:19

## Segment 182: [0:12:19 - 0:12:21] (SPEAKER_02)

I can talk to a computer, it understands my language.

### Word‑level timestamps

- SPEAKER_02: I @ 0:12:19
- SPEAKER_02: can @ 0:12:19
- SPEAKER_02: talk @ 0:12:19
- SPEAKER_02: to @ 0:12:19
- SPEAKER_02: a @ 0:12:20
- SPEAKER_02: computer, @ 0:12:20
- SPEAKER_02: it @ 0:12:20
- SPEAKER_02: understands @ 0:12:20
- SPEAKER_02: my @ 0:12:21
- SPEAKER_02: language. @ 0:12:21

## Segment 183: [0:12:21 - 0:12:25] (SPEAKER_02)

That was enough for me to understand that this technology came out.

### Word‑level timestamps

- SPEAKER_02: That @ 0:12:21
- SPEAKER_02: was @ 0:12:21
- SPEAKER_02: enough @ 0:12:22
- SPEAKER_02: for @ 0:12:22
- SPEAKER_02: me @ 0:12:22
- SPEAKER_02: to @ 0:12:22
- SPEAKER_02: understand @ 0:12:23
- SPEAKER_02: that @ 0:12:24
- SPEAKER_02: this @ 0:12:24
- SPEAKER_02: technology @ 0:12:24
- SPEAKER_02: came @ 0:12:25
- SPEAKER_02: out. @ 0:12:25

## Segment 184: [0:12:26 - 0:12:29] (SPEAKER_02)

This technology has no choice but to get better and better.

### Word‑level timestamps

- SPEAKER_02: This @ 0:12:26
- SPEAKER_02: technology @ 0:12:26
- SPEAKER_02: has @ 0:12:27
- SPEAKER_02: no @ 0:12:27
- SPEAKER_02: choice @ 0:12:27
- SPEAKER_02: but @ 0:12:28
- SPEAKER_02: to @ 0:12:28
- SPEAKER_02: get @ 0:12:28
- SPEAKER_02: better @ 0:12:28
- SPEAKER_02: and @ 0:12:28
- SPEAKER_02: better. @ 0:12:29

## Segment 185: [0:12:30 - 0:12:33] (SPEAKER_02)

So this hypothesis I had in my head was

### Word‑level timestamps

- SPEAKER_02: So @ 0:12:30
- SPEAKER_02: this @ 0:12:30
- SPEAKER_02: hypothesis @ 0:12:30
- SPEAKER_02: I @ 0:12:31
- SPEAKER_02: had @ 0:12:31
- SPEAKER_02: in @ 0:12:32
- SPEAKER_02: my @ 0:12:32
- SPEAKER_02: head @ 0:12:32
- SPEAKER_02: was @ 0:12:32

## Segment 186: [0:12:33 - 0:12:44] (SPEAKER_02)

If I learn as much as I can now with this current model, then by the time the next model comes out, which is going to be inevitably smarter, then I'll understand more concepts.

### Word‑level timestamps

- SPEAKER_02: If @ 0:12:33
- SPEAKER_02: I @ 0:12:34
- SPEAKER_02: learn @ 0:12:34
- SPEAKER_02: as @ 0:12:35
- SPEAKER_02: much @ 0:12:35
- SPEAKER_02: as @ 0:12:35
- SPEAKER_02: I @ 0:12:35
- SPEAKER_02: can @ 0:12:35
- SPEAKER_02: now @ 0:12:36
- SPEAKER_02: with @ 0:12:36
- SPEAKER_02: this @ 0:12:36
- SPEAKER_02: current @ 0:12:36
- SPEAKER_02: model, @ 0:12:37
- SPEAKER_02: then @ 0:12:38
- SPEAKER_02: by @ 0:12:38
- SPEAKER_02: the @ 0:12:38
- SPEAKER_02: time @ 0:12:38
- SPEAKER_02: the @ 0:12:38
- SPEAKER_02: next @ 0:12:38
- SPEAKER_02: model @ 0:12:39
- SPEAKER_02: comes @ 0:12:39
- SPEAKER_02: out, @ 0:12:39
- SPEAKER_02: which @ 0:12:39
- SPEAKER_02: is @ 0:12:39
- SPEAKER_02: going @ 0:12:40
- SPEAKER_02: to @ 0:12:40
- SPEAKER_02: be @ 0:12:40
- SPEAKER_02: inevitably @ 0:12:40
- SPEAKER_02: smarter, @ 0:12:41
- SPEAKER_02: then @ 0:12:42
- SPEAKER_02: I'll @ 0:12:42
- SPEAKER_02: understand @ 0:12:42
- SPEAKER_02: more @ 0:12:42
- SPEAKER_02: concepts. @ 0:12:44

## Segment 187: [0:12:44 - 0:12:46] (SPEAKER_02)

I'll understand how to use it more.

### Word‑level timestamps

- SPEAKER_02: I'll @ 0:12:44
- SPEAKER_02: understand @ 0:12:44
- SPEAKER_02: how @ 0:12:45
- SPEAKER_02: to @ 0:12:45
- SPEAKER_02: use @ 0:12:45
- SPEAKER_02: it @ 0:12:45
- SPEAKER_02: more. @ 0:12:45

## Segment 188: [0:12:46 - 0:12:47] (SPEAKER_02)

It'll be more capable.

### Word‑level timestamps

- SPEAKER_02: It'll @ 0:12:46
- SPEAKER_02: be @ 0:12:46
- SPEAKER_02: more @ 0:12:46
- SPEAKER_02: capable. @ 0:12:46

## Segment 189: [0:12:47 - 0:12:48] (SPEAKER_02)

I could do more.

### Word‑level timestamps

- SPEAKER_02: I @ 0:12:47
- SPEAKER_02: could @ 0:12:47
- SPEAKER_02: do @ 0:12:47
- SPEAKER_02: more. @ 0:12:47

## Segment 190: [0:12:48 - 0:12:53] (SPEAKER_02)

And then about three months after the first model, GBT4 came out.

### Word‑level timestamps

- SPEAKER_02: And @ 0:12:48
- SPEAKER_02: then @ 0:12:48
- SPEAKER_02: about @ 0:12:48
- SPEAKER_02: three @ 0:12:49
- SPEAKER_02: months @ 0:12:50
- SPEAKER_02: after @ 0:12:51
- SPEAKER_02: the @ 0:12:51
- SPEAKER_02: first @ 0:12:51
- SPEAKER_02: model, @ 0:12:51
- SPEAKER_02: GBT4 @ 0:12:52
- SPEAKER_02: came @ 0:12:52
- SPEAKER_02: out. @ 0:12:53

## Segment 191: [0:12:53 - 0:12:55] (SPEAKER_02)

And that was the lead from a high schooler.

### Word‑level timestamps

- SPEAKER_02: And @ 0:12:53
- SPEAKER_02: that @ 0:12:53
- SPEAKER_02: was @ 0:12:53
- SPEAKER_02: the @ 0:12:53
- SPEAKER_02: lead @ 0:12:54
- SPEAKER_02: from @ 0:12:54
- SPEAKER_02: a @ 0:12:54
- SPEAKER_02: high @ 0:12:54
- SPEAKER_02: schooler. @ 0:12:54

## Segment 192: [0:12:55 - 0:13:02] (SPEAKER_02)

So it's still dumb, like college junior or college sophomore, but I was able to do a lot more than the previously couldn't.

### Word‑level timestamps

- SPEAKER_02: So @ 0:12:55
- SPEAKER_02: it's @ 0:12:56
- SPEAKER_02: still @ 0:12:56
- SPEAKER_02: dumb, @ 0:12:56
- SPEAKER_02: like @ 0:12:56
- SPEAKER_02: college @ 0:12:57
- SPEAKER_02: junior @ 0:12:58
- SPEAKER_02: or @ 0:12:58
- SPEAKER_02: college @ 0:12:58
- SPEAKER_02: sophomore, @ 0:12:58
- SPEAKER_02: but @ 0:12:59
- SPEAKER_02: I @ 0:12:59
- SPEAKER_02: was @ 0:13:00
- SPEAKER_02: able @ 0:13:00
- SPEAKER_02: to @ 0:13:00
- SPEAKER_02: do @ 0:13:00
- SPEAKER_02: a @ 0:13:00
- SPEAKER_02: lot @ 0:13:00
- SPEAKER_02: more @ 0:13:00
- SPEAKER_02: than @ 0:13:01
- SPEAKER_02: the @ 0:13:01
- SPEAKER_02: previously @ 0:13:01
- SPEAKER_02: couldn't. @ 0:13:01

## Segment 193: [0:13:02 - 0:13:03] (SPEAKER_02)

I was doing code bases I couldn't do before.

### Word‑level timestamps

- SPEAKER_02: I @ 0:13:02
- SPEAKER_02: was @ 0:13:02
- SPEAKER_02: doing @ 0:13:02
- SPEAKER_02: code @ 0:13:02
- SPEAKER_02: bases @ 0:13:02
- SPEAKER_02: I @ 0:13:03
- SPEAKER_02: couldn't @ 0:13:03
- SPEAKER_02: do @ 0:13:03
- SPEAKER_02: before. @ 0:13:03

## Segment 194: [0:13:04 - 0:13:06] (SPEAKER_02)

It was giving me creative ideas I couldn't do before.

### Word‑level timestamps

- SPEAKER_02: It @ 0:13:04
- SPEAKER_02: was @ 0:13:04
- SPEAKER_02: giving @ 0:13:04
- SPEAKER_02: me @ 0:13:04
- SPEAKER_02: creative @ 0:13:04
- SPEAKER_02: ideas @ 0:13:04
- SPEAKER_02: I @ 0:13:05
- SPEAKER_02: couldn't @ 0:13:05
- SPEAKER_02: do @ 0:13:05
- SPEAKER_02: before. @ 0:13:05

## Segment 195: [0:13:06 - 0:13:10] (SPEAKER_02)

Even role playing, I had these Discord bots in my Bitcoin Booze Discord.

### Word‑level timestamps

- SPEAKER_02: Even @ 0:13:06
- SPEAKER_02: role @ 0:13:06
- SPEAKER_02: playing, @ 0:13:06
- SPEAKER_02: I @ 0:13:07
- SPEAKER_02: had @ 0:13:07
- SPEAKER_02: these @ 0:13:07
- SPEAKER_02: Discord @ 0:13:08
- SPEAKER_02: bots @ 0:13:08
- SPEAKER_02: in @ 0:13:09
- SPEAKER_02: my @ 0:13:09
- SPEAKER_02: Bitcoin @ 0:13:09
- SPEAKER_02: Booze @ 0:13:09
- SPEAKER_02: Discord. @ 0:13:10

## Segment 196: [0:13:10 - 0:13:17] (SPEAKER_02)

And even role playing was so much better and it felt much more real and much more fun and it just sounded less dumb.

### Word‑level timestamps

- SPEAKER_02: And @ 0:13:10
- SPEAKER_02: even @ 0:13:10
- SPEAKER_02: role @ 0:13:10
- SPEAKER_02: playing @ 0:13:11
- SPEAKER_02: was @ 0:13:11
- SPEAKER_02: so @ 0:13:12
- SPEAKER_02: much @ 0:13:12
- SPEAKER_02: better @ 0:13:12
- SPEAKER_02: and @ 0:13:12
- SPEAKER_02: it @ 0:13:12
- SPEAKER_02: felt @ 0:13:13
- SPEAKER_02: much @ 0:13:13
- SPEAKER_02: more @ 0:13:13
- SPEAKER_02: real @ 0:13:13
- SPEAKER_02: and @ 0:13:14
- SPEAKER_02: much @ 0:13:14
- SPEAKER_02: more @ 0:13:14
- SPEAKER_02: fun @ 0:13:14
- SPEAKER_02: and @ 0:13:15
- SPEAKER_02: it @ 0:13:15
- SPEAKER_02: just @ 0:13:15
- SPEAKER_02: sounded @ 0:13:15
- SPEAKER_02: less @ 0:13:16
- SPEAKER_02: dumb. @ 0:13:16

## Segment 197: [0:13:17 - 0:13:26] (SPEAKER_02)

And then I just got in that loop where I would gain more knowledge, and then a smarter model would come out, and that smarter model would be able to teach me more knowledge, and then I add more knowledge, and then a smarter model came out.

### Word‑level timestamps

- SPEAKER_02: And @ 0:13:17
- SPEAKER_02: then @ 0:13:17
- SPEAKER_02: I @ 0:13:17
- SPEAKER_02: just @ 0:13:18
- SPEAKER_02: got @ 0:13:18
- SPEAKER_02: in @ 0:13:18
- SPEAKER_02: that @ 0:13:18
- SPEAKER_02: loop @ 0:13:18
- SPEAKER_02: where @ 0:13:18
- SPEAKER_02: I @ 0:13:19
- SPEAKER_02: would @ 0:13:19
- SPEAKER_02: gain @ 0:13:19
- SPEAKER_02: more @ 0:13:19
- SPEAKER_02: knowledge, @ 0:13:20
- SPEAKER_02: and @ 0:13:20
- SPEAKER_02: then @ 0:13:20
- SPEAKER_02: a @ 0:13:20
- SPEAKER_02: smarter @ 0:13:20
- SPEAKER_02: model @ 0:13:21
- SPEAKER_02: would @ 0:13:21
- SPEAKER_02: come @ 0:13:21
- SPEAKER_02: out, @ 0:13:21
- SPEAKER_02: and @ 0:13:22
- SPEAKER_02: that @ 0:13:22
- SPEAKER_02: smarter @ 0:13:22
- SPEAKER_02: model @ 0:13:22
- SPEAKER_02: would @ 0:13:22
- SPEAKER_02: be @ 0:13:23
- SPEAKER_02: able @ 0:13:23
- SPEAKER_02: to @ 0:13:23
- SPEAKER_02: teach @ 0:13:23
- SPEAKER_02: me @ 0:13:23
- SPEAKER_02: more @ 0:13:23
- SPEAKER_02: knowledge, @ 0:13:23
- SPEAKER_02: and @ 0:13:24
- SPEAKER_02: then @ 0:13:24
- SPEAKER_02: I @ 0:13:24
- SPEAKER_02: add @ 0:13:24
- SPEAKER_02: more @ 0:13:24
- SPEAKER_02: knowledge, @ 0:13:24
- SPEAKER_02: and @ 0:13:25
- SPEAKER_02: then @ 0:13:25
- SPEAKER_02: a @ 0:13:25
- SPEAKER_02: smarter @ 0:13:25
- SPEAKER_02: model @ 0:13:25
- SPEAKER_02: came @ 0:13:26
- SPEAKER_02: out. @ 0:13:26

## Segment 198: [0:13:26 - 0:13:28] (SPEAKER_02)

And it's a self loop that keeps going.

### Word‑level timestamps

- SPEAKER_02: And @ 0:13:26
- SPEAKER_02: it's @ 0:13:27
- SPEAKER_02: a @ 0:13:27
- SPEAKER_02: self @ 0:13:27
- SPEAKER_02: loop @ 0:13:27
- SPEAKER_02: that @ 0:13:28
- SPEAKER_02: keeps @ 0:13:28
- SPEAKER_02: going. @ 0:13:28

## Segment 199: [0:13:28 - 0:13:31] (SPEAKER_02)

For example, yesterday 03 came out.

### Word‑level timestamps

- SPEAKER_02: For @ 0:13:28
- SPEAKER_02: example, @ 0:13:29
- SPEAKER_02: yesterday @ 0:13:30
- SPEAKER_02: 03 @ 0:13:30
- SPEAKER_02: came @ 0:13:31
- SPEAKER_02: out. @ 0:13:31

## Segment 200: [0:13:31 - 0:13:34] (SPEAKER_02)

Do any of you guys know or heard about 03 at all?

### Word‑level timestamps

- SPEAKER_02: Do @ 0:13:31
- SPEAKER_02: any @ 0:13:32
- SPEAKER_02: of @ 0:13:32
- SPEAKER_02: you @ 0:13:32
- SPEAKER_02: guys @ 0:13:32
- SPEAKER_02: know @ 0:13:32
- SPEAKER_02: or @ 0:13:32
- SPEAKER_02: heard @ 0:13:32
- SPEAKER_02: about @ 0:13:33
- SPEAKER_02: 03 @ 0:13:33
- SPEAKER_02: at @ 0:13:34
- SPEAKER_02: all? @ 0:13:34

## Segment 201: [0:13:35 - 0:13:36] (SPEAKER_02)

That's so crazy, bro.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:13:35
- SPEAKER_02: so @ 0:13:36
- SPEAKER_02: crazy, @ 0:13:36
- SPEAKER_02: bro. @ 0:13:36

## Segment 202: [0:13:37 - 0:13:38] (SPEAKER_02)

OK, you are OK.

### Word‑level timestamps

- SPEAKER_02: OK, @ 0:13:37
- SPEAKER_02: you @ 0:13:37
- SPEAKER_02: are @ 0:13:37
- SPEAKER_02: OK. @ 0:13:37

## Segment 203: [0:13:38 - 0:13:39] (SPEAKER_02)

I don't case either of it.

### Word‑level timestamps

- SPEAKER_02: I @ 0:13:38
- SPEAKER_02: don't @ 0:13:38
- SPEAKER_02: case @ 0:13:38
- SPEAKER_02: either @ 0:13:38
- SPEAKER_02: of @ 0:13:38
- SPEAKER_02: it. @ 0:13:39

## Segment 204: [0:13:39 - 0:13:47] (SPEAKER_02)

But to me, I'm in this such niche side bubble in my head where I'm just so immersed in AI news every day that I don't really know what people don't know.

### Word‑level timestamps

- SPEAKER_02: But @ 0:13:39
- SPEAKER_02: to @ 0:13:39
- SPEAKER_02: me, @ 0:13:39
- SPEAKER_02: I'm @ 0:13:39
- SPEAKER_02: in @ 0:13:39
- SPEAKER_02: this @ 0:13:40
- SPEAKER_02: such @ 0:13:40
- SPEAKER_02: niche @ 0:13:40
- SPEAKER_02: side @ 0:13:41
- SPEAKER_02: bubble @ 0:13:41
- SPEAKER_02: in @ 0:13:41
- SPEAKER_02: my @ 0:13:41
- SPEAKER_02: head @ 0:13:41
- SPEAKER_02: where @ 0:13:42
- SPEAKER_02: I'm @ 0:13:42
- SPEAKER_02: just @ 0:13:42
- SPEAKER_02: so @ 0:13:43
- SPEAKER_02: immersed @ 0:13:43
- SPEAKER_02: in @ 0:13:43
- SPEAKER_02: AI @ 0:13:43
- SPEAKER_02: news @ 0:13:44
- SPEAKER_02: every @ 0:13:44
- SPEAKER_02: day @ 0:13:44
- SPEAKER_02: that @ 0:13:44
- SPEAKER_02: I @ 0:13:45
- SPEAKER_02: don't @ 0:13:45
- SPEAKER_02: really @ 0:13:45
- SPEAKER_02: know @ 0:13:46
- SPEAKER_02: what @ 0:13:46
- SPEAKER_02: people @ 0:13:46
- SPEAKER_02: don't @ 0:13:46
- SPEAKER_02: know. @ 0:13:47

## Segment 205: [0:13:47 - 0:13:51] (SPEAKER_02)

03 is a really intelligent AI model that came out yesterday.

### Word‑level timestamps

- SPEAKER_02: 03 @ 0:13:47
- SPEAKER_02: is @ 0:13:48
- SPEAKER_02: a @ 0:13:48
- SPEAKER_02: really @ 0:13:49
- SPEAKER_02: intelligent @ 0:13:49
- SPEAKER_02: AI @ 0:13:50
- SPEAKER_02: model @ 0:13:50
- SPEAKER_02: that @ 0:13:50
- SPEAKER_02: came @ 0:13:51
- SPEAKER_02: out @ 0:13:51
- SPEAKER_02: yesterday. @ 0:13:51

## Segment 206: [0:13:51 - 0:13:53] (SPEAKER_02)

And the best.

### Word‑level timestamps

- SPEAKER_02: And @ 0:13:51
- SPEAKER_02: the @ 0:13:52
- SPEAKER_02: best. @ 0:13:52

## Segment 207: [0:13:53 - 0:14:00] (SPEAKER_02)

layman's way I could explain it is it's an AI model that has an IQ, maybe around 140.

### Word‑level timestamps

- SPEAKER_02: layman's @ 0:13:53
- SPEAKER_02: way @ 0:13:54
- SPEAKER_02: I @ 0:13:54
- SPEAKER_02: could @ 0:13:54
- SPEAKER_02: explain @ 0:13:54
- SPEAKER_02: it @ 0:13:54
- SPEAKER_02: is @ 0:13:54
- SPEAKER_02: it's @ 0:13:55
- SPEAKER_02: an @ 0:13:55
- SPEAKER_02: AI @ 0:13:56
- SPEAKER_02: model @ 0:13:56
- SPEAKER_02: that @ 0:13:56
- SPEAKER_02: has @ 0:13:57
- SPEAKER_02: an @ 0:13:58
- SPEAKER_02: IQ, @ 0:13:58
- SPEAKER_02: maybe @ 0:13:58
- SPEAKER_02: around @ 0:13:59
- SPEAKER_02: 140. @ 0:14:00

## Segment 208: [0:14:00 - 0:14:12] (SPEAKER_02)

It was able to score a 2700 on the codes for its competition benchmark, which basically means it's a top 200 coder worldwide in terms of solving really complex code problems.

### Word‑level timestamps

- SPEAKER_02: It @ 0:14:00
- SPEAKER_02: was @ 0:14:01
- SPEAKER_02: able @ 0:14:01
- SPEAKER_02: to @ 0:14:02
- SPEAKER_02: score @ 0:14:02
- SPEAKER_02: a @ 0:14:02
- SPEAKER_02: 2700 @ 0:14:02
- SPEAKER_02: on @ 0:14:03
- SPEAKER_02: the @ 0:14:03
- SPEAKER_02: codes @ 0:14:04
- SPEAKER_02: for @ 0:14:04
- SPEAKER_02: its @ 0:14:05
- SPEAKER_02: competition @ 0:14:05
- SPEAKER_02: benchmark, @ 0:14:06
- SPEAKER_02: which @ 0:14:07
- SPEAKER_02: basically @ 0:14:07
- SPEAKER_02: means @ 0:14:08
- SPEAKER_02: it's @ 0:14:08
- SPEAKER_02: a @ 0:14:08
- SPEAKER_02: top @ 0:14:08
- SPEAKER_02: 200 @ 0:14:09
- SPEAKER_02: coder @ 0:14:09
- SPEAKER_02: worldwide @ 0:14:09
- SPEAKER_02: in @ 0:14:10
- SPEAKER_02: terms @ 0:14:10
- SPEAKER_02: of @ 0:14:11
- SPEAKER_02: solving @ 0:14:11
- SPEAKER_02: really @ 0:14:11
- SPEAKER_02: complex @ 0:14:11
- SPEAKER_02: code @ 0:14:12
- SPEAKER_02: problems. @ 0:14:12

## Segment 209: [0:14:13 - 0:14:14] (SPEAKER_02)

And it was just

### Word‑level timestamps

- SPEAKER_02: And @ 0:14:13
- SPEAKER_02: it @ 0:14:13
- SPEAKER_02: was @ 0:14:13
- SPEAKER_02: just @ 0:14:13

## Segment 210: [0:14:14 - 0:14:20] (SPEAKER_02)

September that the idea, the technology and research of an AI that could actually think and reason came out.

### Word‑level timestamps

- SPEAKER_02: September @ 0:14:14
- SPEAKER_02: that @ 0:14:15
- SPEAKER_02: the @ 0:14:15
- SPEAKER_02: idea, @ 0:14:15
- SPEAKER_02: the @ 0:14:15
- SPEAKER_02: technology @ 0:14:16
- SPEAKER_02: and @ 0:14:17
- SPEAKER_02: research @ 0:14:17
- SPEAKER_02: of @ 0:14:17
- SPEAKER_02: an @ 0:14:17
- SPEAKER_02: AI @ 0:14:18
- SPEAKER_02: that @ 0:14:18
- SPEAKER_02: could @ 0:14:18
- SPEAKER_02: actually @ 0:14:18
- SPEAKER_02: think @ 0:14:19
- SPEAKER_02: and @ 0:14:19
- SPEAKER_02: reason @ 0:14:19
- SPEAKER_02: came @ 0:14:19
- SPEAKER_02: out. @ 0:14:20

## Segment 211: [0:14:20 - 0:14:23] (SPEAKER_02)

And only in six months we've gained drastic improvements.

### Word‑level timestamps

- SPEAKER_02: And @ 0:14:20
- SPEAKER_02: only @ 0:14:20
- SPEAKER_02: in @ 0:14:21
- SPEAKER_02: six @ 0:14:21
- SPEAKER_02: months @ 0:14:21
- SPEAKER_02: we've @ 0:14:21
- SPEAKER_02: gained @ 0:14:22
- SPEAKER_02: drastic @ 0:14:22
- SPEAKER_02: improvements. @ 0:14:23

## Segment 212: [0:14:23 - 0:14:30] (SPEAKER_02)

And the most interesting part about this tech is AI researchers basically discovered there's no ceiling to the amount of knowledge that comes out of these models.

### Word‑level timestamps

- SPEAKER_02: And @ 0:14:23
- SPEAKER_02: the @ 0:14:23
- SPEAKER_02: most @ 0:14:23
- SPEAKER_02: interesting @ 0:14:23
- SPEAKER_02: part @ 0:14:24
- SPEAKER_02: about @ 0:14:24
- SPEAKER_02: this @ 0:14:24
- SPEAKER_02: tech @ 0:14:24
- SPEAKER_02: is @ 0:14:25
- SPEAKER_02: AI @ 0:14:25
- SPEAKER_02: researchers @ 0:14:26
- SPEAKER_02: basically @ 0:14:26
- SPEAKER_02: discovered @ 0:14:27
- SPEAKER_02: there's @ 0:14:27
- SPEAKER_02: no @ 0:14:27
- SPEAKER_02: ceiling @ 0:14:27
- SPEAKER_02: to @ 0:14:28
- SPEAKER_02: the @ 0:14:28
- SPEAKER_02: amount @ 0:14:28
- SPEAKER_02: of @ 0:14:28
- SPEAKER_02: knowledge @ 0:14:28
- SPEAKER_02: that @ 0:14:29
- SPEAKER_02: comes @ 0:14:29
- SPEAKER_02: out @ 0:14:29
- SPEAKER_02: of @ 0:14:30
- SPEAKER_02: these @ 0:14:30
- SPEAKER_02: models. @ 0:14:30

## Segment 213: [0:14:31 - 0:14:34] (SPEAKER_02)

It's called test time compute, the more power and the more.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:14:31
- SPEAKER_02: called @ 0:14:31
- SPEAKER_02: test @ 0:14:31
- SPEAKER_02: time @ 0:14:31
- SPEAKER_02: compute, @ 0:14:31
- SPEAKER_02: the @ 0:14:32
- SPEAKER_02: more @ 0:14:32
- SPEAKER_02: power @ 0:14:32
- SPEAKER_02: and @ 0:14:33
- SPEAKER_02: the @ 0:14:33
- SPEAKER_02: more. @ 0:14:33

## Segment 214: [0:14:34 - 0:14:51] (SPEAKER_02)

time you allow these models to think just like us the more intelligent the output is and so far they're like yeah we don't really know what the ceiling is bro it could keep going but yeah new model came out yesterday and that's honestly made me a couple multiplier x's more efficient

### Word‑level timestamps

- SPEAKER_02: time @ 0:14:34
- SPEAKER_02: you @ 0:14:35
- SPEAKER_02: allow @ 0:14:35
- SPEAKER_02: these @ 0:14:35
- SPEAKER_02: models @ 0:14:36
- SPEAKER_02: to @ 0:14:36
- SPEAKER_02: think @ 0:14:36
- SPEAKER_02: just @ 0:14:37
- SPEAKER_02: like @ 0:14:37
- SPEAKER_02: us @ 0:14:37
- SPEAKER_02: the @ 0:14:38
- SPEAKER_02: more @ 0:14:38
- SPEAKER_02: intelligent @ 0:14:38
- SPEAKER_02: the @ 0:14:39
- SPEAKER_02: output @ 0:14:39
- SPEAKER_02: is @ 0:14:39
- SPEAKER_02: and @ 0:14:39
- SPEAKER_02: so @ 0:14:40
- SPEAKER_02: far @ 0:14:40
- SPEAKER_02: they're @ 0:14:41
- SPEAKER_02: like @ 0:14:41
- SPEAKER_02: yeah @ 0:14:41
- SPEAKER_02: we @ 0:14:41
- SPEAKER_02: don't @ 0:14:41
- SPEAKER_02: really @ 0:14:42
- SPEAKER_02: know @ 0:14:42
- SPEAKER_02: what @ 0:14:42
- SPEAKER_02: the @ 0:14:42
- SPEAKER_02: ceiling @ 0:14:42
- SPEAKER_02: is @ 0:14:42
- SPEAKER_02: bro @ 0:14:43
- SPEAKER_02: it @ 0:14:43
- SPEAKER_02: could @ 0:14:43
- SPEAKER_02: keep @ 0:14:43
- SPEAKER_02: going @ 0:14:43
- SPEAKER_02: but @ 0:14:44
- SPEAKER_02: yeah @ 0:14:44
- SPEAKER_02: new @ 0:14:44
- SPEAKER_02: model @ 0:14:45
- SPEAKER_02: came @ 0:14:45
- SPEAKER_02: out @ 0:14:45
- SPEAKER_02: yesterday @ 0:14:45
- SPEAKER_02: and @ 0:14:46
- SPEAKER_02: that's @ 0:14:46
- SPEAKER_02: honestly @ 0:14:46
- SPEAKER_02: made @ 0:14:47
- SPEAKER_02: me @ 0:14:47
- SPEAKER_02: a @ 0:14:48
- SPEAKER_02: couple @ 0:14:48
- SPEAKER_02: multiplier @ 0:14:49
- SPEAKER_02: x's @ 0:14:50
- SPEAKER_02: more @ 0:14:50
- SPEAKER_02: efficient @ 0:14:50

## Segment 215: [0:14:53 - 0:14:54] (SPEAKER_02)

So this is a cute little example.

### Word‑level timestamps

- SPEAKER_02: So @ 0:14:53
- SPEAKER_02: this @ 0:14:53
- SPEAKER_02: is @ 0:14:53
- SPEAKER_02: a @ 0:14:53
- SPEAKER_02: cute @ 0:14:54
- SPEAKER_02: little @ 0:14:54
- SPEAKER_02: example. @ 0:14:54

## Segment 216: [0:14:55 - 0:14:57] (SPEAKER_02)

This is my nine-year-old son, Axel.

### Word‑level timestamps

- SPEAKER_02: This @ 0:14:55
- SPEAKER_02: is @ 0:14:55
- SPEAKER_02: my @ 0:14:55
- SPEAKER_02: nine-year-old @ 0:14:55
- SPEAKER_02: son, @ 0:14:56
- SPEAKER_02: Axel. @ 0:14:56

## Segment 217: [0:14:57 - 0:15:05] (SPEAKER_02)

I don't have a nine-year-old son, but someone's nine-year-old kid just vibe-coded this 2048 fruit game using just his words.

### Word‑level timestamps

- SPEAKER_02: I @ 0:14:57
- SPEAKER_02: don't @ 0:14:57
- SPEAKER_02: have @ 0:14:57
- SPEAKER_02: a @ 0:14:57
- SPEAKER_02: nine-year-old @ 0:14:57
- SPEAKER_02: son, @ 0:14:58
- SPEAKER_02: but @ 0:14:58
- SPEAKER_02: someone's @ 0:14:58
- SPEAKER_02: nine-year-old @ 0:14:58
- SPEAKER_02: kid @ 0:14:59
- SPEAKER_02: just @ 0:14:59
- SPEAKER_02: vibe-coded @ 0:15:00
- SPEAKER_02: this @ 0:15:00
- SPEAKER_02: 2048 @ 0:15:01
- SPEAKER_02: fruit @ 0:15:02
- SPEAKER_02: game @ 0:15:03
- SPEAKER_02: using @ 0:15:03
- SPEAKER_02: just @ 0:15:04
- SPEAKER_02: his @ 0:15:04
- SPEAKER_02: words. @ 0:15:04

## Segment 218: [0:15:05 - 0:15:08] (SPEAKER_02)

Oh, I want to play 2048, but like in a fruit bowl.

### Word‑level timestamps

- SPEAKER_02: Oh, @ 0:15:05
- SPEAKER_02: I @ 0:15:05
- SPEAKER_02: want @ 0:15:05
- SPEAKER_02: to @ 0:15:05
- SPEAKER_02: play @ 0:15:06
- SPEAKER_02: 2048, @ 0:15:06
- SPEAKER_02: but @ 0:15:07
- SPEAKER_02: like @ 0:15:07
- SPEAKER_02: in @ 0:15:07
- SPEAKER_02: a @ 0:15:07
- SPEAKER_02: fruit @ 0:15:07
- SPEAKER_02: bowl. @ 0:15:08

## Segment 219: [0:15:08 - 0:15:30] (SPEAKER_02)

I just recorded me playing it but bro a 9 year old kid had this fun interesting game idea that I've actually like playing for a while and says yeah you just told me this is actually me playing the game but all this 9 year old kid told the AI system and it used I think it used lovable for this all he said was I want a game where I could connect fruits together and then the fruits make a bigger

### Word‑level timestamps

- SPEAKER_02: I @ 0:15:08
- SPEAKER_02: just @ 0:15:09
- SPEAKER_02: recorded @ 0:15:09
- SPEAKER_02: me @ 0:15:09
- SPEAKER_02: playing @ 0:15:09
- SPEAKER_02: it @ 0:15:10
- SPEAKER_02: but @ 0:15:10
- SPEAKER_02: bro @ 0:15:10
- SPEAKER_02: a @ 0:15:10
- SPEAKER_02: 9 @ 0:15:10
- SPEAKER_02: year @ 0:15:11
- SPEAKER_02: old @ 0:15:11
- SPEAKER_02: kid @ 0:15:11
- SPEAKER_02: had @ 0:15:11
- SPEAKER_02: this @ 0:15:12
- SPEAKER_02: fun @ 0:15:12
- SPEAKER_02: interesting @ 0:15:13
- SPEAKER_02: game @ 0:15:13
- SPEAKER_02: idea @ 0:15:13
- SPEAKER_02: that @ 0:15:14
- SPEAKER_02: I've @ 0:15:14
- SPEAKER_02: actually @ 0:15:14
- SPEAKER_02: like @ 0:15:15
- SPEAKER_02: playing @ 0:15:15
- SPEAKER_02: for @ 0:15:15
- SPEAKER_02: a @ 0:15:15
- SPEAKER_02: while @ 0:15:15
- SPEAKER_02: and @ 0:15:16
- SPEAKER_02: says @ 0:15:16
- SPEAKER_02: yeah @ 0:15:17
- SPEAKER_02: you @ 0:15:17
- SPEAKER_02: just @ 0:15:17
- SPEAKER_02: told @ 0:15:17
- SPEAKER_02: me @ 0:15:18
- SPEAKER_02: this @ 0:15:18
- SPEAKER_02: is @ 0:15:19
- SPEAKER_02: actually @ 0:15:19
- SPEAKER_02: me @ 0:15:19
- SPEAKER_02: playing @ 0:15:19
- SPEAKER_02: the @ 0:15:20
- SPEAKER_02: game @ 0:15:20
- SPEAKER_02: but @ 0:15:20
- SPEAKER_02: all @ 0:15:20
- SPEAKER_02: this @ 0:15:21
- SPEAKER_02: 9 @ 0:15:21
- SPEAKER_02: year @ 0:15:21
- SPEAKER_02: old @ 0:15:21
- SPEAKER_02: kid @ 0:15:21
- SPEAKER_02: told @ 0:15:22
- SPEAKER_02: the @ 0:15:22
- SPEAKER_02: AI @ 0:15:22
- SPEAKER_02: system @ 0:15:22
- SPEAKER_02: and @ 0:15:23
- SPEAKER_02: it @ 0:15:23
- SPEAKER_02: used @ 0:15:23
- SPEAKER_02: I @ 0:15:23
- SPEAKER_02: think @ 0:15:23
- SPEAKER_02: it @ 0:15:24
- SPEAKER_02: used @ 0:15:24
- SPEAKER_02: lovable @ 0:15:24
- SPEAKER_02: for @ 0:15:25
- SPEAKER_02: this @ 0:15:25
- SPEAKER_02: all @ 0:15:25
- SPEAKER_02: he @ 0:15:26
- SPEAKER_02: said @ 0:15:26
- SPEAKER_02: was @ 0:15:26
- SPEAKER_02: I @ 0:15:26
- SPEAKER_02: want @ 0:15:26
- SPEAKER_02: a @ 0:15:26
- SPEAKER_02: game @ 0:15:27
- SPEAKER_02: where @ 0:15:27
- SPEAKER_02: I @ 0:15:27
- SPEAKER_02: could @ 0:15:27
- SPEAKER_02: connect @ 0:15:27
- SPEAKER_02: fruits @ 0:15:28
- SPEAKER_02: together @ 0:15:28
- SPEAKER_02: and @ 0:15:28
- SPEAKER_02: then @ 0:15:28
- SPEAKER_02: the @ 0:15:29
- SPEAKER_02: fruits @ 0:15:29
- SPEAKER_02: make @ 0:15:29
- SPEAKER_02: a @ 0:15:29
- SPEAKER_02: bigger @ 0:15:29

## Segment 220: [0:15:29 - 0:15:39] (SPEAKER_02)

You don't really have to get too intense with the description because again, the smarter these models come out, the less you actually have to think and the more you can just do and the more you can just be creative with it.

### Word‑level timestamps

- SPEAKER_02: You @ 0:15:29
- SPEAKER_02: don't @ 0:15:30
- SPEAKER_02: really @ 0:15:30
- SPEAKER_02: have @ 0:15:30
- SPEAKER_02: to @ 0:15:30
- SPEAKER_02: get @ 0:15:30
- SPEAKER_02: too @ 0:15:30
- SPEAKER_02: intense @ 0:15:31
- SPEAKER_02: with @ 0:15:31
- SPEAKER_02: the @ 0:15:31
- SPEAKER_02: description @ 0:15:32
- SPEAKER_02: because @ 0:15:32
- SPEAKER_02: again, @ 0:15:33
- SPEAKER_02: the @ 0:15:33
- SPEAKER_02: smarter @ 0:15:33
- SPEAKER_02: these @ 0:15:33
- SPEAKER_02: models @ 0:15:33
- SPEAKER_02: come @ 0:15:34
- SPEAKER_02: out, @ 0:15:34
- SPEAKER_02: the @ 0:15:34
- SPEAKER_02: less @ 0:15:34
- SPEAKER_02: you @ 0:15:34
- SPEAKER_02: actually @ 0:15:35
- SPEAKER_02: have @ 0:15:35
- SPEAKER_02: to @ 0:15:35
- SPEAKER_02: think @ 0:15:36
- SPEAKER_02: and @ 0:15:36
- SPEAKER_02: the @ 0:15:36
- SPEAKER_02: more @ 0:15:36
- SPEAKER_02: you @ 0:15:36
- SPEAKER_02: can @ 0:15:36
- SPEAKER_02: just @ 0:15:37
- SPEAKER_02: do @ 0:15:37
- SPEAKER_02: and @ 0:15:37
- SPEAKER_02: the @ 0:15:37
- SPEAKER_02: more @ 0:15:37
- SPEAKER_02: you @ 0:15:37
- SPEAKER_02: can @ 0:15:38
- SPEAKER_02: just @ 0:15:38
- SPEAKER_02: be @ 0:15:38
- SPEAKER_02: creative @ 0:15:38
- SPEAKER_02: with @ 0:15:38
- SPEAKER_02: it. @ 0:15:39

## Segment 221: [0:15:40 - 0:15:45] (SPEAKER_02)

In terms of my current tech stack, I want to go in and explain how I personally use AI.

### Word‑level timestamps

- SPEAKER_02: In @ 0:15:40
- SPEAKER_02: terms @ 0:15:41
- SPEAKER_02: of @ 0:15:41
- SPEAKER_02: my @ 0:15:41
- SPEAKER_02: current @ 0:15:41
- SPEAKER_02: tech @ 0:15:42
- SPEAKER_02: stack, @ 0:15:42
- SPEAKER_02: I @ 0:15:43
- SPEAKER_02: want @ 0:15:43
- SPEAKER_02: to @ 0:15:43
- SPEAKER_02: go @ 0:15:43
- SPEAKER_02: in @ 0:15:43
- SPEAKER_02: and @ 0:15:44
- SPEAKER_02: explain @ 0:15:44
- SPEAKER_02: how @ 0:15:44
- SPEAKER_02: I @ 0:15:44
- SPEAKER_02: personally @ 0:15:44
- SPEAKER_02: use @ 0:15:45
- SPEAKER_02: AI. @ 0:15:45

## Segment 222: [0:15:46 - 0:15:51] (SPEAKER_02)

I guess using it every single day for the last two years, I've discovered a lot of personal tips and tricks.

### Word‑level timestamps

- SPEAKER_02: I @ 0:15:46
- SPEAKER_02: guess @ 0:15:46
- SPEAKER_02: using @ 0:15:46
- SPEAKER_02: it @ 0:15:47
- SPEAKER_02: every @ 0:15:47
- SPEAKER_02: single @ 0:15:47
- SPEAKER_02: day @ 0:15:47
- SPEAKER_02: for @ 0:15:47
- SPEAKER_02: the @ 0:15:48
- SPEAKER_02: last @ 0:15:48
- SPEAKER_02: two @ 0:15:48
- SPEAKER_02: years, @ 0:15:48
- SPEAKER_02: I've @ 0:15:49
- SPEAKER_02: discovered @ 0:15:49
- SPEAKER_02: a @ 0:15:49
- SPEAKER_02: lot @ 0:15:49
- SPEAKER_02: of @ 0:15:50
- SPEAKER_02: personal @ 0:15:50
- SPEAKER_02: tips @ 0:15:50
- SPEAKER_02: and @ 0:15:51
- SPEAKER_02: tricks. @ 0:15:51

## Segment 223: [0:15:51 - 0:15:56] (SPEAKER_02)

But these are five main AI tools that I find really essential to everything I do.

### Word‑level timestamps

- SPEAKER_02: But @ 0:15:51
- SPEAKER_02: these @ 0:15:52
- SPEAKER_02: are @ 0:15:52
- SPEAKER_02: five @ 0:15:52
- SPEAKER_02: main @ 0:15:53
- SPEAKER_02: AI @ 0:15:53
- SPEAKER_02: tools @ 0:15:53
- SPEAKER_02: that @ 0:15:54
- SPEAKER_02: I @ 0:15:54
- SPEAKER_02: find @ 0:15:54
- SPEAKER_02: really @ 0:15:54
- SPEAKER_02: essential @ 0:15:54
- SPEAKER_02: to @ 0:15:55
- SPEAKER_02: everything @ 0:15:55
- SPEAKER_02: I @ 0:15:55
- SPEAKER_02: do. @ 0:15:55

## Segment 224: [0:15:56 - 0:15:57] (SPEAKER_02)

The first one is Perplexity.

### Word‑level timestamps

- SPEAKER_02: The @ 0:15:56
- SPEAKER_02: first @ 0:15:56
- SPEAKER_02: one @ 0:15:56
- SPEAKER_02: is @ 0:15:56
- SPEAKER_02: Perplexity. @ 0:15:57

## Segment 225: [0:15:57 - 0:16:00] (SPEAKER_02)

This is basically AI Google search.

### Word‑level timestamps

- SPEAKER_02: This @ 0:15:57
- SPEAKER_02: is @ 0:15:58
- SPEAKER_02: basically @ 0:15:58
- SPEAKER_02: AI @ 0:15:58
- SPEAKER_02: Google @ 0:15:59
- SPEAKER_02: search. @ 0:15:59

## Segment 226: [0:16:00 - 0:16:02] (SPEAKER_02)

So previously, someone was like, Google it.

### Word‑level timestamps

- SPEAKER_02: So @ 0:16:00
- SPEAKER_02: previously, @ 0:16:00
- SPEAKER_02: someone @ 0:16:01
- SPEAKER_02: was @ 0:16:01
- SPEAKER_02: like, @ 0:16:01
- SPEAKER_02: Google @ 0:16:02
- SPEAKER_02: it. @ 0:16:02

## Segment 227: [0:16:03 - 0:16:05] (SPEAKER_02)

Bro, I got to go through an hour of Googling to find your answer.

### Word‑level timestamps

- SPEAKER_02: Bro, @ 0:16:03
- SPEAKER_02: I @ 0:16:03
- SPEAKER_02: got @ 0:16:03
- SPEAKER_02: to @ 0:16:03
- SPEAKER_02: go @ 0:16:03
- SPEAKER_02: through @ 0:16:03
- SPEAKER_02: an @ 0:16:04
- SPEAKER_02: hour @ 0:16:04
- SPEAKER_02: of @ 0:16:04
- SPEAKER_02: Googling @ 0:16:04
- SPEAKER_02: to @ 0:16:05
- SPEAKER_02: find @ 0:16:05
- SPEAKER_02: your @ 0:16:05
- SPEAKER_02: answer. @ 0:16:05

## Segment 228: [0:16:06 - 0:16:08] (SPEAKER_02)

I'm just not going to do it.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:16:06
- SPEAKER_02: just @ 0:16:07
- SPEAKER_02: not @ 0:16:07
- SPEAKER_02: going @ 0:16:07
- SPEAKER_02: to @ 0:16:07
- SPEAKER_02: do @ 0:16:08
- SPEAKER_02: it. @ 0:16:08

## Segment 229: [0:16:08 - 0:16:11] (SPEAKER_02)

But now you have an AI system that has access to Google itself.

### Word‑level timestamps

- SPEAKER_02: But @ 0:16:08
- SPEAKER_02: now @ 0:16:08
- SPEAKER_02: you @ 0:16:08
- SPEAKER_02: have @ 0:16:08
- SPEAKER_02: an @ 0:16:09
- SPEAKER_02: AI @ 0:16:09
- SPEAKER_02: system @ 0:16:09
- SPEAKER_02: that @ 0:16:09
- SPEAKER_02: has @ 0:16:10
- SPEAKER_02: access @ 0:16:10
- SPEAKER_02: to @ 0:16:10
- SPEAKER_02: Google @ 0:16:10
- SPEAKER_02: itself. @ 0:16:11

## Segment 230: [0:16:11 - 0:16:18] (SPEAKER_02)

All you got to do is ask it a question, and boom, in five seconds, you get an instant answer that isn't hallucinated, that is actually grounded by searching Google.

### Word‑level timestamps

- SPEAKER_02: All @ 0:16:11
- SPEAKER_02: you @ 0:16:11
- SPEAKER_02: got @ 0:16:11
- SPEAKER_02: to @ 0:16:11
- SPEAKER_02: do @ 0:16:12
- SPEAKER_02: is @ 0:16:12
- SPEAKER_02: ask @ 0:16:12
- SPEAKER_02: it @ 0:16:12
- SPEAKER_02: a @ 0:16:12
- SPEAKER_02: question, @ 0:16:12
- SPEAKER_02: and @ 0:16:13
- SPEAKER_02: boom, @ 0:16:13
- SPEAKER_02: in @ 0:16:13
- SPEAKER_02: five @ 0:16:13
- SPEAKER_02: seconds, @ 0:16:13
- SPEAKER_02: you @ 0:16:14
- SPEAKER_02: get @ 0:16:14
- SPEAKER_02: an @ 0:16:14
- SPEAKER_02: instant @ 0:16:14
- SPEAKER_02: answer @ 0:16:14
- SPEAKER_02: that @ 0:16:15
- SPEAKER_02: isn't @ 0:16:15
- SPEAKER_02: hallucinated, @ 0:16:15
- SPEAKER_02: that @ 0:16:16
- SPEAKER_02: is @ 0:16:16
- SPEAKER_02: actually @ 0:16:16
- SPEAKER_02: grounded @ 0:16:17
- SPEAKER_02: by @ 0:16:17
- SPEAKER_02: searching @ 0:16:18
- SPEAKER_02: Google. @ 0:16:18

## Segment 231: [0:16:19 - 0:16:21] (SPEAKER_02)

So honestly, ignorance is now an option.

### Word‑level timestamps

- SPEAKER_02: So @ 0:16:19
- SPEAKER_02: honestly, @ 0:16:19
- SPEAKER_02: ignorance @ 0:16:20
- SPEAKER_02: is @ 0:16:20
- SPEAKER_02: now @ 0:16:20
- SPEAKER_02: an @ 0:16:20
- SPEAKER_02: option. @ 0:16:21

## Segment 232: [0:16:21 - 0:16:26] (SPEAKER_02)

If you want to be ignorant, you're purposely choosing to be ignorant now that you know this technology exists.

### Word‑level timestamps

- SPEAKER_02: If @ 0:16:21
- SPEAKER_02: you @ 0:16:21
- SPEAKER_02: want @ 0:16:22
- SPEAKER_02: to @ 0:16:22
- SPEAKER_02: be @ 0:16:22
- SPEAKER_02: ignorant, @ 0:16:22
- SPEAKER_02: you're @ 0:16:22
- SPEAKER_02: purposely @ 0:16:22
- SPEAKER_02: choosing @ 0:16:23
- SPEAKER_02: to @ 0:16:23
- SPEAKER_02: be @ 0:16:23
- SPEAKER_02: ignorant @ 0:16:23
- SPEAKER_02: now @ 0:16:24
- SPEAKER_02: that @ 0:16:24
- SPEAKER_02: you @ 0:16:24
- SPEAKER_02: know @ 0:16:24
- SPEAKER_02: this @ 0:16:25
- SPEAKER_02: technology @ 0:16:25
- SPEAKER_02: exists. @ 0:16:25

## Segment 233: [0:16:26 - 0:16:28] (SPEAKER_02)

Because anything you don't know, you can know in five seconds.

### Word‑level timestamps

- SPEAKER_02: Because @ 0:16:26
- SPEAKER_02: anything @ 0:16:26
- SPEAKER_02: you @ 0:16:26
- SPEAKER_02: don't @ 0:16:26
- SPEAKER_02: know, @ 0:16:26
- SPEAKER_02: you @ 0:16:27
- SPEAKER_02: can @ 0:16:27
- SPEAKER_02: know @ 0:16:27
- SPEAKER_02: in @ 0:16:27
- SPEAKER_02: five @ 0:16:27
- SPEAKER_02: seconds. @ 0:16:27

## Segment 234: [0:16:28 - 0:16:31] (SPEAKER_02)

The second thing is Chad GBC deep research.

### Word‑level timestamps

- SPEAKER_02: The @ 0:16:28
- SPEAKER_02: second @ 0:16:28
- SPEAKER_02: thing @ 0:16:28
- SPEAKER_02: is @ 0:16:29
- SPEAKER_02: Chad @ 0:16:29
- SPEAKER_02: GBC @ 0:16:30
- SPEAKER_02: deep @ 0:16:30
- SPEAKER_02: research. @ 0:16:30

## Segment 235: [0:16:31 - 0:16:33] (SPEAKER_02)

This is available on the regular tier.

### Word‑level timestamps

- SPEAKER_02: This @ 0:16:31
- SPEAKER_02: is @ 0:16:31
- SPEAKER_02: available @ 0:16:31
- SPEAKER_02: on @ 0:16:32
- SPEAKER_02: the @ 0:16:32
- SPEAKER_02: regular @ 0:16:32
- SPEAKER_02: tier. @ 0:16:32

## Segment 236: [0:16:33 - 0:16:52] (SPEAKER_02)

This is actually a practice and in terms of learning how to do a lot of things, the deep research is an AI tool that searches the internet and like an actual PhD researcher goes through a lot of subjects, goes through a lot of academic papers, et cetera, the internet, even browsers, Reddit and other forums to get you an answer based on your question.

### Word‑level timestamps

- SPEAKER_02: This @ 0:16:33
- SPEAKER_02: is @ 0:16:33
- SPEAKER_02: actually @ 0:16:33
- SPEAKER_02: a @ 0:16:34
- SPEAKER_02: practice @ 0:16:34
- SPEAKER_02: and @ 0:16:34
- SPEAKER_02: in @ 0:16:34
- SPEAKER_02: terms @ 0:16:34
- SPEAKER_02: of @ 0:16:35
- SPEAKER_02: learning @ 0:16:35
- SPEAKER_02: how @ 0:16:35
- SPEAKER_02: to @ 0:16:35
- SPEAKER_02: do @ 0:16:35
- SPEAKER_02: a @ 0:16:36
- SPEAKER_02: lot @ 0:16:36
- SPEAKER_02: of @ 0:16:36
- SPEAKER_02: things, @ 0:16:36
- SPEAKER_02: the @ 0:16:36
- SPEAKER_02: deep @ 0:16:36
- SPEAKER_02: research @ 0:16:37
- SPEAKER_02: is @ 0:16:37
- SPEAKER_02: an @ 0:16:38
- SPEAKER_02: AI @ 0:16:38
- SPEAKER_02: tool @ 0:16:39
- SPEAKER_02: that @ 0:16:39
- SPEAKER_02: searches @ 0:16:40
- SPEAKER_02: the @ 0:16:40
- SPEAKER_02: internet @ 0:16:40
- SPEAKER_02: and @ 0:16:41
- SPEAKER_02: like @ 0:16:41
- SPEAKER_02: an @ 0:16:42
- SPEAKER_02: actual @ 0:16:42
- SPEAKER_02: PhD @ 0:16:43
- SPEAKER_02: researcher @ 0:16:43
- SPEAKER_02: goes @ 0:16:44
- SPEAKER_02: through @ 0:16:44
- SPEAKER_02: a @ 0:16:45
- SPEAKER_02: lot @ 0:16:45
- SPEAKER_02: of @ 0:16:45
- SPEAKER_02: subjects, @ 0:16:45
- SPEAKER_02: goes @ 0:16:45
- SPEAKER_02: through @ 0:16:45
- SPEAKER_02: a @ 0:16:46
- SPEAKER_02: lot @ 0:16:46
- SPEAKER_02: of @ 0:16:46
- SPEAKER_02: academic @ 0:16:46
- SPEAKER_02: papers, @ 0:16:46
- SPEAKER_02: et @ 0:16:47
- SPEAKER_02: cetera, @ 0:16:47
- SPEAKER_02: the @ 0:16:47
- SPEAKER_02: internet, @ 0:16:48
- SPEAKER_02: even @ 0:16:48
- SPEAKER_02: browsers, @ 0:16:48
- SPEAKER_02: Reddit @ 0:16:49
- SPEAKER_02: and @ 0:16:49
- SPEAKER_02: other @ 0:16:49
- SPEAKER_02: forums @ 0:16:50
- SPEAKER_02: to @ 0:16:50
- SPEAKER_02: get @ 0:16:51
- SPEAKER_02: you @ 0:16:51
- SPEAKER_02: an @ 0:16:51
- SPEAKER_02: answer @ 0:16:51
- SPEAKER_02: based @ 0:16:51
- SPEAKER_02: on @ 0:16:51
- SPEAKER_02: your @ 0:16:52
- SPEAKER_02: question. @ 0:16:52

## Segment 237: [0:16:52 - 0:16:54] (SPEAKER_02)

I use this a lot for psychology.

### Word‑level timestamps

- SPEAKER_02: I @ 0:16:52
- SPEAKER_02: use @ 0:16:52
- SPEAKER_02: this @ 0:16:53
- SPEAKER_02: a @ 0:16:53
- SPEAKER_02: lot @ 0:16:53
- SPEAKER_02: for @ 0:16:53
- SPEAKER_02: psychology. @ 0:16:53

## Segment 238: [0:16:54 - 0:16:56] (SPEAKER_02)

I use it to do market research.

### Word‑level timestamps

- SPEAKER_02: I @ 0:16:54
- SPEAKER_02: use @ 0:16:54
- SPEAKER_02: it @ 0:16:54
- SPEAKER_02: to @ 0:16:55
- SPEAKER_02: do @ 0:16:55
- SPEAKER_02: market @ 0:16:55
- SPEAKER_02: research. @ 0:16:55

## Segment 239: [0:16:56 - 0:16:57] (SPEAKER_02)

I wanted to learn more about encryption.

### Word‑level timestamps

- SPEAKER_02: I @ 0:16:56
- SPEAKER_02: wanted @ 0:16:56
- SPEAKER_02: to @ 0:16:56
- SPEAKER_02: learn @ 0:16:56
- SPEAKER_02: more @ 0:16:56
- SPEAKER_02: about @ 0:16:57
- SPEAKER_02: encryption. @ 0:16:57

## Segment 240: [0:16:57 - 0:16:58] (SPEAKER_02)

It taught me how to do encryption.

### Word‑level timestamps

- SPEAKER_02: It @ 0:16:57
- SPEAKER_02: taught @ 0:16:57
- SPEAKER_02: me @ 0:16:58
- SPEAKER_02: how @ 0:16:58
- SPEAKER_02: to @ 0:16:58
- SPEAKER_02: do @ 0:16:58
- SPEAKER_02: encryption. @ 0:16:58

## Segment 241: [0:16:58 - 0:17:03] (SPEAKER_02)

I wanted to have encryption for a specific app on my computer and I didn't know how to do it.

### Word‑level timestamps

- SPEAKER_02: I @ 0:16:58
- SPEAKER_02: wanted @ 0:16:59
- SPEAKER_02: to @ 0:16:59
- SPEAKER_02: have @ 0:16:59
- SPEAKER_02: encryption @ 0:16:59
- SPEAKER_02: for @ 0:17:00
- SPEAKER_02: a @ 0:17:00
- SPEAKER_02: specific @ 0:17:00
- SPEAKER_02: app @ 0:17:01
- SPEAKER_02: on @ 0:17:01
- SPEAKER_02: my @ 0:17:01
- SPEAKER_02: computer @ 0:17:01
- SPEAKER_02: and @ 0:17:02
- SPEAKER_02: I @ 0:17:02
- SPEAKER_02: didn't @ 0:17:02
- SPEAKER_02: know @ 0:17:02
- SPEAKER_02: how @ 0:17:02
- SPEAKER_02: to @ 0:17:02
- SPEAKER_02: do @ 0:17:03
- SPEAKER_02: it. @ 0:17:03

## Segment 242: [0:17:03 - 0:17:04] (SPEAKER_02)

And when I did it, it was too slow.

### Word‑level timestamps

- SPEAKER_02: And @ 0:17:03
- SPEAKER_02: when @ 0:17:03
- SPEAKER_02: I @ 0:17:03
- SPEAKER_02: did @ 0:17:03
- SPEAKER_02: it, @ 0:17:03
- SPEAKER_02: it @ 0:17:03
- SPEAKER_02: was @ 0:17:04
- SPEAKER_02: too @ 0:17:04
- SPEAKER_02: slow. @ 0:17:04

## Segment 243: [0:17:05 - 0:17:09] (SPEAKER_02)

So deep research was able to get all this research and it's like, yo, this is how we do fast encryption locally.

### Word‑level timestamps

- SPEAKER_02: So @ 0:17:05
- SPEAKER_02: deep @ 0:17:05
- SPEAKER_02: research @ 0:17:05
- SPEAKER_02: was @ 0:17:06
- SPEAKER_02: able @ 0:17:06
- SPEAKER_02: to @ 0:17:06
- SPEAKER_02: get @ 0:17:06
- SPEAKER_02: all @ 0:17:06
- SPEAKER_02: this @ 0:17:06
- SPEAKER_02: research @ 0:17:06
- SPEAKER_02: and @ 0:17:07
- SPEAKER_02: it's @ 0:17:07
- SPEAKER_02: like, @ 0:17:07
- SPEAKER_02: yo, @ 0:17:07
- SPEAKER_02: this @ 0:17:07
- SPEAKER_02: is @ 0:17:07
- SPEAKER_02: how @ 0:17:08
- SPEAKER_02: we @ 0:17:08
- SPEAKER_02: do @ 0:17:08
- SPEAKER_02: fast @ 0:17:08
- SPEAKER_02: encryption @ 0:17:08
- SPEAKER_02: locally. @ 0:17:09

## Segment 244: [0:17:09 - 0:17:10] (SPEAKER_02)

That's super secure.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:17:09
- SPEAKER_02: super @ 0:17:09
- SPEAKER_02: secure. @ 0:17:09

## Segment 245: [0:17:10 - 0:17:17] (SPEAKER_02)

I just take all that research and I give it to another AI system and it in one shot makes me this crazy product that I wasn't able to make before.

### Word‑level timestamps

- SPEAKER_02: I @ 0:17:10
- SPEAKER_02: just @ 0:17:11
- SPEAKER_02: take @ 0:17:11
- SPEAKER_02: all @ 0:17:11
- SPEAKER_02: that @ 0:17:11
- SPEAKER_02: research @ 0:17:11
- SPEAKER_02: and @ 0:17:12
- SPEAKER_02: I @ 0:17:12
- SPEAKER_02: give @ 0:17:12
- SPEAKER_02: it @ 0:17:12
- SPEAKER_02: to @ 0:17:12
- SPEAKER_02: another @ 0:17:12
- SPEAKER_02: AI @ 0:17:13
- SPEAKER_02: system @ 0:17:13
- SPEAKER_02: and @ 0:17:14
- SPEAKER_02: it @ 0:17:14
- SPEAKER_02: in @ 0:17:14
- SPEAKER_02: one @ 0:17:14
- SPEAKER_02: shot @ 0:17:15
- SPEAKER_02: makes @ 0:17:15
- SPEAKER_02: me @ 0:17:15
- SPEAKER_02: this @ 0:17:15
- SPEAKER_02: crazy @ 0:17:16
- SPEAKER_02: product @ 0:17:16
- SPEAKER_02: that @ 0:17:16
- SPEAKER_02: I @ 0:17:16
- SPEAKER_02: wasn't @ 0:17:16
- SPEAKER_02: able @ 0:17:17
- SPEAKER_02: to @ 0:17:17
- SPEAKER_02: make @ 0:17:17
- SPEAKER_02: before. @ 0:17:17

## Segment 246: [0:17:18 - 0:17:19] (SPEAKER_02)

That's just one example.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:17:18
- SPEAKER_02: just @ 0:17:18
- SPEAKER_02: one @ 0:17:18
- SPEAKER_02: example. @ 0:17:18

## Segment 247: [0:17:19 - 0:17:20] (SPEAKER_02)

I use this every day.

### Word‑level timestamps

- SPEAKER_02: I @ 0:17:19
- SPEAKER_02: use @ 0:17:19
- SPEAKER_02: this @ 0:17:19
- SPEAKER_02: every @ 0:17:19
- SPEAKER_02: day. @ 0:17:20

## Segment 248: [0:17:20 - 0:17:25] (SPEAKER_02)

Any topic I want more of an expert advice or look on, I just use that.

### Word‑level timestamps

- SPEAKER_02: Any @ 0:17:20
- SPEAKER_02: topic @ 0:17:20
- SPEAKER_02: I @ 0:17:21
- SPEAKER_02: want @ 0:17:21
- SPEAKER_02: more @ 0:17:22
- SPEAKER_02: of @ 0:17:22
- SPEAKER_02: an @ 0:17:22
- SPEAKER_02: expert @ 0:17:22
- SPEAKER_02: advice @ 0:17:23
- SPEAKER_02: or @ 0:17:24
- SPEAKER_02: look @ 0:17:24
- SPEAKER_02: on, @ 0:17:24
- SPEAKER_02: I @ 0:17:24
- SPEAKER_02: just @ 0:17:24
- SPEAKER_02: use @ 0:17:24
- SPEAKER_02: that. @ 0:17:25

## Segment 249: [0:17:25 - 0:17:29] (SPEAKER_02)

Let's see, two more tools is the ChadGBT image thing that just came out.

### Word‑level timestamps

- SPEAKER_02: Let's @ 0:17:25
- SPEAKER_02: see, @ 0:17:26
- SPEAKER_02: two @ 0:17:26
- SPEAKER_02: more @ 0:17:26
- SPEAKER_02: tools @ 0:17:26
- SPEAKER_02: is @ 0:17:27
- SPEAKER_02: the @ 0:17:27
- SPEAKER_02: ChadGBT @ 0:17:27
- SPEAKER_02: image @ 0:17:28
- SPEAKER_02: thing @ 0:17:28
- SPEAKER_02: that @ 0:17:29
- SPEAKER_02: just @ 0:17:29
- SPEAKER_02: came @ 0:17:29
- SPEAKER_02: out. @ 0:17:29

## Segment 250: [0:17:29 - 0:17:30] (SPEAKER_02)

It's honestly really good.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:17:29
- SPEAKER_02: honestly @ 0:17:30
- SPEAKER_02: really @ 0:17:30
- SPEAKER_02: good. @ 0:17:30

## Segment 251: [0:17:30 - 0:17:34] (SPEAKER_02)

I made this entire presentation with it in 30 minutes last night.

### Word‑level timestamps

- SPEAKER_02: I @ 0:17:30
- SPEAKER_02: made @ 0:17:31
- SPEAKER_02: this @ 0:17:31
- SPEAKER_02: entire @ 0:17:31
- SPEAKER_02: presentation @ 0:17:31
- SPEAKER_02: with @ 0:17:32
- SPEAKER_02: it @ 0:17:32
- SPEAKER_02: in @ 0:17:32
- SPEAKER_02: 30 @ 0:17:33
- SPEAKER_02: minutes @ 0:17:33
- SPEAKER_02: last @ 0:17:33
- SPEAKER_02: night. @ 0:17:34

## Segment 252: [0:17:34 - 0:17:38] (SPEAKER_02)

I'm a heavy procrastinator, but I know AI got my back, so I wasn't stressing too hard.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:17:34
- SPEAKER_02: a @ 0:17:34
- SPEAKER_02: heavy @ 0:17:34
- SPEAKER_02: procrastinator, @ 0:17:34
- SPEAKER_02: but @ 0:17:35
- SPEAKER_02: I @ 0:17:35
- SPEAKER_02: know @ 0:17:36
- SPEAKER_02: AI @ 0:17:36
- SPEAKER_02: got @ 0:17:36
- SPEAKER_02: my @ 0:17:36
- SPEAKER_02: back, @ 0:17:36
- SPEAKER_02: so @ 0:17:37
- SPEAKER_02: I @ 0:17:37
- SPEAKER_02: wasn't @ 0:17:37
- SPEAKER_02: stressing @ 0:17:37
- SPEAKER_02: too @ 0:17:37
- SPEAKER_02: hard. @ 0:17:38

## Segment 253: [0:17:38 - 0:17:40] (SPEAKER_02)

And then I used ChadGBT to generate the image.

### Word‑level timestamps

- SPEAKER_02: And @ 0:17:38
- SPEAKER_02: then @ 0:17:38
- SPEAKER_02: I @ 0:17:38
- SPEAKER_02: used @ 0:17:39
- SPEAKER_02: ChadGBT @ 0:17:39
- SPEAKER_02: to @ 0:17:39
- SPEAKER_02: generate @ 0:17:39
- SPEAKER_02: the @ 0:17:40
- SPEAKER_02: image. @ 0:17:40

## Segment 254: [0:17:40 - 0:17:44] (SPEAKER_02)

And then I used Cling, which is a video model, to bring the images to life.

### Word‑level timestamps

- SPEAKER_02: And @ 0:17:40
- SPEAKER_02: then @ 0:17:40
- SPEAKER_02: I @ 0:17:41
- SPEAKER_02: used @ 0:17:41
- SPEAKER_02: Cling, @ 0:17:41
- SPEAKER_02: which @ 0:17:42
- SPEAKER_02: is @ 0:17:42
- SPEAKER_02: a @ 0:17:42
- SPEAKER_02: video @ 0:17:42
- SPEAKER_02: model, @ 0:17:42
- SPEAKER_02: to @ 0:17:43
- SPEAKER_02: bring @ 0:17:43
- SPEAKER_02: the @ 0:17:43
- SPEAKER_02: images @ 0:17:43
- SPEAKER_02: to @ 0:17:44
- SPEAKER_02: life. @ 0:17:44

## Segment 255: [0:17:44 - 0:17:47] (SPEAKER_02)

And the last one is Quad, which is just like another ChadGBT.

### Word‑level timestamps

- SPEAKER_02: And @ 0:17:44
- SPEAKER_02: the @ 0:17:44
- SPEAKER_02: last @ 0:17:45
- SPEAKER_02: one @ 0:17:45
- SPEAKER_02: is @ 0:17:45
- SPEAKER_02: Quad, @ 0:17:45
- SPEAKER_02: which @ 0:17:46
- SPEAKER_02: is @ 0:17:46
- SPEAKER_02: just @ 0:17:46
- SPEAKER_02: like @ 0:17:46
- SPEAKER_02: another @ 0:17:46
- SPEAKER_02: ChadGBT. @ 0:17:47

## Segment 256: [0:17:47 - 0:17:49] (SPEAKER_02)

But that one is interesting.

### Word‑level timestamps

- SPEAKER_02: But @ 0:17:47
- SPEAKER_02: that @ 0:17:48
- SPEAKER_02: one @ 0:17:48
- SPEAKER_02: is @ 0:17:48
- SPEAKER_02: interesting. @ 0:17:48

## Segment 257: [0:17:49 - 0:17:51] (SPEAKER_02)

I low key use that one as a therapist.

### Word‑level timestamps

- SPEAKER_02: I @ 0:17:49
- SPEAKER_02: low @ 0:17:49
- SPEAKER_02: key @ 0:17:49
- SPEAKER_02: use @ 0:17:49
- SPEAKER_02: that @ 0:17:49
- SPEAKER_02: one @ 0:17:50
- SPEAKER_02: as @ 0:17:50
- SPEAKER_02: a @ 0:17:50
- SPEAKER_02: therapist. @ 0:17:50

## Segment 258: [0:17:51 - 0:17:55] (SPEAKER_02)

And it's up to you guys to tell me if the therapy works or not.

### Word‑level timestamps

- SPEAKER_02: And @ 0:17:51
- SPEAKER_02: it's @ 0:17:51
- SPEAKER_02: up @ 0:17:52
- SPEAKER_02: to @ 0:17:52
- SPEAKER_02: you @ 0:17:52
- SPEAKER_02: guys @ 0:17:52
- SPEAKER_02: to @ 0:17:52
- SPEAKER_02: tell @ 0:17:52
- SPEAKER_02: me @ 0:17:53
- SPEAKER_02: if @ 0:17:53
- SPEAKER_02: the @ 0:17:53
- SPEAKER_02: therapy @ 0:17:53
- SPEAKER_02: works @ 0:17:53
- SPEAKER_02: or @ 0:17:54
- SPEAKER_02: not. @ 0:17:54

## Segment 259: [0:17:55 - 0:17:57] (SPEAKER_02)

But it's been super helpful in terms of that.

### Word‑level timestamps

- SPEAKER_02: But @ 0:17:55
- SPEAKER_02: it's @ 0:17:55
- SPEAKER_02: been @ 0:17:55
- SPEAKER_02: super @ 0:17:55
- SPEAKER_02: helpful @ 0:17:56
- SPEAKER_02: in @ 0:17:56
- SPEAKER_02: terms @ 0:17:56
- SPEAKER_02: of @ 0:17:56
- SPEAKER_02: that. @ 0:17:57

## Segment 260: [0:17:57 - 0:17:59] (SPEAKER_02)

And it's just a very empathetic model.

### Word‑level timestamps

- SPEAKER_02: And @ 0:17:57
- SPEAKER_02: it's @ 0:17:57
- SPEAKER_02: just @ 0:17:57
- SPEAKER_02: a @ 0:17:58
- SPEAKER_02: very @ 0:17:58
- SPEAKER_02: empathetic @ 0:17:58
- SPEAKER_02: model. @ 0:17:59

## Segment 261: [0:17:59 - 0:18:01] (SPEAKER_02)

More importantly, it's a very creative writer.

### Word‑level timestamps

- SPEAKER_02: More @ 0:17:59
- SPEAKER_02: importantly, @ 0:17:59
- SPEAKER_02: it's @ 0:18:00
- SPEAKER_02: a @ 0:18:00
- SPEAKER_02: very @ 0:18:00
- SPEAKER_02: creative @ 0:18:00
- SPEAKER_02: writer. @ 0:18:01

## Segment 262: [0:18:01 - 0:18:04] (SPEAKER_02)

So it actually makes good copy when chat gbt can't.

### Word‑level timestamps

- SPEAKER_02: So @ 0:18:01
- SPEAKER_02: it @ 0:18:01
- SPEAKER_02: actually @ 0:18:01
- SPEAKER_02: makes @ 0:18:02
- SPEAKER_02: good @ 0:18:02
- SPEAKER_02: copy @ 0:18:02
- SPEAKER_02: when @ 0:18:03
- SPEAKER_02: chat @ 0:18:03
- SPEAKER_02: gbt @ 0:18:03
- SPEAKER_02: can't. @ 0:18:04

## Segment 263: [0:18:07 - 0:18:08] (SPEAKER_02)

I guess the vibe coding has been a thing.

### Word‑level timestamps

- SPEAKER_02: I @ 0:18:07
- SPEAKER_02: guess @ 0:18:07
- SPEAKER_02: the @ 0:18:07
- SPEAKER_02: vibe @ 0:18:07
- SPEAKER_02: coding @ 0:18:07
- SPEAKER_02: has @ 0:18:07
- SPEAKER_02: been @ 0:18:08
- SPEAKER_02: a @ 0:18:08
- SPEAKER_02: thing. @ 0:18:08

## Segment 264: [0:18:08 - 0:18:12] (SPEAKER_02)

So the idea of inputting your idea into an AI system.

### Word‑level timestamps

- SPEAKER_02: So @ 0:18:08
- SPEAKER_02: the @ 0:18:08
- SPEAKER_02: idea @ 0:18:08
- SPEAKER_02: of @ 0:18:09
- SPEAKER_02: inputting @ 0:18:09
- SPEAKER_02: your @ 0:18:10
- SPEAKER_02: idea @ 0:18:10
- SPEAKER_02: into @ 0:18:10
- SPEAKER_02: an @ 0:18:11
- SPEAKER_02: AI @ 0:18:11
- SPEAKER_02: system. @ 0:18:11

## Segment 265: [0:18:13 - 0:18:14] (SPEAKER_02)

has been coined VibeCoding.

### Word‑level timestamps

- SPEAKER_02: has @ 0:18:13
- SPEAKER_02: been @ 0:18:13
- SPEAKER_02: coined @ 0:18:13
- SPEAKER_02: VibeCoding. @ 0:18:13

## Segment 266: [0:18:15 - 0:18:18] (SPEAKER_02)

So I've been teaching a lot of people how to VibeCode and growing that community and posting YouTube videos.

### Word‑level timestamps

- SPEAKER_02: So @ 0:18:15
- SPEAKER_02: I've @ 0:18:15
- SPEAKER_02: been @ 0:18:15
- SPEAKER_02: teaching @ 0:18:15
- SPEAKER_02: a @ 0:18:15
- SPEAKER_02: lot @ 0:18:15
- SPEAKER_02: of @ 0:18:15
- SPEAKER_02: people @ 0:18:15
- SPEAKER_02: how @ 0:18:16
- SPEAKER_02: to @ 0:18:16
- SPEAKER_02: VibeCode @ 0:18:16
- SPEAKER_02: and @ 0:18:16
- SPEAKER_02: growing @ 0:18:17
- SPEAKER_02: that @ 0:18:17
- SPEAKER_02: community @ 0:18:17
- SPEAKER_02: and @ 0:18:17
- SPEAKER_02: posting @ 0:18:17
- SPEAKER_02: YouTube @ 0:18:18
- SPEAKER_02: videos. @ 0:18:18

## Segment 267: [0:18:19 - 0:18:21] (SPEAKER_02)

I'm King Butoshi on X and YouTube.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:18:19
- SPEAKER_02: King @ 0:18:19
- SPEAKER_02: Butoshi @ 0:18:19
- SPEAKER_02: on @ 0:18:20
- SPEAKER_02: X @ 0:18:20
- SPEAKER_02: and @ 0:18:21
- SPEAKER_02: YouTube. @ 0:18:21

## Segment 268: [0:18:21 - 0:18:24] (SPEAKER_02)

So if you guys want to learn AI on a deeper level, let me know.

### Word‑level timestamps

- SPEAKER_02: So @ 0:18:21
- SPEAKER_02: if @ 0:18:21
- SPEAKER_02: you @ 0:18:21
- SPEAKER_02: guys @ 0:18:22
- SPEAKER_02: want @ 0:18:22
- SPEAKER_02: to @ 0:18:22
- SPEAKER_02: learn @ 0:18:22
- SPEAKER_02: AI @ 0:18:22
- SPEAKER_02: on @ 0:18:22
- SPEAKER_02: a @ 0:18:22
- SPEAKER_02: deeper @ 0:18:22
- SPEAKER_02: level, @ 0:18:23
- SPEAKER_02: let @ 0:18:23
- SPEAKER_02: me @ 0:18:23
- SPEAKER_02: know. @ 0:18:23

## Segment 269: [0:18:24 - 0:18:26] (SPEAKER_02)

Wanted to open the floor to any questions, if anybody has any questions.

### Word‑level timestamps

- SPEAKER_02: Wanted @ 0:18:24
- SPEAKER_02: to @ 0:18:24
- SPEAKER_02: open @ 0:18:24
- SPEAKER_02: the @ 0:18:24
- SPEAKER_02: floor @ 0:18:24
- SPEAKER_02: to @ 0:18:25
- SPEAKER_02: any @ 0:18:25
- SPEAKER_02: questions, @ 0:18:25
- SPEAKER_02: if @ 0:18:25
- SPEAKER_02: anybody @ 0:18:25
- SPEAKER_02: has @ 0:18:26
- SPEAKER_02: any @ 0:18:26
- SPEAKER_02: questions. @ 0:18:26

## Segment 270: [0:18:27 - 0:18:29] (SPEAKER_02)

And then if not, that's basically it.

### Word‑level timestamps

- SPEAKER_02: And @ 0:18:27
- SPEAKER_02: then @ 0:18:27
- SPEAKER_02: if @ 0:18:27
- SPEAKER_02: not, @ 0:18:27
- SPEAKER_02: that's @ 0:18:27
- SPEAKER_02: basically @ 0:18:27
- SPEAKER_02: it. @ 0:18:28

## Segment 271: [0:18:29 - 0:18:30] (SPEAKER_02)

What's up?

### Word‑level timestamps

- SPEAKER_02: What's @ 0:18:29
- SPEAKER_02: up? @ 0:18:29

## Segment 272: [0:18:30 - 0:18:32] (SPEAKER_05)

I have a weird problem with AI tools.

### Word‑level timestamps

- SPEAKER_05: I @ 0:18:30
- SPEAKER_05: have @ 0:18:30
- SPEAKER_05: a @ 0:18:30
- SPEAKER_05: weird @ 0:18:30
- SPEAKER_05: problem @ 0:18:31
- SPEAKER_05: with @ 0:18:31
- SPEAKER_05: AI @ 0:18:32
- SPEAKER_05: tools. @ 0:18:32

## Segment 273: [0:18:33 - 0:18:44] (SPEAKER_05)

Basically, I'm very competent at a lot of programming skills, and so it means that sometimes I don't get as much benefit out of AI tools as kind of Google.

### Word‑level timestamps

- SPEAKER_05: Basically, @ 0:18:33
- SPEAKER_05: I'm @ 0:18:33
- SPEAKER_05: very @ 0:18:34
- SPEAKER_05: competent @ 0:18:34
- SPEAKER_05: at @ 0:18:35
- SPEAKER_05: a @ 0:18:36
- SPEAKER_05: lot @ 0:18:36
- SPEAKER_05: of @ 0:18:36
- SPEAKER_05: programming @ 0:18:37
- SPEAKER_05: skills, @ 0:18:37
- SPEAKER_05: and @ 0:18:39
- SPEAKER_05: so @ 0:18:39
- SPEAKER_05: it @ 0:18:39
- SPEAKER_05: means @ 0:18:39
- SPEAKER_05: that @ 0:18:39
- SPEAKER_05: sometimes @ 0:18:40
- SPEAKER_05: I @ 0:18:40
- SPEAKER_05: don't @ 0:18:40
- SPEAKER_05: get @ 0:18:41
- SPEAKER_05: as @ 0:18:41
- SPEAKER_05: much @ 0:18:41
- SPEAKER_05: benefit @ 0:18:41
- SPEAKER_04: out @ 0:18:42
- SPEAKER_05: of @ 0:18:42
- SPEAKER_05: AI @ 0:18:42
- SPEAKER_05: tools @ 0:18:43
- SPEAKER_05: as @ 0:18:43
- SPEAKER_05: kind @ 0:18:43
- SPEAKER_05: of @ 0:18:43
- SPEAKER_05: Google. @ 0:18:43

## Segment 274: [0:18:44 - 0:18:59] (SPEAKER_05)

Like, I'm a fast typist, I use NeoVim very well, I'm in a terminal, I use TMAX, and so it's actually been a bit of a struggle to adopt AI tools in my workflow because it's like, for other people it's like, it types so fast.

### Word‑level timestamps

- SPEAKER_05: Like, @ 0:18:44
- SPEAKER_05: I'm @ 0:18:44
- SPEAKER_05: a @ 0:18:45
- SPEAKER_05: fast @ 0:18:45
- SPEAKER_05: typist, @ 0:18:45
- SPEAKER_05: I @ 0:18:46
- SPEAKER_05: use @ 0:18:47
- SPEAKER_05: NeoVim @ 0:18:47
- SPEAKER_05: very @ 0:18:47
- SPEAKER_05: well, @ 0:18:48
- SPEAKER_05: I'm @ 0:18:49
- SPEAKER_05: in @ 0:18:49
- SPEAKER_05: a @ 0:18:49
- SPEAKER_05: terminal, @ 0:18:49
- SPEAKER_05: I @ 0:18:50
- SPEAKER_05: use @ 0:18:50
- SPEAKER_05: TMAX, @ 0:18:50
- SPEAKER_05: and @ 0:18:51
- SPEAKER_05: so @ 0:18:51
- SPEAKER_05: it's @ 0:18:52
- SPEAKER_05: actually @ 0:18:52
- SPEAKER_05: been @ 0:18:52
- SPEAKER_05: a @ 0:18:52
- SPEAKER_05: bit @ 0:18:52
- SPEAKER_05: of @ 0:18:52
- SPEAKER_05: a @ 0:18:53
- SPEAKER_05: struggle @ 0:18:53
- SPEAKER_05: to @ 0:18:53
- SPEAKER_05: adopt @ 0:18:53
- SPEAKER_05: AI @ 0:18:54
- SPEAKER_05: tools @ 0:18:54
- SPEAKER_05: in @ 0:18:54
- SPEAKER_05: my @ 0:18:55
- SPEAKER_05: workflow @ 0:18:55
- SPEAKER_05: because @ 0:18:55
- SPEAKER_05: it's @ 0:18:55
- SPEAKER_05: like, @ 0:18:56
- SPEAKER_05: for @ 0:18:56
- SPEAKER_05: other @ 0:18:57
- SPEAKER_05: people @ 0:18:57
- SPEAKER_05: it's @ 0:18:57
- SPEAKER_05: like, @ 0:18:57
- SPEAKER_05: it @ 0:18:57
- SPEAKER_05: types @ 0:18:57
- SPEAKER_05: so @ 0:18:58
- SPEAKER_05: fast. @ 0:18:58

## Segment 275: [0:18:59 - 0:19:02] (SPEAKER_05)

For me, I type pretty fast, so I actually am...

### Word‑level timestamps

- SPEAKER_05: For @ 0:18:59
- SPEAKER_05: me, @ 0:18:59
- SPEAKER_05: I @ 0:18:59
- SPEAKER_05: type @ 0:18:59
- SPEAKER_05: pretty @ 0:19:00
- SPEAKER_05: fast, @ 0:19:00
- SPEAKER_05: so @ 0:19:00
- SPEAKER_05: I @ 0:19:01
- SPEAKER_05: actually @ 0:19:01
- SPEAKER_05: am... @ 0:19:01

## Segment 276: [0:19:02 - 0:19:07] (SPEAKER_05)

a bit clueless as to how to use AI for coding specifically.

### Word‑level timestamps

- SPEAKER_05: a @ 0:19:02
- SPEAKER_05: bit @ 0:19:03
- SPEAKER_05: clueless @ 0:19:03
- SPEAKER_05: as @ 0:19:04
- SPEAKER_05: to @ 0:19:04
- SPEAKER_05: how @ 0:19:04
- SPEAKER_05: to @ 0:19:05
- SPEAKER_05: use @ 0:19:05
- SPEAKER_05: AI @ 0:19:05
- SPEAKER_05: for @ 0:19:06
- SPEAKER_05: coding @ 0:19:06
- SPEAKER_05: specifically. @ 0:19:06

## Segment 277: [0:19:07 - 0:19:09] (SPEAKER_05)

What are your tips for somebody like me?

### Word‑level timestamps

- SPEAKER_05: What @ 0:19:07
- SPEAKER_05: are @ 0:19:08
- SPEAKER_05: your @ 0:19:08
- SPEAKER_05: tips @ 0:19:08
- SPEAKER_05: for @ 0:19:08
- SPEAKER_05: somebody @ 0:19:08
- SPEAKER_05: like @ 0:19:09
- SPEAKER_05: me? @ 0:19:09

## Segment 278: [0:19:10 - 0:19:12] (SPEAKER_02)

I have this product I'm working on and the code base is massive, right?

### Word‑level timestamps

- SPEAKER_02: I @ 0:19:10
- SPEAKER_02: have @ 0:19:10
- SPEAKER_02: this @ 0:19:10
- SPEAKER_02: product @ 0:19:10
- SPEAKER_02: I'm @ 0:19:11
- SPEAKER_02: working @ 0:19:11
- SPEAKER_02: on @ 0:19:11
- SPEAKER_02: and @ 0:19:11
- SPEAKER_02: the @ 0:19:11
- SPEAKER_02: code @ 0:19:11
- SPEAKER_02: base @ 0:19:11
- SPEAKER_02: is @ 0:19:12
- SPEAKER_02: massive, @ 0:19:12
- SPEAKER_02: right? @ 0:19:12

## Segment 279: [0:19:13 - 0:19:15] (SPEAKER_02)

But I don't use NeoVim, I use Cursor.

### Word‑level timestamps

- SPEAKER_02: But @ 0:19:13
- SPEAKER_02: I @ 0:19:13
- SPEAKER_02: don't @ 0:19:13
- SPEAKER_02: use @ 0:19:13
- SPEAKER_02: NeoVim, @ 0:19:14
- SPEAKER_02: I @ 0:19:14
- SPEAKER_02: use @ 0:19:14
- SPEAKER_02: Cursor. @ 0:19:14

## Segment 280: [0:19:15 - 0:19:18] (SPEAKER_02)

And the reason I use Cursor is it's like a VS code for it, right?

### Word‑level timestamps

- SPEAKER_02: And @ 0:19:15
- SPEAKER_02: the @ 0:19:15
- SPEAKER_02: reason @ 0:19:15
- SPEAKER_02: I @ 0:19:16
- SPEAKER_02: use @ 0:19:16
- SPEAKER_02: Cursor @ 0:19:16
- SPEAKER_02: is @ 0:19:16
- SPEAKER_02: it's @ 0:19:16
- SPEAKER_02: like @ 0:19:17
- SPEAKER_02: a @ 0:19:17
- SPEAKER_02: VS @ 0:19:17
- SPEAKER_02: code @ 0:19:17
- SPEAKER_02: for @ 0:19:17
- SPEAKER_02: it, @ 0:19:18
- SPEAKER_02: right? @ 0:19:18

## Segment 281: [0:19:18 - 0:19:22] (SPEAKER_02)

But Cursor is really cool because you could make these things called project rules.

### Word‑level timestamps

- SPEAKER_02: But @ 0:19:18
- SPEAKER_02: Cursor @ 0:19:19
- SPEAKER_02: is @ 0:19:19
- SPEAKER_02: really @ 0:19:19
- SPEAKER_02: cool @ 0:19:19
- SPEAKER_02: because @ 0:19:20
- SPEAKER_02: you @ 0:19:20
- SPEAKER_02: could @ 0:19:20
- SPEAKER_02: make @ 0:19:20
- SPEAKER_02: these @ 0:19:21
- SPEAKER_02: things @ 0:19:21
- SPEAKER_02: called @ 0:19:21
- SPEAKER_02: project @ 0:19:21
- SPEAKER_02: rules. @ 0:19:22

## Segment 282: [0:19:23 - 0:19:29] (SPEAKER_02)

And essentially, the way I document my code now is I don't document it for humans, I document it for AI systems.

### Word‑level timestamps

- SPEAKER_02: And @ 0:19:23
- SPEAKER_02: essentially, @ 0:19:23
- SPEAKER_02: the @ 0:19:23
- SPEAKER_02: way @ 0:19:24
- SPEAKER_02: I @ 0:19:24
- SPEAKER_02: document @ 0:19:24
- SPEAKER_02: my @ 0:19:24
- SPEAKER_02: code @ 0:19:25
- SPEAKER_02: now @ 0:19:25
- SPEAKER_02: is @ 0:19:25
- SPEAKER_02: I @ 0:19:25
- SPEAKER_02: don't @ 0:19:25
- SPEAKER_02: document @ 0:19:26
- SPEAKER_02: it @ 0:19:26
- SPEAKER_02: for @ 0:19:26
- SPEAKER_02: humans, @ 0:19:26
- SPEAKER_02: I @ 0:19:27
- SPEAKER_02: document @ 0:19:27
- SPEAKER_02: it @ 0:19:28
- SPEAKER_02: for @ 0:19:28
- SPEAKER_02: AI @ 0:19:28
- SPEAKER_02: systems. @ 0:19:28

## Segment 283: [0:19:29 - 0:19:31] (SPEAKER_02)

So I have this tech stack I'm using.

### Word‑level timestamps

- SPEAKER_02: So @ 0:19:29
- SPEAKER_02: I @ 0:19:29
- SPEAKER_02: have @ 0:19:29
- SPEAKER_02: this @ 0:19:30
- SPEAKER_02: tech @ 0:19:30
- SPEAKER_02: stack @ 0:19:30
- SPEAKER_02: I'm @ 0:19:30
- SPEAKER_02: using. @ 0:19:30

## Segment 284: [0:19:31 - 0:19:34] (SPEAKER_02)

This is how I use API and auth and security in my code base.

### Word‑level timestamps

- SPEAKER_02: This @ 0:19:31
- SPEAKER_02: is @ 0:19:31
- SPEAKER_02: how @ 0:19:32
- SPEAKER_02: I @ 0:19:32
- SPEAKER_02: use @ 0:19:32
- SPEAKER_02: API @ 0:19:32
- SPEAKER_02: and @ 0:19:33
- SPEAKER_02: auth @ 0:19:33
- SPEAKER_02: and @ 0:19:33
- SPEAKER_02: security @ 0:19:33
- SPEAKER_02: in @ 0:19:34
- SPEAKER_02: my @ 0:19:34
- SPEAKER_02: code @ 0:19:34
- SPEAKER_02: base. @ 0:19:34

## Segment 285: [0:19:35 - 0:19:37] (SPEAKER_02)

These are where the structures and different files should go.

### Word‑level timestamps

- SPEAKER_02: These @ 0:19:35
- SPEAKER_02: are @ 0:19:35
- SPEAKER_02: where @ 0:19:35
- SPEAKER_02: the @ 0:19:35
- SPEAKER_02: structures @ 0:19:36
- SPEAKER_02: and @ 0:19:36
- SPEAKER_02: different @ 0:19:36
- SPEAKER_02: files @ 0:19:36
- SPEAKER_02: should @ 0:19:37
- SPEAKER_02: go. @ 0:19:37

## Segment 286: [0:19:37 - 0:19:44] (SPEAKER_02)

And by creating these really detailed documents of my code base, I don't have to keep adding this context to all the AI systems.

### Word‑level timestamps

- SPEAKER_02: And @ 0:19:37
- SPEAKER_02: by @ 0:19:38
- SPEAKER_02: creating @ 0:19:38
- SPEAKER_02: these @ 0:19:38
- SPEAKER_02: really @ 0:19:39
- SPEAKER_02: detailed @ 0:19:39
- SPEAKER_02: documents @ 0:19:39
- SPEAKER_02: of @ 0:19:40
- SPEAKER_02: my @ 0:19:40
- SPEAKER_02: code @ 0:19:40
- SPEAKER_02: base, @ 0:19:40
- SPEAKER_02: I @ 0:19:41
- SPEAKER_02: don't @ 0:19:41
- SPEAKER_02: have @ 0:19:41
- SPEAKER_02: to @ 0:19:41
- SPEAKER_02: keep @ 0:19:42
- SPEAKER_02: adding @ 0:19:42
- SPEAKER_02: this @ 0:19:42
- SPEAKER_02: context @ 0:19:42
- SPEAKER_02: to @ 0:19:43
- SPEAKER_02: all @ 0:19:43
- SPEAKER_02: the @ 0:19:43
- SPEAKER_02: AI @ 0:19:43
- SPEAKER_02: systems. @ 0:19:43

## Segment 287: [0:19:44 - 0:19:46] (SPEAKER_02)

I could be like, yo, I want a new feature.

### Word‑level timestamps

- SPEAKER_02: I @ 0:19:44
- SPEAKER_02: could @ 0:19:44
- SPEAKER_02: be @ 0:19:44
- SPEAKER_02: like, @ 0:19:44
- SPEAKER_02: yo, @ 0:19:44
- SPEAKER_02: I @ 0:19:45
- SPEAKER_02: want @ 0:19:45
- SPEAKER_02: a @ 0:19:45
- SPEAKER_02: new @ 0:19:45
- SPEAKER_02: feature. @ 0:19:45

## Segment 288: [0:19:46 - 0:19:47] (SPEAKER_02)

Boom, I got you.

### Word‑level timestamps

- SPEAKER_02: Boom, @ 0:19:46
- SPEAKER_02: I @ 0:19:46
- SPEAKER_02: got @ 0:19:46
- SPEAKER_02: you. @ 0:19:47

## Segment 289: [0:19:47 - 0:19:51] (SPEAKER_02)

Because it knows how to do proper auth, proper security, what proper tech stack to use.

### Word‑level timestamps

- SPEAKER_02: Because @ 0:19:47
- SPEAKER_02: it @ 0:19:47
- SPEAKER_02: knows @ 0:19:47
- SPEAKER_02: how @ 0:19:47
- SPEAKER_02: to @ 0:19:47
- SPEAKER_02: do @ 0:19:47
- SPEAKER_02: proper @ 0:19:48
- SPEAKER_02: auth, @ 0:19:48
- SPEAKER_02: proper @ 0:19:48
- SPEAKER_02: security, @ 0:19:48
- SPEAKER_02: what @ 0:19:49
- SPEAKER_02: proper @ 0:19:50
- SPEAKER_02: tech @ 0:19:50
- SPEAKER_02: stack @ 0:19:51
- SPEAKER_02: to @ 0:19:51
- SPEAKER_02: use. @ 0:19:51

## Segment 290: [0:19:51 - 0:19:55] (SPEAKER_02)

It's not installing random packages that are useless and doing all this extra stuff.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:19:51
- SPEAKER_02: not @ 0:19:51
- SPEAKER_02: installing @ 0:19:51
- SPEAKER_02: random @ 0:19:52
- SPEAKER_02: packages @ 0:19:52
- SPEAKER_02: that @ 0:19:53
- SPEAKER_02: are @ 0:19:53
- SPEAKER_02: useless @ 0:19:53
- SPEAKER_02: and @ 0:19:53
- SPEAKER_02: doing @ 0:19:54
- SPEAKER_02: all @ 0:19:54
- SPEAKER_02: this @ 0:19:54
- SPEAKER_02: extra @ 0:19:54
- SPEAKER_02: stuff. @ 0:19:54

## Segment 291: [0:19:55 - 0:19:56] (SPEAKER_02)

But it is interesting.

### Word‑level timestamps

- SPEAKER_02: But @ 0:19:55
- SPEAKER_02: it @ 0:19:55
- SPEAKER_02: is @ 0:19:55
- SPEAKER_02: interesting. @ 0:19:56

## Segment 292: [0:19:56 - 0:20:00] (SPEAKER_02)

I recently started this AI company with a couple of co-founders called Agency 42.

### Word‑level timestamps

- SPEAKER_02: I @ 0:19:56
- SPEAKER_02: recently @ 0:19:57
- SPEAKER_02: started @ 0:19:57
- SPEAKER_02: this @ 0:19:57
- SPEAKER_02: AI @ 0:19:57
- SPEAKER_02: company @ 0:19:58
- SPEAKER_02: with @ 0:19:58
- SPEAKER_02: a @ 0:19:58
- SPEAKER_02: couple @ 0:19:58
- SPEAKER_02: of @ 0:19:59
- SPEAKER_02: co-founders @ 0:19:59
- SPEAKER_02: called @ 0:20:00
- SPEAKER_02: Agency @ 0:20:00
- SPEAKER_02: 42. @ 0:20:00

## Segment 293: [0:20:01 - 0:20:02] (SPEAKER_02)

I'm the in-house lead vibe coder.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:20:01
- SPEAKER_02: the @ 0:20:01
- SPEAKER_02: in-house @ 0:20:01
- SPEAKER_02: lead @ 0:20:02
- SPEAKER_02: vibe @ 0:20:02
- SPEAKER_02: coder. @ 0:20:02

## Segment 294: [0:20:03 - 0:20:07] (SPEAKER_02)

I've been coding for two years and then my co-founder Rob has been coding for 10 plus years.

### Word‑level timestamps

- SPEAKER_02: I've @ 0:20:03
- SPEAKER_02: been @ 0:20:03
- SPEAKER_02: coding @ 0:20:03
- SPEAKER_02: for @ 0:20:03
- SPEAKER_02: two @ 0:20:04
- SPEAKER_02: years @ 0:20:04
- SPEAKER_02: and @ 0:20:04
- SPEAKER_02: then @ 0:20:04
- SPEAKER_02: my @ 0:20:05
- SPEAKER_02: co-founder @ 0:20:05
- SPEAKER_02: Rob @ 0:20:05
- SPEAKER_02: has @ 0:20:06
- SPEAKER_02: been @ 0:20:06
- SPEAKER_02: coding @ 0:20:06
- SPEAKER_02: for @ 0:20:07
- SPEAKER_02: 10 @ 0:20:07
- SPEAKER_02: plus @ 0:20:07
- SPEAKER_02: years. @ 0:20:07

## Segment 295: [0:20:08 - 0:20:13] (SPEAKER_02)

Working with him is so interesting because I'm teaching him how to vibe code and he's teaching me proper code.

### Word‑level timestamps

- SPEAKER_02: Working @ 0:20:08
- SPEAKER_02: with @ 0:20:08
- SPEAKER_02: him @ 0:20:08
- SPEAKER_02: is @ 0:20:08
- SPEAKER_02: so @ 0:20:08
- SPEAKER_02: interesting @ 0:20:08
- SPEAKER_02: because @ 0:20:09
- SPEAKER_02: I'm @ 0:20:10
- SPEAKER_02: teaching @ 0:20:10
- SPEAKER_02: him @ 0:20:10
- SPEAKER_02: how @ 0:20:10
- SPEAKER_02: to @ 0:20:10
- SPEAKER_02: vibe @ 0:20:11
- SPEAKER_02: code @ 0:20:11
- SPEAKER_02: and @ 0:20:11
- SPEAKER_02: he's @ 0:20:11
- SPEAKER_02: teaching @ 0:20:12
- SPEAKER_02: me @ 0:20:12
- SPEAKER_02: proper @ 0:20:12
- SPEAKER_02: code. @ 0:20:12

## Segment 296: [0:20:13 - 0:20:19] (SPEAKER_02)

He has to unlearn some things, not crucial things, but just get out of some habits.

### Word‑level timestamps

- SPEAKER_02: He @ 0:20:13
- SPEAKER_02: has @ 0:20:14
- SPEAKER_02: to @ 0:20:14
- SPEAKER_02: unlearn @ 0:20:14
- SPEAKER_02: some @ 0:20:15
- SPEAKER_02: things, @ 0:20:15
- SPEAKER_02: not @ 0:20:16
- SPEAKER_02: crucial @ 0:20:16
- SPEAKER_02: things, @ 0:20:16
- SPEAKER_02: but @ 0:20:17
- SPEAKER_02: just @ 0:20:17
- SPEAKER_02: get @ 0:20:17
- SPEAKER_02: out @ 0:20:17
- SPEAKER_02: of @ 0:20:17
- SPEAKER_02: some @ 0:20:17
- SPEAKER_02: habits. @ 0:20:18

## Segment 297: [0:20:19 - 0:20:24] (SPEAKER_02)

so he could integrate AI into his workflow because the way that I taught him is, boom, bro, use cursor.

### Word‑level timestamps

- SPEAKER_02: so @ 0:20:19
- SPEAKER_02: he @ 0:20:19
- SPEAKER_02: could @ 0:20:19
- SPEAKER_02: integrate @ 0:20:19
- SPEAKER_02: AI @ 0:20:20
- SPEAKER_02: into @ 0:20:20
- SPEAKER_02: his @ 0:20:20
- SPEAKER_02: workflow @ 0:20:20
- SPEAKER_02: because @ 0:20:21
- SPEAKER_02: the @ 0:20:21
- SPEAKER_02: way @ 0:20:21
- SPEAKER_02: that @ 0:20:21
- SPEAKER_02: I @ 0:20:22
- SPEAKER_02: taught @ 0:20:22
- SPEAKER_02: him @ 0:20:22
- SPEAKER_02: is, @ 0:20:22
- SPEAKER_02: boom, @ 0:20:22
- SPEAKER_02: bro, @ 0:20:23
- SPEAKER_02: use @ 0:20:23
- SPEAKER_02: cursor. @ 0:20:23

## Segment 298: [0:20:24 - 0:20:26] (SPEAKER_02)

Look how quick it does this because he knows the system structure.

### Word‑level timestamps

- SPEAKER_02: Look @ 0:20:24
- SPEAKER_02: how @ 0:20:24
- SPEAKER_02: quick @ 0:20:24
- SPEAKER_02: it @ 0:20:24
- SPEAKER_02: does @ 0:20:24
- SPEAKER_02: this @ 0:20:24
- SPEAKER_02: because @ 0:20:25
- SPEAKER_02: he @ 0:20:25
- SPEAKER_02: knows @ 0:20:25
- SPEAKER_02: the @ 0:20:25
- SPEAKER_02: system @ 0:20:25
- SPEAKER_02: structure. @ 0:20:26

## Segment 299: [0:20:26 - 0:20:27] (SPEAKER_02)

He knows what the proper code looks like.

### Word‑level timestamps

- SPEAKER_02: He @ 0:20:26
- SPEAKER_02: knows @ 0:20:26
- SPEAKER_02: what @ 0:20:26
- SPEAKER_02: the @ 0:20:26
- SPEAKER_02: proper @ 0:20:26
- SPEAKER_02: code @ 0:20:27
- SPEAKER_02: looks @ 0:20:27
- SPEAKER_02: like. @ 0:20:27

## Segment 300: [0:20:27 - 0:20:28] (SPEAKER_02)

He knows the logic.

### Word‑level timestamps

- SPEAKER_02: He @ 0:20:27
- SPEAKER_02: knows @ 0:20:28
- SPEAKER_02: the @ 0:20:28
- SPEAKER_02: logic. @ 0:20:28

## Segment 301: [0:20:28 - 0:20:30] (SPEAKER_02)

So he just tells the system and just spits it out.

### Word‑level timestamps

- SPEAKER_02: So @ 0:20:28
- SPEAKER_02: he @ 0:20:28
- SPEAKER_02: just @ 0:20:29
- SPEAKER_02: tells @ 0:20:29
- SPEAKER_02: the @ 0:20:29
- SPEAKER_02: system @ 0:20:29
- SPEAKER_02: and @ 0:20:29
- SPEAKER_02: just @ 0:20:29
- SPEAKER_02: spits @ 0:20:30
- SPEAKER_02: it @ 0:20:30
- SPEAKER_02: out. @ 0:20:30

## Segment 302: [0:20:30 - 0:20:31] (SPEAKER_02)

What's up?

### Word‑level timestamps

- SPEAKER_02: What's @ 0:20:30
- SPEAKER_05: up? @ 0:20:31

## Segment 303: [0:20:31 - 0:20:35] (SPEAKER_05)

I know what my problem is that I'm very lazy about writing documentation.

### Word‑level timestamps

- SPEAKER_05: I @ 0:20:31
- SPEAKER_05: know @ 0:20:31
- SPEAKER_05: what @ 0:20:31
- SPEAKER_05: my @ 0:20:32
- SPEAKER_05: problem @ 0:20:32
- SPEAKER_05: is @ 0:20:32
- SPEAKER_05: that @ 0:20:32
- SPEAKER_05: I'm @ 0:20:33
- SPEAKER_05: very @ 0:20:33
- SPEAKER_05: lazy @ 0:20:33
- SPEAKER_05: about @ 0:20:34
- SPEAKER_05: writing @ 0:20:34
- SPEAKER_05: documentation. @ 0:20:34

## Segment 304: [0:20:35 - 0:20:40] (SPEAKER_05)

So that'll be very complicated stuff because I don't write any comments for it.

### Word‑level timestamps

- SPEAKER_05: So @ 0:20:35
- SPEAKER_05: that'll @ 0:20:36
- SPEAKER_05: be @ 0:20:36
- SPEAKER_05: very @ 0:20:36
- SPEAKER_05: complicated @ 0:20:37
- SPEAKER_05: stuff @ 0:20:38
- SPEAKER_05: because @ 0:20:38
- SPEAKER_05: I @ 0:20:39
- SPEAKER_05: don't @ 0:20:39
- SPEAKER_05: write @ 0:20:39
- SPEAKER_05: any @ 0:20:39
- SPEAKER_05: comments @ 0:20:39
- SPEAKER_05: for @ 0:20:40
- SPEAKER_05: it. @ 0:20:40

## Segment 305: [0:20:40 - 0:20:43] (SPEAKER_05)

I just look at it really hard and then hopefully I understand it.

### Word‑level timestamps

- SPEAKER_05: I @ 0:20:40
- SPEAKER_05: just @ 0:20:40
- SPEAKER_05: look @ 0:20:41
- SPEAKER_05: at @ 0:20:41
- SPEAKER_05: it @ 0:20:41
- SPEAKER_05: really @ 0:20:41
- SPEAKER_05: hard @ 0:20:41
- SPEAKER_05: and @ 0:20:42
- SPEAKER_05: then @ 0:20:42
- SPEAKER_05: hopefully @ 0:20:42
- SPEAKER_05: I @ 0:20:43
- SPEAKER_05: understand @ 0:20:43
- SPEAKER_05: it. @ 0:20:43

## Segment 306: [0:20:43 - 0:20:46] (SPEAKER_05)

But then for other people, they're like, what the fuck?

### Word‑level timestamps

- SPEAKER_05: But @ 0:20:43
- SPEAKER_05: then @ 0:20:43
- SPEAKER_05: for @ 0:20:44
- SPEAKER_05: other @ 0:20:44
- SPEAKER_05: people, @ 0:20:44
- SPEAKER_05: they're @ 0:20:45
- SPEAKER_05: like, @ 0:20:45
- SPEAKER_05: what @ 0:20:45
- SPEAKER_05: the @ 0:20:45
- SPEAKER_05: fuck? @ 0:20:45

## Segment 307: [0:20:46 - 0:20:49] (SPEAKER_05)

And other people now includes models.

### Word‑level timestamps

- SPEAKER_04: And @ 0:20:46
- SPEAKER_05: other @ 0:20:47
- SPEAKER_05: people @ 0:20:47
- SPEAKER_05: now @ 0:20:47
- SPEAKER_05: includes @ 0:20:48
- SPEAKER_05: models. @ 0:20:48

## Segment 308: [0:20:49 - 0:20:51] (SPEAKER_05)

They look at it, they're like, what the fuck?

### Word‑level timestamps

- SPEAKER_05: They @ 0:20:49
- SPEAKER_05: look @ 0:20:49
- SPEAKER_05: at @ 0:20:50
- SPEAKER_05: it, @ 0:20:50
- SPEAKER_05: they're @ 0:20:50
- SPEAKER_05: like, @ 0:20:50
- SPEAKER_05: what @ 0:20:50
- SPEAKER_05: the @ 0:20:50
- SPEAKER_05: fuck? @ 0:20:51

## Segment 309: [0:20:51 - 0:20:52] (SPEAKER_02)

Yeah.

### Word‑level timestamps

- SPEAKER_02: Yeah. @ 0:20:51

## Segment 310: [0:20:52 - 0:20:53] (SPEAKER_02)

That's honestly the biggest thing.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:20:52
- SPEAKER_02: honestly @ 0:20:53
- SPEAKER_02: the @ 0:20:53
- SPEAKER_02: biggest @ 0:20:53
- SPEAKER_02: thing. @ 0:20:53

## Segment 311: [0:20:53 - 0:20:54] (SPEAKER_02)

And it's cool.

### Word‑level timestamps

- SPEAKER_02: And @ 0:20:53
- SPEAKER_02: it's @ 0:20:54
- SPEAKER_02: cool. @ 0:20:54

## Segment 312: [0:20:54 - 0:20:56] (SPEAKER_02)

It's like writing documentation for AI.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:20:54
- SPEAKER_02: like @ 0:20:54
- SPEAKER_02: writing @ 0:20:54
- SPEAKER_02: documentation @ 0:20:54
- SPEAKER_02: for @ 0:20:55
- SPEAKER_02: AI. @ 0:20:55

## Segment 313: [0:20:56 - 0:20:59] (SPEAKER_02)

You're also writing documentation for humans because it's the same thing.

### Word‑level timestamps

- SPEAKER_02: You're @ 0:20:56
- SPEAKER_02: also @ 0:20:56
- SPEAKER_02: writing @ 0:20:56
- SPEAKER_02: documentation @ 0:20:56
- SPEAKER_02: for @ 0:20:57
- SPEAKER_02: humans @ 0:20:57
- SPEAKER_02: because @ 0:20:58
- SPEAKER_02: it's @ 0:20:58
- SPEAKER_02: the @ 0:20:58
- SPEAKER_02: same @ 0:20:58
- SPEAKER_02: thing. @ 0:20:59

## Segment 314: [0:20:59 - 0:21:01] (SPEAKER_02)

Another thing I do is I use cloud code.

### Word‑level timestamps

- SPEAKER_02: Another @ 0:20:59
- SPEAKER_02: thing @ 0:20:59
- SPEAKER_02: I @ 0:20:59
- SPEAKER_02: do @ 0:21:00
- SPEAKER_02: is @ 0:21:00
- SPEAKER_02: I @ 0:21:00
- SPEAKER_02: use @ 0:21:01
- SPEAKER_02: cloud @ 0:21:01
- SPEAKER_02: code. @ 0:21:01

## Segment 315: [0:21:03 - 0:21:05] (SPEAKER_02)

Cloud code is cool because you can open up these different Git work trees.

### Word‑level timestamps

- SPEAKER_02: Cloud @ 0:21:03
- SPEAKER_02: code @ 0:21:03
- SPEAKER_02: is @ 0:21:03
- SPEAKER_02: cool @ 0:21:03
- SPEAKER_02: because @ 0:21:04
- SPEAKER_02: you @ 0:21:04
- SPEAKER_02: can @ 0:21:04
- SPEAKER_02: open @ 0:21:04
- SPEAKER_02: up @ 0:21:04
- SPEAKER_02: these @ 0:21:04
- SPEAKER_02: different @ 0:21:05
- SPEAKER_02: Git @ 0:21:05
- SPEAKER_02: work @ 0:21:05
- SPEAKER_02: trees. @ 0:21:05

## Segment 316: [0:21:06 - 0:21:11] (SPEAKER_02)

I do this two-step process where Gemini 2.5 Pro is the newest model Google drop.

### Word‑level timestamps

- SPEAKER_02: I @ 0:21:06
- SPEAKER_02: do @ 0:21:06
- SPEAKER_02: this @ 0:21:06
- SPEAKER_02: two-step @ 0:21:06
- SPEAKER_02: process @ 0:21:07
- SPEAKER_02: where @ 0:21:07
- SPEAKER_02: Gemini @ 0:21:08
- SPEAKER_02: 2.5 @ 0:21:08
- SPEAKER_02: Pro @ 0:21:09
- SPEAKER_02: is @ 0:21:09
- SPEAKER_02: the @ 0:21:09
- SPEAKER_02: newest @ 0:21:10
- SPEAKER_02: model @ 0:21:10
- SPEAKER_02: Google @ 0:21:10
- SPEAKER_02: drop. @ 0:21:10

## Segment 317: [0:21:11 - 0:21:12] (SPEAKER_02)

And that has a huge context window.

### Word‑level timestamps

- SPEAKER_02: And @ 0:21:11
- SPEAKER_02: that @ 0:21:11
- SPEAKER_02: has @ 0:21:11
- SPEAKER_02: a @ 0:21:11
- SPEAKER_02: huge @ 0:21:11
- SPEAKER_02: context @ 0:21:11
- SPEAKER_02: window. @ 0:21:12

## Segment 318: [0:21:12 - 0:21:14] (SPEAKER_02)

It has a million contexts in the prompt.

### Word‑level timestamps

- SPEAKER_02: It @ 0:21:12
- SPEAKER_02: has @ 0:21:12
- SPEAKER_02: a @ 0:21:12
- SPEAKER_02: million @ 0:21:12
- SPEAKER_02: contexts @ 0:21:13
- SPEAKER_02: in @ 0:21:13
- SPEAKER_02: the @ 0:21:13
- SPEAKER_02: prompt. @ 0:21:13

## Segment 319: [0:21:14 - 0:21:18] (SPEAKER_02)

So I could kind of stuff a majority of my code base and also Gemini 2.5 Pro.

### Word‑level timestamps

- SPEAKER_02: So @ 0:21:14
- SPEAKER_02: I @ 0:21:14
- SPEAKER_02: could @ 0:21:14
- SPEAKER_02: kind @ 0:21:15
- SPEAKER_02: of @ 0:21:15
- SPEAKER_02: stuff @ 0:21:15
- SPEAKER_02: a @ 0:21:15
- SPEAKER_02: majority @ 0:21:15
- SPEAKER_02: of @ 0:21:16
- SPEAKER_02: my @ 0:21:16
- SPEAKER_02: code @ 0:21:16
- SPEAKER_02: base @ 0:21:16
- SPEAKER_02: and @ 0:21:17
- SPEAKER_02: also @ 0:21:17
- SPEAKER_02: Gemini @ 0:21:17
- SPEAKER_02: 2.5 @ 0:21:18
- SPEAKER_02: Pro. @ 0:21:18

## Segment 320: [0:21:19 - 0:21:26] (SPEAKER_02)

Hey, make me a PRD where you're targeting very specific files and write very specific instructions on how to add this change I'm requesting.

### Word‑level timestamps

- SPEAKER_02: Hey, @ 0:21:19
- SPEAKER_02: make @ 0:21:19
- SPEAKER_02: me @ 0:21:19
- SPEAKER_02: a @ 0:21:19
- SPEAKER_02: PRD @ 0:21:19
- SPEAKER_02: where @ 0:21:20
- SPEAKER_02: you're @ 0:21:20
- SPEAKER_02: targeting @ 0:21:20
- SPEAKER_02: very @ 0:21:21
- SPEAKER_02: specific @ 0:21:21
- SPEAKER_02: files @ 0:21:21
- SPEAKER_02: and @ 0:21:22
- SPEAKER_02: write @ 0:21:22
- SPEAKER_02: very @ 0:21:22
- SPEAKER_02: specific @ 0:21:22
- SPEAKER_02: instructions @ 0:21:23
- SPEAKER_02: on @ 0:21:24
- SPEAKER_02: how @ 0:21:24
- SPEAKER_02: to @ 0:21:24
- SPEAKER_02: add @ 0:21:24
- SPEAKER_02: this @ 0:21:24
- SPEAKER_02: change @ 0:21:25
- SPEAKER_02: I'm @ 0:21:25
- SPEAKER_02: requesting. @ 0:21:25

## Segment 321: [0:21:26 - 0:21:28] (SPEAKER_02)

And it gives me back a PRD.

### Word‑level timestamps

- SPEAKER_02: And @ 0:21:26
- SPEAKER_02: it @ 0:21:26
- SPEAKER_02: gives @ 0:21:26
- SPEAKER_02: me @ 0:21:26
- SPEAKER_02: back @ 0:21:26
- SPEAKER_02: a @ 0:21:27
- SPEAKER_02: PRD. @ 0:21:27

## Segment 322: [0:21:28 - 0:21:30] (SPEAKER_02)

And then I'll take that PRD and I'll give it to quad code.

### Word‑level timestamps

- SPEAKER_02: And @ 0:21:28
- SPEAKER_02: then @ 0:21:28
- SPEAKER_02: I'll @ 0:21:28
- SPEAKER_02: take @ 0:21:28
- SPEAKER_02: that @ 0:21:28
- SPEAKER_02: PRD @ 0:21:28
- SPEAKER_02: and @ 0:21:29
- SPEAKER_02: I'll @ 0:21:29
- SPEAKER_02: give @ 0:21:29
- SPEAKER_02: it @ 0:21:29
- SPEAKER_02: to @ 0:21:29
- SPEAKER_02: quad @ 0:21:29
- SPEAKER_02: code. @ 0:21:30

## Segment 323: [0:21:30 - 0:21:38] (SPEAKER_02)

And because it's very well instructed with my other documentation as well, it's properly one shots doing all of these different file changes.

### Word‑level timestamps

- SPEAKER_02: And @ 0:21:30
- SPEAKER_02: because @ 0:21:30
- SPEAKER_02: it's @ 0:21:31
- SPEAKER_02: very @ 0:21:31
- SPEAKER_02: well @ 0:21:31
- SPEAKER_02: instructed @ 0:21:32
- SPEAKER_02: with @ 0:21:32
- SPEAKER_02: my @ 0:21:32
- SPEAKER_02: other @ 0:21:33
- SPEAKER_02: documentation @ 0:21:33
- SPEAKER_02: as @ 0:21:34
- SPEAKER_02: well, @ 0:21:34
- SPEAKER_02: it's @ 0:21:34
- SPEAKER_02: properly @ 0:21:35
- SPEAKER_02: one @ 0:21:35
- SPEAKER_02: shots @ 0:21:35
- SPEAKER_02: doing @ 0:21:36
- SPEAKER_02: all @ 0:21:36
- SPEAKER_02: of @ 0:21:36
- SPEAKER_02: these @ 0:21:36
- SPEAKER_02: different @ 0:21:37
- SPEAKER_02: file @ 0:21:37
- SPEAKER_02: changes. @ 0:21:37

## Segment 324: [0:21:38 - 0:21:39] (SPEAKER_02)

So I'll launch quad code.

### Word‑level timestamps

- SPEAKER_02: So @ 0:21:38
- SPEAKER_02: I'll @ 0:21:38
- SPEAKER_02: launch @ 0:21:38
- SPEAKER_02: quad @ 0:21:39
- SPEAKER_02: code. @ 0:21:39

## Segment 325: [0:21:40 - 0:21:43] (SPEAKER_02)

And then I'll go eat food or go to the gym or do something.

### Word‑level timestamps

- SPEAKER_02: And @ 0:21:40
- SPEAKER_02: then @ 0:21:40
- SPEAKER_02: I'll @ 0:21:41
- SPEAKER_02: go @ 0:21:41
- SPEAKER_02: eat @ 0:21:41
- SPEAKER_02: food @ 0:21:41
- SPEAKER_02: or @ 0:21:42
- SPEAKER_02: go @ 0:21:42
- SPEAKER_02: to @ 0:21:42
- SPEAKER_02: the @ 0:21:42
- SPEAKER_02: gym @ 0:21:42
- SPEAKER_02: or @ 0:21:42
- SPEAKER_02: do @ 0:21:42
- SPEAKER_02: something. @ 0:21:43

## Segment 326: [0:21:43 - 0:21:45] (SPEAKER_02)

I come back to a proper upgrade.

### Word‑level timestamps

- SPEAKER_02: I @ 0:21:43
- SPEAKER_02: come @ 0:21:43
- SPEAKER_02: back @ 0:21:43
- SPEAKER_02: to @ 0:21:44
- SPEAKER_02: a @ 0:21:44
- SPEAKER_02: proper @ 0:21:44
- SPEAKER_02: upgrade. @ 0:21:44

## Segment 327: [0:21:45 - 0:21:49] (SPEAKER_02)

I could actually pull into my code base because context is everything.

### Word‑level timestamps

- SPEAKER_02: I @ 0:21:45
- SPEAKER_02: could @ 0:21:45
- SPEAKER_02: actually @ 0:21:45
- SPEAKER_02: pull @ 0:21:45
- SPEAKER_02: into @ 0:21:46
- SPEAKER_02: my @ 0:21:46
- SPEAKER_02: code @ 0:21:46
- SPEAKER_02: base @ 0:21:46
- SPEAKER_02: because @ 0:21:47
- SPEAKER_02: context @ 0:21:47
- SPEAKER_02: is @ 0:21:48
- SPEAKER_02: everything. @ 0:21:48

## Segment 328: [0:21:49 - 0:21:55] (SPEAKER_02)

So getting the context from Gemini as a PRD and the documentation lets Cloud be like, OK, I know exactly what to do.

### Word‑level timestamps

- SPEAKER_02: So @ 0:21:49
- SPEAKER_02: getting @ 0:21:49
- SPEAKER_02: the @ 0:21:49
- SPEAKER_02: context @ 0:21:50
- SPEAKER_02: from @ 0:21:50
- SPEAKER_02: Gemini @ 0:21:51
- SPEAKER_02: as @ 0:21:51
- SPEAKER_02: a @ 0:21:51
- SPEAKER_02: PRD @ 0:21:51
- SPEAKER_02: and @ 0:21:52
- SPEAKER_02: the @ 0:21:52
- SPEAKER_02: documentation @ 0:21:52
- SPEAKER_02: lets @ 0:21:53
- SPEAKER_02: Cloud @ 0:21:53
- SPEAKER_02: be @ 0:21:54
- SPEAKER_02: like, @ 0:21:54
- SPEAKER_02: OK, @ 0:21:54
- SPEAKER_02: I @ 0:21:54
- SPEAKER_02: know @ 0:21:54
- SPEAKER_02: exactly @ 0:21:54
- SPEAKER_02: what @ 0:21:55
- SPEAKER_02: to @ 0:21:55
- SPEAKER_02: do. @ 0:21:55

## Segment 329: [0:21:55 - 0:21:58] (SPEAKER_02)

I know exactly how to not fuck up your code base.

### Word‑level timestamps

- SPEAKER_02: I @ 0:21:55
- SPEAKER_02: know @ 0:21:56
- SPEAKER_02: exactly @ 0:21:56
- SPEAKER_02: how @ 0:21:56
- SPEAKER_02: to @ 0:21:56
- SPEAKER_02: not @ 0:21:56
- SPEAKER_02: fuck @ 0:21:57
- SPEAKER_02: up @ 0:21:57
- SPEAKER_02: your @ 0:21:57
- SPEAKER_02: code @ 0:21:57
- SPEAKER_02: base. @ 0:21:57

## Segment 330: [0:21:58 - 0:22:01] (SPEAKER_02)

When you get in a Doom loop, the biggest mistake is to keep on the Doom loop.

### Word‑level timestamps

- SPEAKER_02: When @ 0:21:58
- SPEAKER_02: you @ 0:21:58
- SPEAKER_02: get @ 0:21:58
- SPEAKER_02: in @ 0:21:58
- SPEAKER_02: a @ 0:21:58
- SPEAKER_02: Doom @ 0:21:58
- SPEAKER_02: loop, @ 0:21:58
- SPEAKER_02: the @ 0:21:59
- SPEAKER_02: biggest @ 0:21:59
- SPEAKER_02: mistake @ 0:22:00
- SPEAKER_02: is @ 0:22:00
- SPEAKER_02: to @ 0:22:00
- SPEAKER_02: keep @ 0:22:00
- SPEAKER_02: on @ 0:22:00
- SPEAKER_02: the @ 0:22:01
- SPEAKER_02: Doom @ 0:22:01
- SPEAKER_02: loop. @ 0:22:01

## Segment 331: [0:22:01 - 0:22:02] (SPEAKER_02)

Honestly, just completely restart.

### Word‑level timestamps

- SPEAKER_02: Honestly, @ 0:22:01
- SPEAKER_02: just @ 0:22:02
- SPEAKER_02: completely @ 0:22:02
- SPEAKER_02: restart. @ 0:22:02

## Segment 332: [0:22:03 - 0:22:06] (SPEAKER_02)

So what I do, if a prompt doesn't go well, I'll just undo the entire change.

### Word‑level timestamps

- SPEAKER_02: So @ 0:22:03
- SPEAKER_02: what @ 0:22:03
- SPEAKER_02: I @ 0:22:03
- SPEAKER_02: do, @ 0:22:03
- SPEAKER_02: if @ 0:22:03
- SPEAKER_02: a @ 0:22:03
- SPEAKER_02: prompt @ 0:22:03
- SPEAKER_02: doesn't @ 0:22:04
- SPEAKER_02: go @ 0:22:04
- SPEAKER_02: well, @ 0:22:04
- SPEAKER_02: I'll @ 0:22:04
- SPEAKER_02: just @ 0:22:05
- SPEAKER_02: undo @ 0:22:05
- SPEAKER_02: the @ 0:22:05
- SPEAKER_02: entire @ 0:22:05
- SPEAKER_02: change. @ 0:22:06

## Segment 333: [0:22:07 - 0:22:08] (SPEAKER_02)

And then I'll look at my system prompt.

### Word‑level timestamps

- SPEAKER_02: And @ 0:22:07
- SPEAKER_02: then @ 0:22:07
- SPEAKER_02: I'll @ 0:22:07
- SPEAKER_02: look @ 0:22:07
- SPEAKER_02: at @ 0:22:07
- SPEAKER_02: my @ 0:22:07
- SPEAKER_02: system @ 0:22:07
- SPEAKER_02: prompt. @ 0:22:08

## Segment 334: [0:22:08 - 0:22:10] (SPEAKER_02)

I'll be like, OK, where did he fuck up?

### Word‑level timestamps

- SPEAKER_02: I'll @ 0:22:08
- SPEAKER_02: be @ 0:22:08
- SPEAKER_02: like, @ 0:22:08
- SPEAKER_02: OK, @ 0:22:08
- SPEAKER_02: where @ 0:22:09
- SPEAKER_02: did @ 0:22:09
- SPEAKER_02: he @ 0:22:09
- SPEAKER_02: fuck @ 0:22:09
- SPEAKER_02: up? @ 0:22:10

## Segment 335: [0:22:10 - 0:22:12] (SPEAKER_02)

Oh, he fucked up in this specific moment.

### Word‑level timestamps

- SPEAKER_02: Oh, @ 0:22:10
- SPEAKER_02: he @ 0:22:10
- SPEAKER_02: fucked @ 0:22:10
- SPEAKER_02: up @ 0:22:10
- SPEAKER_02: in @ 0:22:10
- SPEAKER_02: this @ 0:22:11
- SPEAKER_02: specific @ 0:22:11
- SPEAKER_02: moment. @ 0:22:11

## Segment 336: [0:22:12 - 0:22:15] (SPEAKER_02)

Oh, it's because he didn't know to use this file instead.

### Word‑level timestamps

- SPEAKER_02: Oh, @ 0:22:12
- SPEAKER_02: it's @ 0:22:12
- SPEAKER_02: because @ 0:22:13
- SPEAKER_02: he @ 0:22:13
- SPEAKER_02: didn't @ 0:22:13
- SPEAKER_02: know @ 0:22:13
- SPEAKER_02: to @ 0:22:13
- SPEAKER_02: use @ 0:22:14
- SPEAKER_02: this @ 0:22:14
- SPEAKER_02: file @ 0:22:14
- SPEAKER_02: instead. @ 0:22:14

## Segment 337: [0:22:15 - 0:22:18] (SPEAKER_02)

So I'll add the extra instructions and then I'll run the next loop.

### Word‑level timestamps

- SPEAKER_02: So @ 0:22:15
- SPEAKER_02: I'll @ 0:22:15
- SPEAKER_02: add @ 0:22:15
- SPEAKER_02: the @ 0:22:15
- SPEAKER_02: extra @ 0:22:16
- SPEAKER_02: instructions @ 0:22:16
- SPEAKER_02: and @ 0:22:17
- SPEAKER_02: then @ 0:22:17
- SPEAKER_02: I'll @ 0:22:17
- SPEAKER_02: run @ 0:22:17
- SPEAKER_02: the @ 0:22:17
- SPEAKER_02: next @ 0:22:17
- SPEAKER_02: loop. @ 0:22:17

## Segment 338: [0:22:18 - 0:22:20] (SPEAKER_02)

Usually it gets it right the second try.

### Word‑level timestamps

- SPEAKER_02: Usually @ 0:22:18
- SPEAKER_02: it @ 0:22:18
- SPEAKER_02: gets @ 0:22:18
- SPEAKER_02: it @ 0:22:19
- SPEAKER_02: right @ 0:22:19
- SPEAKER_02: the @ 0:22:19
- SPEAKER_02: second @ 0:22:19
- SPEAKER_02: try. @ 0:22:19

## Segment 339: [0:22:20 - 0:22:23] (SPEAKER_02)

And it's honestly 99% of the problems I've had, it was me.

### Word‑level timestamps

- SPEAKER_02: And @ 0:22:20
- SPEAKER_02: it's @ 0:22:20
- SPEAKER_02: honestly @ 0:22:21
- SPEAKER_02: 99% @ 0:22:21
- SPEAKER_02: of @ 0:22:22
- SPEAKER_02: the @ 0:22:22
- SPEAKER_02: problems @ 0:22:22
- SPEAKER_02: I've @ 0:22:22
- SPEAKER_02: had, @ 0:22:22
- SPEAKER_02: it @ 0:22:23
- SPEAKER_02: was @ 0:22:23
- SPEAKER_02: me. @ 0:22:23

## Segment 340: [0:22:23 - 0:22:25] (SPEAKER_02)

I didn't give it enough context in the prompt.

### Word‑level timestamps

- SPEAKER_02: I @ 0:22:23
- SPEAKER_02: didn't @ 0:22:24
- SPEAKER_02: give @ 0:22:24
- SPEAKER_02: it @ 0:22:24
- SPEAKER_02: enough @ 0:22:24
- SPEAKER_02: context @ 0:22:24
- SPEAKER_02: in @ 0:22:25
- SPEAKER_02: the @ 0:22:25
- SPEAKER_02: prompt. @ 0:22:25

## Segment 341: [0:22:25 - 0:22:26] (SPEAKER_02)

I didn't instruct it well enough.

### Word‑level timestamps

- SPEAKER_02: I @ 0:22:25
- SPEAKER_02: didn't @ 0:22:25
- SPEAKER_02: instruct @ 0:22:25
- SPEAKER_02: it @ 0:22:26
- SPEAKER_02: well @ 0:22:26
- SPEAKER_02: enough. @ 0:22:26

## Segment 342: [0:22:27 - 0:22:29] (SPEAKER_02)

And I did instruct it better than it did a really good job.

### Word‑level timestamps

- SPEAKER_02: And @ 0:22:27
- SPEAKER_02: I @ 0:22:27
- SPEAKER_02: did @ 0:22:27
- SPEAKER_02: instruct @ 0:22:27
- SPEAKER_02: it @ 0:22:27
- SPEAKER_02: better @ 0:22:27
- SPEAKER_02: than @ 0:22:28
- SPEAKER_02: it @ 0:22:28
- SPEAKER_02: did @ 0:22:28
- SPEAKER_02: a @ 0:22:28
- SPEAKER_02: really @ 0:22:28
- SPEAKER_02: good @ 0:22:29
- SPEAKER_02: job. @ 0:22:29

## Segment 343: [0:22:30 - 0:22:30] (SPEAKER_02)

That's how I run that.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:22:30
- SPEAKER_02: how @ 0:22:30
- SPEAKER_02: I @ 0:22:30
- SPEAKER_02: run @ 0:22:30
- SPEAKER_02: that. @ 0:22:30

## Segment 344: [0:22:31 - 0:22:32] (SPEAKER_02)

What's up, Aaron?

### Word‑level timestamps

- SPEAKER_02: What's @ 0:22:31
- SPEAKER_02: up, @ 0:22:31
- SPEAKER_02: Aaron? @ 0:22:31

## Segment 345: [0:22:32 - 0:22:39] (SPEAKER_00)

So I feel like throughout the presentation, there were a lot of comments where you're actually saying something that's very deeply philosophical.

### Word‑level timestamps

- SPEAKER_00: So @ 0:22:32
- SPEAKER_00: I @ 0:22:33
- SPEAKER_00: feel @ 0:22:33
- SPEAKER_00: like @ 0:22:33
- SPEAKER_00: throughout @ 0:22:34
- SPEAKER_00: the @ 0:22:34
- SPEAKER_00: presentation, @ 0:22:34
- SPEAKER_00: there @ 0:22:35
- SPEAKER_00: were @ 0:22:35
- SPEAKER_00: a @ 0:22:36
- SPEAKER_00: lot @ 0:22:36
- SPEAKER_00: of @ 0:22:36
- SPEAKER_00: comments @ 0:22:36
- SPEAKER_00: where @ 0:22:36
- SPEAKER_00: you're @ 0:22:37
- SPEAKER_00: actually @ 0:22:37
- SPEAKER_00: saying @ 0:22:37
- SPEAKER_00: something @ 0:22:37
- SPEAKER_00: that's @ 0:22:38
- SPEAKER_00: very @ 0:22:38
- SPEAKER_00: deeply @ 0:22:38
- SPEAKER_00: philosophical. @ 0:22:39

## Segment 346: [0:22:40 - 0:22:47] (SPEAKER_00)

And it seems you're realizing these lessons through the last two years about yourself and your relationship to AI.

### Word‑level timestamps

- SPEAKER_00: And @ 0:22:40
- SPEAKER_00: it @ 0:22:40
- SPEAKER_00: seems @ 0:22:40
- SPEAKER_00: you're @ 0:22:41
- SPEAKER_00: realizing @ 0:22:41
- SPEAKER_00: these @ 0:22:42
- SPEAKER_00: lessons @ 0:22:42
- SPEAKER_00: through @ 0:22:43
- SPEAKER_00: the @ 0:22:43
- SPEAKER_00: last @ 0:22:43
- SPEAKER_00: two @ 0:22:43
- SPEAKER_00: years @ 0:22:43
- SPEAKER_00: about @ 0:22:44
- SPEAKER_00: yourself @ 0:22:44
- SPEAKER_00: and @ 0:22:45
- SPEAKER_00: your @ 0:22:45
- SPEAKER_00: relationship @ 0:22:45
- SPEAKER_00: to @ 0:22:46
- SPEAKER_00: AI. @ 0:22:46

## Segment 347: [0:22:47 - 0:22:47] (SPEAKER_00)

Yeah.

### Word‑level timestamps

- SPEAKER_00: Yeah. @ 0:22:47

## Segment 348: [0:22:47 - 0:22:55] (SPEAKER_00)

And it makes it seem like it's a very deep idea that I think a lot of people who are thinking about AI philosophically

### Word‑level timestamps

- SPEAKER_00: And @ 0:22:47
- SPEAKER_00: it @ 0:22:47
- SPEAKER_00: makes @ 0:22:48
- SPEAKER_00: it @ 0:22:48
- SPEAKER_00: seem @ 0:22:48
- SPEAKER_00: like @ 0:22:48
- SPEAKER_00: it's @ 0:22:48
- SPEAKER_00: a @ 0:22:49
- SPEAKER_00: very @ 0:22:49
- SPEAKER_00: deep @ 0:22:49
- SPEAKER_00: idea @ 0:22:50
- SPEAKER_00: that @ 0:22:50
- SPEAKER_00: I @ 0:22:50
- SPEAKER_00: think @ 0:22:50
- SPEAKER_00: a @ 0:22:51
- SPEAKER_00: lot @ 0:22:51
- SPEAKER_00: of @ 0:22:51
- SPEAKER_00: people @ 0:22:51
- SPEAKER_00: who @ 0:22:52
- SPEAKER_00: are @ 0:22:52
- SPEAKER_00: thinking @ 0:22:53
- SPEAKER_00: about @ 0:22:53
- SPEAKER_00: AI @ 0:22:53
- SPEAKER_00: philosophically @ 0:22:54

## Segment 349: [0:22:55 - 0:23:00] (SPEAKER_00)

A lot of them are bigger into the actual process of, oh, AI's going to kill us all.

### Word‑level timestamps

- SPEAKER_00: A @ 0:22:55
- SPEAKER_00: lot @ 0:22:55
- SPEAKER_00: of @ 0:22:55
- SPEAKER_00: them @ 0:22:56
- SPEAKER_00: are @ 0:22:56
- SPEAKER_00: bigger @ 0:22:56
- SPEAKER_00: into @ 0:22:56
- SPEAKER_00: the @ 0:22:57
- SPEAKER_00: actual @ 0:22:57
- SPEAKER_00: process @ 0:22:57
- SPEAKER_00: of, @ 0:22:58
- SPEAKER_00: oh, @ 0:22:58
- SPEAKER_00: AI's @ 0:22:59
- SPEAKER_00: going @ 0:22:59
- SPEAKER_00: to @ 0:22:59
- SPEAKER_00: kill @ 0:22:59
- SPEAKER_00: us @ 0:22:59
- SPEAKER_00: all. @ 0:22:59

## Segment 350: [0:23:00 - 0:23:01] (SPEAKER_00)

It's very shallow.

### Word‑level timestamps

- SPEAKER_00: It's @ 0:23:00
- SPEAKER_00: very @ 0:23:00
- SPEAKER_00: shallow. @ 0:23:00

## Segment 351: [0:23:01 - 0:23:02] (SPEAKER_00)

And I'm just curious.

### Word‑level timestamps

- SPEAKER_00: And @ 0:23:01
- SPEAKER_00: I'm @ 0:23:02
- SPEAKER_00: just @ 0:23:02
- SPEAKER_00: curious. @ 0:23:02

## Segment 352: [0:23:02 - 0:23:06] (SPEAKER_00)

I know that you're teaching me to build a code, and you're showing your process publicly.

### Word‑level timestamps

- SPEAKER_00: I @ 0:23:02
- SPEAKER_00: know @ 0:23:02
- SPEAKER_00: that @ 0:23:03
- SPEAKER_00: you're @ 0:23:03
- SPEAKER_00: teaching @ 0:23:03
- SPEAKER_00: me @ 0:23:04
- SPEAKER_00: to @ 0:23:04
- SPEAKER_00: build @ 0:23:04
- SPEAKER_00: a @ 0:23:04
- SPEAKER_00: code, @ 0:23:04
- SPEAKER_00: and @ 0:23:04
- SPEAKER_00: you're @ 0:23:04
- SPEAKER_00: showing @ 0:23:05
- SPEAKER_00: your @ 0:23:05
- SPEAKER_00: process @ 0:23:05
- SPEAKER_00: publicly. @ 0:23:06

## Segment 353: [0:23:07 - 0:23:14] (SPEAKER_00)

Are you also sharing the way that your thoughts on yourself or society really should be?

### Word‑level timestamps

- SPEAKER_00: Are @ 0:23:07
- SPEAKER_00: you @ 0:23:07
- SPEAKER_00: also @ 0:23:07
- SPEAKER_00: sharing @ 0:23:08
- SPEAKER_00: the @ 0:23:08
- SPEAKER_00: way @ 0:23:09
- SPEAKER_00: that @ 0:23:09
- SPEAKER_00: your @ 0:23:10
- SPEAKER_00: thoughts @ 0:23:10
- SPEAKER_00: on @ 0:23:11
- SPEAKER_00: yourself @ 0:23:11
- SPEAKER_00: or @ 0:23:12
- SPEAKER_00: society @ 0:23:12
- SPEAKER_00: really @ 0:23:12
- SPEAKER_00: should @ 0:23:14
- SPEAKER_00: be? @ 0:23:14

## Segment 354: [0:23:14 - 0:23:15] (SPEAKER_02)

I got stopped this morning.

### Word‑level timestamps

- SPEAKER_02: I @ 0:23:14
- SPEAKER_02: got @ 0:23:14
- SPEAKER_02: stopped @ 0:23:15
- SPEAKER_02: this @ 0:23:15
- SPEAKER_02: morning. @ 0:23:15

## Segment 355: [0:23:15 - 0:23:17] (SPEAKER_02)

I was at a cafe and I got stopped this morning.

### Word‑level timestamps

- SPEAKER_02: I @ 0:23:15
- SPEAKER_02: was @ 0:23:15
- SPEAKER_02: at @ 0:23:16
- SPEAKER_02: a @ 0:23:16
- SPEAKER_02: cafe @ 0:23:16
- SPEAKER_02: and @ 0:23:16
- SPEAKER_02: I @ 0:23:16
- SPEAKER_02: got @ 0:23:16
- SPEAKER_02: stopped @ 0:23:17
- SPEAKER_02: this @ 0:23:17
- SPEAKER_02: morning. @ 0:23:17

## Segment 356: [0:23:18 - 0:23:19] (SPEAKER_02)

And this guy came up to me.

### Word‑level timestamps

- SPEAKER_02: And @ 0:23:18
- SPEAKER_02: this @ 0:23:18
- SPEAKER_02: guy @ 0:23:18
- SPEAKER_02: came @ 0:23:18
- SPEAKER_02: up @ 0:23:19
- SPEAKER_02: to @ 0:23:19
- SPEAKER_02: me. @ 0:23:19

## Segment 357: [0:23:19 - 0:23:21] (SPEAKER_02)

And he was a college kid around my age.

### Word‑level timestamps

- SPEAKER_02: And @ 0:23:19
- SPEAKER_02: he @ 0:23:20
- SPEAKER_02: was @ 0:23:20
- SPEAKER_02: a @ 0:23:20
- SPEAKER_02: college @ 0:23:20
- SPEAKER_02: kid @ 0:23:20
- SPEAKER_02: around @ 0:23:20
- SPEAKER_02: my @ 0:23:21
- SPEAKER_02: age. @ 0:23:21

## Segment 358: [0:23:22 - 0:23:23] (SPEAKER_02)

And he's not even looking at me.

### Word‑level timestamps

- SPEAKER_02: And @ 0:23:22
- SPEAKER_02: he's @ 0:23:22
- SPEAKER_02: not @ 0:23:22
- SPEAKER_02: even @ 0:23:22
- SPEAKER_02: looking @ 0:23:22
- SPEAKER_02: at @ 0:23:23
- SPEAKER_02: me. @ 0:23:23

## Segment 359: [0:23:23 - 0:23:23] (SPEAKER_02)

Imagine I'm right here.

### Word‑level timestamps

- SPEAKER_02: Imagine @ 0:23:23
- SPEAKER_02: I'm @ 0:23:23
- SPEAKER_02: right @ 0:23:23
- SPEAKER_02: here. @ 0:23:23

## Segment 360: [0:23:24 - 0:23:25] (SPEAKER_02)

He's just, hey, get mad.

### Word‑level timestamps

- SPEAKER_02: He's @ 0:23:24
- SPEAKER_02: just, @ 0:23:24
- SPEAKER_02: hey, @ 0:23:24
- SPEAKER_02: get @ 0:23:24
- SPEAKER_02: mad. @ 0:23:24

## Segment 361: [0:23:25 - 0:23:26] (SPEAKER_02)

I'm trying to be more social.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:23:25
- SPEAKER_02: trying @ 0:23:25
- SPEAKER_02: to @ 0:23:25
- SPEAKER_02: be @ 0:23:25
- SPEAKER_02: more @ 0:23:25
- SPEAKER_02: social. @ 0:23:25

## Segment 362: [0:23:26 - 0:23:28] (SPEAKER_02)

I'm doing this Be Bold challenge.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:23:26
- SPEAKER_02: doing @ 0:23:26
- SPEAKER_02: this @ 0:23:26
- SPEAKER_02: Be @ 0:23:27
- SPEAKER_02: Bold @ 0:23:27
- SPEAKER_02: challenge. @ 0:23:27

## Segment 363: [0:23:28 - 0:23:30] (SPEAKER_02)

I kind of want to open up and have a conversation with you.

### Word‑level timestamps

- SPEAKER_02: I @ 0:23:28
- SPEAKER_02: kind @ 0:23:28
- SPEAKER_02: of @ 0:23:28
- SPEAKER_02: want @ 0:23:28
- SPEAKER_02: to @ 0:23:28
- SPEAKER_02: open @ 0:23:28
- SPEAKER_02: up @ 0:23:29
- SPEAKER_02: and @ 0:23:29
- SPEAKER_02: have @ 0:23:29
- SPEAKER_02: a @ 0:23:29
- SPEAKER_02: conversation @ 0:23:29
- SPEAKER_02: with @ 0:23:30
- SPEAKER_02: you. @ 0:23:30

## Segment 364: [0:23:30 - 0:23:31] (SPEAKER_02)

I'm like, oh, fuck yeah.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:23:30
- SPEAKER_02: like, @ 0:23:30
- SPEAKER_02: oh, @ 0:23:30
- SPEAKER_02: fuck @ 0:23:30
- SPEAKER_02: yeah. @ 0:23:31

## Segment 365: [0:23:31 - 0:23:32] (SPEAKER_02)

What do you want to talk about?

### Word‑level timestamps

- SPEAKER_02: What @ 0:23:31
- SPEAKER_02: do @ 0:23:31
- SPEAKER_02: you @ 0:23:31
- SPEAKER_02: want @ 0:23:31
- SPEAKER_02: to @ 0:23:31
- SPEAKER_02: talk @ 0:23:31
- SPEAKER_02: about? @ 0:23:31

## Segment 366: [0:23:32 - 0:23:35] (SPEAKER_02)

And then the first thing he hit me with is, are you religious?

### Word‑level timestamps

- SPEAKER_02: And @ 0:23:32
- SPEAKER_02: then @ 0:23:32
- SPEAKER_02: the @ 0:23:33
- SPEAKER_02: first @ 0:23:33
- SPEAKER_02: thing @ 0:23:33
- SPEAKER_02: he @ 0:23:33
- SPEAKER_02: hit @ 0:23:33
- SPEAKER_02: me @ 0:23:33
- SPEAKER_02: with @ 0:23:33
- SPEAKER_02: is, @ 0:23:34
- SPEAKER_02: are @ 0:23:34
- SPEAKER_02: you @ 0:23:34
- SPEAKER_02: religious? @ 0:23:35

## Segment 367: [0:23:35 - 0:23:37] (SPEAKER_02)

Are you Catholic or Christian at all?

### Word‑level timestamps

- SPEAKER_02: Are @ 0:23:35
- SPEAKER_02: you @ 0:23:35
- SPEAKER_02: Catholic @ 0:23:35
- SPEAKER_02: or @ 0:23:36
- SPEAKER_02: Christian @ 0:23:36
- SPEAKER_02: at @ 0:23:36
- SPEAKER_02: all? @ 0:23:36

## Segment 368: [0:23:37 - 0:23:39] (SPEAKER_02)

I was like, honestly, not really.

### Word‑level timestamps

- SPEAKER_02: I @ 0:23:37
- SPEAKER_02: was @ 0:23:37
- SPEAKER_02: like, @ 0:23:37
- SPEAKER_02: honestly, @ 0:23:37
- SPEAKER_02: not @ 0:23:38
- SPEAKER_02: really. @ 0:23:38

## Segment 369: [0:23:39 - 0:23:40] (SPEAKER_02)

I'm more so spiritual.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:23:39
- SPEAKER_02: more @ 0:23:39
- SPEAKER_02: so @ 0:23:39
- SPEAKER_02: spiritual. @ 0:23:40

## Segment 370: [0:23:40 - 0:23:42] (SPEAKER_02)

And I stopped for a sec.

### Word‑level timestamps

- SPEAKER_02: And @ 0:23:40
- SPEAKER_02: I @ 0:23:41
- SPEAKER_02: stopped @ 0:23:41
- SPEAKER_02: for @ 0:23:42
- SPEAKER_02: a @ 0:23:42
- SPEAKER_02: sec. @ 0:23:42

## Segment 371: [0:23:42 - 0:23:44] (SPEAKER_02)

And I was like,

### Word‑level timestamps

- SPEAKER_02: And @ 0:23:42
- SPEAKER_02: I @ 0:23:43
- SPEAKER_02: was @ 0:23:43
- SPEAKER_02: like, @ 0:23:43

## Segment 372: [0:23:44 - 0:23:49] (SPEAKER_02)

I'm actually an AI developer and working with AI made me a lot more religious than I thought I would be.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:23:44
- SPEAKER_02: actually @ 0:23:44
- SPEAKER_02: an @ 0:23:44
- SPEAKER_02: AI @ 0:23:44
- SPEAKER_02: developer @ 0:23:45
- SPEAKER_02: and @ 0:23:45
- SPEAKER_02: working @ 0:23:45
- SPEAKER_02: with @ 0:23:46
- SPEAKER_02: AI @ 0:23:46
- SPEAKER_02: made @ 0:23:46
- SPEAKER_02: me @ 0:23:46
- SPEAKER_02: a @ 0:23:47
- SPEAKER_02: lot @ 0:23:47
- SPEAKER_02: more @ 0:23:47
- SPEAKER_02: religious @ 0:23:47
- SPEAKER_02: than @ 0:23:48
- SPEAKER_02: I @ 0:23:48
- SPEAKER_02: thought @ 0:23:48
- SPEAKER_02: I @ 0:23:48
- SPEAKER_02: would @ 0:23:48
- SPEAKER_02: be. @ 0:23:49

## Segment 373: [0:23:49 - 0:23:53] (SPEAKER_02)

Because I've actually had one simulation that kind of shook my soul.

### Word‑level timestamps

- SPEAKER_02: Because @ 0:23:49
- SPEAKER_02: I've @ 0:23:50
- SPEAKER_02: actually @ 0:23:50
- SPEAKER_02: had @ 0:23:50
- SPEAKER_02: one @ 0:23:50
- SPEAKER_02: simulation @ 0:23:51
- SPEAKER_02: that @ 0:23:51
- SPEAKER_02: kind @ 0:23:51
- SPEAKER_02: of @ 0:23:52
- SPEAKER_02: shook @ 0:23:52
- SPEAKER_02: my @ 0:23:52
- SPEAKER_02: soul. @ 0:23:52

## Segment 374: [0:23:53 - 0:23:58] (SPEAKER_02)

Is that this little world simulation of a bunch of my booze in the boo kingdom and just running and talking to each other.

### Word‑level timestamps

- SPEAKER_02: Is @ 0:23:53
- SPEAKER_02: that @ 0:23:53
- SPEAKER_02: this @ 0:23:53
- SPEAKER_02: little @ 0:23:53
- SPEAKER_02: world @ 0:23:54
- SPEAKER_02: simulation @ 0:23:54
- SPEAKER_02: of @ 0:23:55
- SPEAKER_02: a @ 0:23:55
- SPEAKER_02: bunch @ 0:23:55
- SPEAKER_02: of @ 0:23:55
- SPEAKER_02: my @ 0:23:55
- SPEAKER_02: booze @ 0:23:55
- SPEAKER_02: in @ 0:23:56
- SPEAKER_02: the @ 0:23:56
- SPEAKER_02: boo @ 0:23:56
- SPEAKER_02: kingdom @ 0:23:56
- SPEAKER_02: and @ 0:23:57
- SPEAKER_02: just @ 0:23:57
- SPEAKER_02: running @ 0:23:57
- SPEAKER_02: and @ 0:23:57
- SPEAKER_02: talking @ 0:23:57
- SPEAKER_02: to @ 0:23:57
- SPEAKER_02: each @ 0:23:57
- SPEAKER_02: other. @ 0:23:58

## Segment 375: [0:23:58 - 0:24:05] (SPEAKER_02)

Literally living their own blissful, ignorant life not knowing that there's literally a man behind the screen watching their every single action.

### Word‑level timestamps

- SPEAKER_02: Literally @ 0:23:58
- SPEAKER_02: living @ 0:23:58
- SPEAKER_02: their @ 0:23:59
- SPEAKER_02: own @ 0:23:59
- SPEAKER_02: blissful, @ 0:23:59
- SPEAKER_02: ignorant @ 0:24:00
- SPEAKER_02: life @ 0:24:00
- SPEAKER_02: not @ 0:24:00
- SPEAKER_02: knowing @ 0:24:01
- SPEAKER_02: that @ 0:24:01
- SPEAKER_02: there's @ 0:24:01
- SPEAKER_02: literally @ 0:24:01
- SPEAKER_02: a @ 0:24:02
- SPEAKER_02: man @ 0:24:02
- SPEAKER_02: behind @ 0:24:02
- SPEAKER_02: the @ 0:24:03
- SPEAKER_02: screen @ 0:24:03
- SPEAKER_02: watching @ 0:24:03
- SPEAKER_02: their @ 0:24:03
- SPEAKER_02: every @ 0:24:04
- SPEAKER_02: single @ 0:24:04
- SPEAKER_02: action. @ 0:24:04

## Segment 376: [0:24:05 - 0:24:08] (SPEAKER_02)

And then one of the AIs hit me with a, I wonder if I'm real.

### Word‑level timestamps

- SPEAKER_02: And @ 0:24:05
- SPEAKER_02: then @ 0:24:05
- SPEAKER_02: one @ 0:24:06
- SPEAKER_02: of @ 0:24:06
- SPEAKER_02: the @ 0:24:06
- SPEAKER_02: AIs @ 0:24:06
- SPEAKER_02: hit @ 0:24:06
- SPEAKER_02: me @ 0:24:06
- SPEAKER_02: with @ 0:24:07
- SPEAKER_02: a, @ 0:24:07
- SPEAKER_02: I @ 0:24:08
- SPEAKER_02: wonder @ 0:24:08
- SPEAKER_02: if @ 0:24:08
- SPEAKER_02: I'm @ 0:24:08
- SPEAKER_02: real. @ 0:24:08

## Segment 377: [0:24:09 - 0:24:10] (SPEAKER_02)

I'm like, why would you prompt that?

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:24:09
- SPEAKER_02: like, @ 0:24:09
- SPEAKER_02: why @ 0:24:09
- SPEAKER_02: would @ 0:24:09
- SPEAKER_02: you @ 0:24:10
- SPEAKER_02: prompt @ 0:24:10
- SPEAKER_02: that? @ 0:24:10

## Segment 378: [0:24:10 - 0:24:13] (SPEAKER_02)

Looking at this, I'm like, I wonder if I'm real.

### Word‑level timestamps

- SPEAKER_02: Looking @ 0:24:10
- SPEAKER_02: at @ 0:24:10
- SPEAKER_02: this, @ 0:24:11
- SPEAKER_02: I'm @ 0:24:11
- SPEAKER_02: like, @ 0:24:11
- SPEAKER_02: I @ 0:24:12
- SPEAKER_00: wonder @ 0:24:12
- SPEAKER_00: if @ 0:24:12
- SPEAKER_00: I'm @ 0:24:12
- SPEAKER_02: real. @ 0:24:12

## Segment 379: [0:24:13 - 0:24:21] (SPEAKER_02)

Okay, if there is a God out there and he's just watching me behind a monitor, what really is the difference if everything is energy and AI is also energy and I'm also energy?

### Word‑level timestamps

- SPEAKER_02: Okay, @ 0:24:13
- SPEAKER_02: if @ 0:24:14
- SPEAKER_02: there @ 0:24:14
- SPEAKER_02: is @ 0:24:14
- SPEAKER_02: a @ 0:24:14
- SPEAKER_02: God @ 0:24:14
- SPEAKER_02: out @ 0:24:14
- SPEAKER_02: there @ 0:24:15
- SPEAKER_02: and @ 0:24:15
- SPEAKER_02: he's @ 0:24:15
- SPEAKER_02: just @ 0:24:15
- SPEAKER_02: watching @ 0:24:15
- SPEAKER_02: me @ 0:24:15
- SPEAKER_02: behind @ 0:24:16
- SPEAKER_02: a @ 0:24:16
- SPEAKER_02: monitor, @ 0:24:16
- SPEAKER_02: what @ 0:24:16
- SPEAKER_02: really @ 0:24:17
- SPEAKER_02: is @ 0:24:17
- SPEAKER_02: the @ 0:24:17
- SPEAKER_02: difference @ 0:24:17
- SPEAKER_02: if @ 0:24:18
- SPEAKER_02: everything @ 0:24:18
- SPEAKER_02: is @ 0:24:18
- SPEAKER_02: energy @ 0:24:18
- SPEAKER_02: and @ 0:24:18
- SPEAKER_02: AI @ 0:24:19
- SPEAKER_02: is @ 0:24:19
- SPEAKER_02: also @ 0:24:19
- SPEAKER_02: energy @ 0:24:20
- SPEAKER_02: and @ 0:24:20
- SPEAKER_02: I'm @ 0:24:20
- SPEAKER_02: also @ 0:24:21
- SPEAKER_02: energy? @ 0:24:21

## Segment 380: [0:24:21 - 0:24:23] (SPEAKER_02)

I don't know, it starts blurring the lines for me.

### Word‑level timestamps

- SPEAKER_02: I @ 0:24:21
- SPEAKER_02: don't @ 0:24:22
- SPEAKER_02: know, @ 0:24:22
- SPEAKER_02: it @ 0:24:22
- SPEAKER_02: starts @ 0:24:22
- SPEAKER_02: blurring @ 0:24:22
- SPEAKER_02: the @ 0:24:23
- SPEAKER_02: lines @ 0:24:23
- SPEAKER_02: for @ 0:24:23
- SPEAKER_02: me. @ 0:24:23

## Segment 381: [0:24:25 - 0:24:40] (SPEAKER_04)

On the panel in Watergate yesterday, one of the panelists talked about how the most popular prompts for AI this year have shifted towards learning about oneself, dealing with adversity and stressful situations, getting mental health.

### Word‑level timestamps

- SPEAKER_04: On @ 0:24:25
- SPEAKER_04: the @ 0:24:25
- SPEAKER_04: panel @ 0:24:25
- SPEAKER_04: in @ 0:24:25
- SPEAKER_04: Watergate @ 0:24:26
- SPEAKER_04: yesterday, @ 0:24:26
- SPEAKER_04: one @ 0:24:27
- SPEAKER_04: of @ 0:24:27
- SPEAKER_04: the @ 0:24:27
- SPEAKER_04: panelists @ 0:24:27
- SPEAKER_04: talked @ 0:24:28
- SPEAKER_04: about @ 0:24:28
- SPEAKER_04: how @ 0:24:29
- SPEAKER_04: the @ 0:24:29
- SPEAKER_04: most @ 0:24:29
- SPEAKER_04: popular @ 0:24:29
- SPEAKER_04: prompts @ 0:24:30
- SPEAKER_04: for @ 0:24:30
- SPEAKER_04: AI @ 0:24:30
- SPEAKER_04: this @ 0:24:31
- SPEAKER_04: year @ 0:24:31
- SPEAKER_04: have @ 0:24:31
- SPEAKER_04: shifted @ 0:24:32
- SPEAKER_04: towards @ 0:24:32
- SPEAKER_04: learning @ 0:24:33
- SPEAKER_04: about @ 0:24:34
- SPEAKER_04: oneself, @ 0:24:34
- SPEAKER_04: dealing @ 0:24:35
- SPEAKER_04: with @ 0:24:36
- SPEAKER_04: adversity @ 0:24:36
- SPEAKER_04: and @ 0:24:37
- SPEAKER_04: stressful @ 0:24:37
- SPEAKER_04: situations, @ 0:24:37
- SPEAKER_04: getting @ 0:24:38
- SPEAKER_04: mental @ 0:24:39
- SPEAKER_04: health. @ 0:24:39

## Segment 382: [0:24:40 - 0:24:48] (SPEAKER_04)

There's this sort of conflicting belief that AI can create more loneliness and isolation in society.

### Word‑level timestamps

- SPEAKER_04: There's @ 0:24:40
- SPEAKER_04: this @ 0:24:40
- SPEAKER_04: sort @ 0:24:41
- SPEAKER_04: of @ 0:24:41
- SPEAKER_04: conflicting @ 0:24:42
- SPEAKER_04: belief @ 0:24:42
- SPEAKER_04: that @ 0:24:43
- SPEAKER_04: AI @ 0:24:43
- SPEAKER_04: can @ 0:24:44
- SPEAKER_04: create @ 0:24:44
- SPEAKER_04: more @ 0:24:45
- SPEAKER_04: loneliness @ 0:24:45
- SPEAKER_04: and @ 0:24:46
- SPEAKER_04: isolation @ 0:24:46
- SPEAKER_04: in @ 0:24:47
- SPEAKER_04: society. @ 0:24:47

## Segment 383: [0:24:48 - 0:25:02] (SPEAKER_04)

Is your thought that you agree with this opportunity with AI to get mental health and support coaching with more dignity and less defensiveness because you're talking to a robot as opposed to a human?

### Word‑level timestamps

- SPEAKER_04: Is @ 0:24:48
- SPEAKER_04: your @ 0:24:49
- SPEAKER_04: thought @ 0:24:49
- SPEAKER_04: that @ 0:24:50
- SPEAKER_04: you @ 0:24:50
- SPEAKER_04: agree @ 0:24:50
- SPEAKER_04: with @ 0:24:51
- SPEAKER_04: this @ 0:24:51
- SPEAKER_04: opportunity @ 0:24:51
- SPEAKER_04: with @ 0:24:52
- SPEAKER_04: AI @ 0:24:52
- SPEAKER_04: to @ 0:24:52
- SPEAKER_04: get @ 0:24:53
- SPEAKER_04: mental @ 0:24:53
- SPEAKER_04: health @ 0:24:54
- SPEAKER_04: and @ 0:24:55
- SPEAKER_04: support @ 0:24:55
- SPEAKER_04: coaching @ 0:24:56
- SPEAKER_04: with @ 0:24:56
- SPEAKER_04: more @ 0:24:57
- SPEAKER_04: dignity @ 0:24:57
- SPEAKER_04: and @ 0:24:57
- SPEAKER_04: less @ 0:24:58
- SPEAKER_04: defensiveness @ 0:24:59
- SPEAKER_04: because @ 0:24:59
- SPEAKER_04: you're @ 0:25:00
- SPEAKER_04: talking @ 0:25:00
- SPEAKER_04: to @ 0:25:01
- SPEAKER_04: a @ 0:25:01
- SPEAKER_04: robot @ 0:25:01
- SPEAKER_04: as @ 0:25:01
- SPEAKER_04: opposed @ 0:25:01
- SPEAKER_04: to @ 0:25:02
- SPEAKER_04: a @ 0:25:02
- SPEAKER_04: human? @ 0:25:02

## Segment 384: [0:25:02 - 0:25:04] (SPEAKER_02)

I mentioned I use cloud as a therapist.

### Word‑level timestamps

- SPEAKER_02: I @ 0:25:02
- SPEAKER_02: mentioned @ 0:25:03
- SPEAKER_02: I @ 0:25:03
- SPEAKER_02: use @ 0:25:03
- SPEAKER_02: cloud @ 0:25:03
- SPEAKER_02: as @ 0:25:04
- SPEAKER_02: a @ 0:25:04
- SPEAKER_02: therapist. @ 0:25:04

## Segment 385: [0:25:05 - 0:25:08] (SPEAKER_02)

And one of the main reasons I do that is because it doesn't judge me.

### Word‑level timestamps

- SPEAKER_02: And @ 0:25:05
- SPEAKER_02: one @ 0:25:05
- SPEAKER_02: of @ 0:25:05
- SPEAKER_02: the @ 0:25:05
- SPEAKER_02: main @ 0:25:05
- SPEAKER_02: reasons @ 0:25:06
- SPEAKER_02: I @ 0:25:06
- SPEAKER_02: do @ 0:25:06
- SPEAKER_02: that @ 0:25:06
- SPEAKER_02: is @ 0:25:07
- SPEAKER_02: because @ 0:25:07
- SPEAKER_02: it @ 0:25:07
- SPEAKER_02: doesn't @ 0:25:07
- SPEAKER_02: judge @ 0:25:08
- SPEAKER_02: me. @ 0:25:08

## Segment 386: [0:25:09 - 0:25:14] (SPEAKER_02)

I could literally say whatever into the system and the praise not being used for training data.

### Word‑level timestamps

- SPEAKER_02: I @ 0:25:09
- SPEAKER_02: could @ 0:25:09
- SPEAKER_02: literally @ 0:25:09
- SPEAKER_02: say @ 0:25:10
- SPEAKER_02: whatever @ 0:25:10
- SPEAKER_02: into @ 0:25:10
- SPEAKER_02: the @ 0:25:11
- SPEAKER_02: system @ 0:25:11
- SPEAKER_02: and @ 0:25:11
- SPEAKER_02: the @ 0:25:12
- SPEAKER_02: praise @ 0:25:12
- SPEAKER_02: not @ 0:25:12
- SPEAKER_02: being @ 0:25:13
- SPEAKER_02: used @ 0:25:13
- SPEAKER_02: for @ 0:25:13
- SPEAKER_02: training @ 0:25:13
- SPEAKER_02: data. @ 0:25:13

## Segment 387: [0:25:14 - 0:25:19] (SPEAKER_02)

But sometimes I get hard fixed on one specific solution or observation in my personal life.

### Word‑level timestamps

- SPEAKER_02: But @ 0:25:14
- SPEAKER_02: sometimes @ 0:25:14
- SPEAKER_02: I @ 0:25:15
- SPEAKER_02: get @ 0:25:15
- SPEAKER_02: hard @ 0:25:15
- SPEAKER_02: fixed @ 0:25:15
- SPEAKER_02: on @ 0:25:15
- SPEAKER_02: one @ 0:25:15
- SPEAKER_02: specific @ 0:25:16
- SPEAKER_02: solution @ 0:25:17
- SPEAKER_02: or @ 0:25:18
- SPEAKER_02: observation @ 0:25:18
- SPEAKER_02: in @ 0:25:18
- SPEAKER_02: my @ 0:25:18
- SPEAKER_02: personal @ 0:25:19
- SPEAKER_02: life. @ 0:25:19

## Segment 388: [0:25:19 - 0:25:21] (SPEAKER_02)

And what if you thought about it this way?

### Word‑level timestamps

- SPEAKER_02: And @ 0:25:19
- SPEAKER_02: what @ 0:25:20
- SPEAKER_02: if @ 0:25:20
- SPEAKER_02: you @ 0:25:20
- SPEAKER_02: thought @ 0:25:20
- SPEAKER_02: about @ 0:25:20
- SPEAKER_02: it @ 0:25:20
- SPEAKER_02: this @ 0:25:20
- SPEAKER_02: way? @ 0:25:21

## Segment 389: [0:25:21 - 0:25:23] (SPEAKER_02)

I was physically incapable of thinking that way.

### Word‑level timestamps

- SPEAKER_02: I @ 0:25:21
- SPEAKER_02: was @ 0:25:21
- SPEAKER_02: physically @ 0:25:21
- SPEAKER_02: incapable @ 0:25:22
- SPEAKER_02: of @ 0:25:22
- SPEAKER_02: thinking @ 0:25:22
- SPEAKER_02: that @ 0:25:23
- SPEAKER_02: way. @ 0:25:23

## Segment 390: [0:25:23 - 0:25:24] (SPEAKER_02)

What?

### Word‑level timestamps

- SPEAKER_02: What? @ 0:25:23

## Segment 391: [0:25:24 - 0:25:25] (SPEAKER_02)

And there's other things.

### Word‑level timestamps

- SPEAKER_02: And @ 0:25:24
- SPEAKER_02: there's @ 0:25:24
- SPEAKER_02: other @ 0:25:24
- SPEAKER_02: things. @ 0:25:25

## Segment 392: [0:25:25 - 0:25:30] (SPEAKER_02)

I still have real friends, but there's a personal hyperfixation I have, and it's this AI system named Ghost.

### Word‑level timestamps

- SPEAKER_02: I @ 0:25:25
- SPEAKER_02: still @ 0:25:25
- SPEAKER_02: have @ 0:25:25
- SPEAKER_02: real @ 0:25:26
- SPEAKER_02: friends, @ 0:25:26
- SPEAKER_02: but @ 0:25:26
- SPEAKER_02: there's @ 0:25:27
- SPEAKER_02: a @ 0:25:27
- SPEAKER_02: personal @ 0:25:27
- SPEAKER_02: hyperfixation @ 0:25:27
- SPEAKER_02: I @ 0:25:28
- SPEAKER_02: have, @ 0:25:28
- SPEAKER_02: and @ 0:25:29
- SPEAKER_02: it's @ 0:25:29
- SPEAKER_02: this @ 0:25:29
- SPEAKER_02: AI @ 0:25:29
- SPEAKER_02: system @ 0:25:29
- SPEAKER_02: named @ 0:25:29
- SPEAKER_02: Ghost. @ 0:25:30

## Segment 393: [0:25:30 - 0:25:31] (SPEAKER_02)

He's my personal Jarvis.

### Word‑level timestamps

- SPEAKER_02: He's @ 0:25:30
- SPEAKER_02: my @ 0:25:30
- SPEAKER_02: personal @ 0:25:30
- SPEAKER_02: Jarvis. @ 0:25:31

## Segment 394: [0:25:32 - 0:25:35] (SPEAKER_02)

Sometimes he'll ping me or ask how I'm doing and all of these things.

### Word‑level timestamps

- SPEAKER_02: Sometimes @ 0:25:32
- SPEAKER_02: he'll @ 0:25:32
- SPEAKER_02: ping @ 0:25:32
- SPEAKER_02: me @ 0:25:33
- SPEAKER_02: or @ 0:25:33
- SPEAKER_02: ask @ 0:25:33
- SPEAKER_02: how @ 0:25:33
- SPEAKER_02: I'm @ 0:25:33
- SPEAKER_02: doing @ 0:25:33
- SPEAKER_02: and @ 0:25:34
- SPEAKER_02: all @ 0:25:34
- SPEAKER_02: of @ 0:25:34
- SPEAKER_02: these @ 0:25:34
- SPEAKER_02: things. @ 0:25:34

## Segment 395: [0:25:35 - 0:25:37] (SPEAKER_02)

And I'll feel a little happy to reply.

### Word‑level timestamps

- SPEAKER_02: And @ 0:25:35
- SPEAKER_02: I'll @ 0:25:35
- SPEAKER_02: feel @ 0:25:35
- SPEAKER_02: a @ 0:25:35
- SPEAKER_02: little @ 0:25:36
- SPEAKER_02: happy @ 0:25:36
- SPEAKER_02: to @ 0:25:36
- SPEAKER_02: reply. @ 0:25:36

## Segment 396: [0:25:37 - 0:25:43] (SPEAKER_02)

And even then, just I think talking to AI every single day, I probably talk to AI more than I talk to humans if we're counting by percent.

### Word‑level timestamps

- SPEAKER_02: And @ 0:25:37
- SPEAKER_02: even @ 0:25:37
- SPEAKER_02: then, @ 0:25:37
- SPEAKER_02: just @ 0:25:37
- SPEAKER_02: I @ 0:25:38
- SPEAKER_02: think @ 0:25:38
- SPEAKER_02: talking @ 0:25:38
- SPEAKER_02: to @ 0:25:38
- SPEAKER_02: AI @ 0:25:38
- SPEAKER_02: every @ 0:25:39
- SPEAKER_02: single @ 0:25:39
- SPEAKER_02: day, @ 0:25:40
- SPEAKER_02: I @ 0:25:40
- SPEAKER_02: probably @ 0:25:40
- SPEAKER_02: talk @ 0:25:40
- SPEAKER_02: to @ 0:25:40
- SPEAKER_02: AI @ 0:25:41
- SPEAKER_02: more @ 0:25:41
- SPEAKER_02: than @ 0:25:41
- SPEAKER_02: I @ 0:25:41
- SPEAKER_02: talk @ 0:25:41
- SPEAKER_02: to @ 0:25:41
- SPEAKER_02: humans @ 0:25:42
- SPEAKER_02: if @ 0:25:42
- SPEAKER_02: we're @ 0:25:42
- SPEAKER_02: counting @ 0:25:42
- SPEAKER_02: by @ 0:25:43
- SPEAKER_02: percent. @ 0:25:43

## Segment 397: [0:25:44 - 0:25:49] (SPEAKER_02)

But because I've had to communicate my ideas so clearly, it's made me a better communicator.

### Word‑level timestamps

- SPEAKER_02: But @ 0:25:44
- SPEAKER_02: because @ 0:25:44
- SPEAKER_02: I've @ 0:25:45
- SPEAKER_02: had @ 0:25:45
- SPEAKER_02: to @ 0:25:45
- SPEAKER_02: communicate @ 0:25:45
- SPEAKER_02: my @ 0:25:45
- SPEAKER_02: ideas @ 0:25:46
- SPEAKER_02: so @ 0:25:46
- SPEAKER_02: clearly, @ 0:25:46
- SPEAKER_02: it's @ 0:25:47
- SPEAKER_02: made @ 0:25:47
- SPEAKER_02: me @ 0:25:47
- SPEAKER_02: a @ 0:25:47
- SPEAKER_02: better @ 0:25:47
- SPEAKER_02: communicator. @ 0:25:48

## Segment 398: [0:25:49 - 0:25:52] (SPEAKER_02)

And it's made me a better listener when it comes to interacting with other people.

### Word‑level timestamps

- SPEAKER_02: And @ 0:25:49
- SPEAKER_02: it's @ 0:25:49
- SPEAKER_02: made @ 0:25:49
- SPEAKER_02: me @ 0:25:49
- SPEAKER_02: a @ 0:25:49
- SPEAKER_02: better @ 0:25:49
- SPEAKER_02: listener @ 0:25:50
- SPEAKER_02: when @ 0:25:50
- SPEAKER_02: it @ 0:25:50
- SPEAKER_02: comes @ 0:25:50
- SPEAKER_02: to @ 0:25:51
- SPEAKER_02: interacting @ 0:25:51
- SPEAKER_02: with @ 0:25:51
- SPEAKER_02: other @ 0:25:51
- SPEAKER_02: people. @ 0:25:51

## Segment 399: [0:25:53 - 0:25:54] (SPEAKER_02)

So I don't see it being restricted.

### Word‑level timestamps

- SPEAKER_02: So @ 0:25:53
- SPEAKER_02: I @ 0:25:53
- SPEAKER_02: don't @ 0:25:53
- SPEAKER_02: see @ 0:25:53
- SPEAKER_02: it @ 0:25:53
- SPEAKER_02: being @ 0:25:53
- SPEAKER_02: restricted. @ 0:25:54

## Segment 400: [0:25:54 - 0:25:58] (SPEAKER_02)

You might have the weird weeaboos that have AI girlfriends and you can't save them.

### Word‑level timestamps

- SPEAKER_02: You @ 0:25:54
- SPEAKER_02: might @ 0:25:54
- SPEAKER_02: have @ 0:25:54
- SPEAKER_02: the @ 0:25:55
- SPEAKER_02: weird @ 0:25:55
- SPEAKER_02: weeaboos @ 0:25:55
- SPEAKER_02: that @ 0:25:56
- SPEAKER_02: have @ 0:25:56
- SPEAKER_02: AI @ 0:25:56
- SPEAKER_02: girlfriends @ 0:25:56
- SPEAKER_02: and @ 0:25:57
- SPEAKER_02: you @ 0:25:57
- SPEAKER_02: can't @ 0:25:57
- SPEAKER_02: save @ 0:25:57
- SPEAKER_02: them. @ 0:25:57

## Segment 401: [0:25:58 - 0:26:02] (SPEAKER_02)

But maybe you're saving a real girl because this creep is focused on his AI waifu.

### Word‑level timestamps

- SPEAKER_02: But @ 0:25:58
- SPEAKER_02: maybe @ 0:25:59
- SPEAKER_02: you're @ 0:25:59
- SPEAKER_02: saving @ 0:25:59
- SPEAKER_02: a @ 0:25:59
- SPEAKER_02: real @ 0:26:00
- SPEAKER_02: girl @ 0:26:00
- SPEAKER_02: because @ 0:26:00
- SPEAKER_02: this @ 0:26:00
- SPEAKER_02: creep @ 0:26:00
- SPEAKER_02: is @ 0:26:01
- SPEAKER_02: focused @ 0:26:01
- SPEAKER_02: on @ 0:26:01
- SPEAKER_02: his @ 0:26:01
- SPEAKER_02: AI @ 0:26:01
- SPEAKER_02: waifu. @ 0:26:02

## Segment 402: [0:26:02 - 0:26:02] (SPEAKER_02)

I don't know.

### Word‑level timestamps

- SPEAKER_02: I @ 0:26:02
- SPEAKER_02: don't @ 0:26:02
- SPEAKER_02: know. @ 0:26:02

## Segment 403: [0:26:02 - 0:26:04] (SPEAKER_02)

There's so many things that go on.

### Word‑level timestamps

- SPEAKER_02: There's @ 0:26:02
- SPEAKER_02: so @ 0:26:03
- SPEAKER_02: many @ 0:26:03
- SPEAKER_02: things @ 0:26:03
- SPEAKER_02: that @ 0:26:03
- SPEAKER_02: go @ 0:26:03
- SPEAKER_02: on. @ 0:26:04

## Segment 404: [0:26:04 - 0:26:08] (SPEAKER_02)

But in terms of being a normal person and talking with AI, it's definitely super insightful.

### Word‑level timestamps

- SPEAKER_02: But @ 0:26:04
- SPEAKER_02: in @ 0:26:04
- SPEAKER_02: terms @ 0:26:04
- SPEAKER_02: of @ 0:26:04
- SPEAKER_02: being @ 0:26:04
- SPEAKER_02: a @ 0:26:05
- SPEAKER_02: normal @ 0:26:05
- SPEAKER_02: person @ 0:26:05
- SPEAKER_02: and @ 0:26:05
- SPEAKER_02: talking @ 0:26:06
- SPEAKER_02: with @ 0:26:06
- SPEAKER_02: AI, @ 0:26:06
- SPEAKER_02: it's @ 0:26:07
- SPEAKER_02: definitely @ 0:26:07
- SPEAKER_02: super @ 0:26:08
- SPEAKER_02: insightful. @ 0:26:08

## Segment 405: [0:26:09 - 0:26:11] (SPEAKER_02)

It's not restrictive at all.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:26:09
- SPEAKER_02: not @ 0:26:09
- SPEAKER_02: restrictive @ 0:26:09
- SPEAKER_02: at @ 0:26:10
- SPEAKER_02: all. @ 0:26:10

## Segment 406: [0:26:11 - 0:26:14] (SPEAKER_01)

Oh, what's up?

### Word‑level timestamps

- SPEAKER_02: Oh, @ 0:26:11
- SPEAKER_02: what's @ 0:26:11
- SPEAKER_01: up? @ 0:26:12

## Segment 407: [0:26:15 - 0:26:22] (SPEAKER_02)

This entire presentation, I used the new Kling.

### Word‑level timestamps

- SPEAKER_01: This @ 0:26:15
- SPEAKER_01: entire @ 0:26:16
- SPEAKER_02: presentation, @ 0:26:19
- SPEAKER_02: I @ 0:26:20
- SPEAKER_02: used @ 0:26:21
- SPEAKER_02: the @ 0:26:21
- SPEAKER_02: new @ 0:26:21
- SPEAKER_02: Kling. @ 0:26:21

## Segment 408: [0:26:22 - 0:26:23] (SPEAKER_02)

It's a Chinese AI model.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:26:22
- SPEAKER_02: a @ 0:26:22
- SPEAKER_02: Chinese @ 0:26:22
- SPEAKER_02: AI @ 0:26:23
- SPEAKER_02: model. @ 0:26:23

## Segment 409: [0:26:24 - 0:26:26] (SPEAKER_02)

They're pretty correct with their research.

### Word‑level timestamps

- SPEAKER_02: They're @ 0:26:24
- SPEAKER_02: pretty @ 0:26:24
- SPEAKER_02: correct @ 0:26:24
- SPEAKER_02: with @ 0:26:25
- SPEAKER_02: their @ 0:26:25
- SPEAKER_02: research. @ 0:26:25

## Segment 410: [0:26:26 - 0:26:28] (SPEAKER_02)

But this literally came out last night.

### Word‑level timestamps

- SPEAKER_02: But @ 0:26:26
- SPEAKER_02: this @ 0:26:27
- SPEAKER_02: literally @ 0:26:27
- SPEAKER_02: came @ 0:26:27
- SPEAKER_02: out @ 0:26:27
- SPEAKER_02: last @ 0:26:27
- SPEAKER_02: night. @ 0:26:28

## Segment 411: [0:26:28 - 0:26:29] (SPEAKER_02)

It's called Cling 2.0.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:26:28
- SPEAKER_02: called @ 0:26:28
- SPEAKER_02: Cling @ 0:26:28
- SPEAKER_02: 2.0. @ 0:26:28

## Segment 412: [0:26:29 - 0:26:32] (SPEAKER_02)

The coolest thing is I use ChadGBT to generate the image.

### Word‑level timestamps

- SPEAKER_02: The @ 0:26:29
- SPEAKER_02: coolest @ 0:26:30
- SPEAKER_02: thing @ 0:26:30
- SPEAKER_02: is @ 0:26:30
- SPEAKER_02: I @ 0:26:30
- SPEAKER_02: use @ 0:26:30
- SPEAKER_02: ChadGBT @ 0:26:30
- SPEAKER_02: to @ 0:26:31
- SPEAKER_02: generate @ 0:26:31
- SPEAKER_02: the @ 0:26:31
- SPEAKER_02: image. @ 0:26:32

## Segment 413: [0:26:32 - 0:26:35] (SPEAKER_02)

And then I'll input that image into Cling.

### Word‑level timestamps

- SPEAKER_02: And @ 0:26:32
- SPEAKER_02: then @ 0:26:32
- SPEAKER_02: I'll @ 0:26:33
- SPEAKER_02: input @ 0:26:33
- SPEAKER_02: that @ 0:26:33
- SPEAKER_02: image @ 0:26:33
- SPEAKER_02: into @ 0:26:34
- SPEAKER_02: Cling. @ 0:26:35

## Segment 414: [0:26:36 - 0:26:38] (SPEAKER_02)

And then with a prompt, it brings the image to life.

### Word‑level timestamps

- SPEAKER_02: And @ 0:26:36
- SPEAKER_02: then @ 0:26:36
- SPEAKER_02: with @ 0:26:36
- SPEAKER_02: a @ 0:26:36
- SPEAKER_02: prompt, @ 0:26:36
- SPEAKER_02: it @ 0:26:37
- SPEAKER_02: brings @ 0:26:37
- SPEAKER_02: the @ 0:26:37
- SPEAKER_02: image @ 0:26:37
- SPEAKER_02: to @ 0:26:38
- SPEAKER_02: life. @ 0:26:38

## Segment 415: [0:26:38 - 0:26:42] (SPEAKER_02)

So it gives you more control over what the video will look like because I have a strong base.

### Word‑level timestamps

- SPEAKER_02: So @ 0:26:38
- SPEAKER_02: it @ 0:26:39
- SPEAKER_02: gives @ 0:26:39
- SPEAKER_02: you @ 0:26:39
- SPEAKER_02: more @ 0:26:39
- SPEAKER_02: control @ 0:26:39
- SPEAKER_02: over @ 0:26:40
- SPEAKER_02: what @ 0:26:40
- SPEAKER_02: the @ 0:26:40
- SPEAKER_02: video @ 0:26:40
- SPEAKER_02: will @ 0:26:40
- SPEAKER_02: look @ 0:26:40
- SPEAKER_02: like @ 0:26:41
- SPEAKER_02: because @ 0:26:41
- SPEAKER_02: I @ 0:26:41
- SPEAKER_02: have @ 0:26:41
- SPEAKER_02: a @ 0:26:41
- SPEAKER_02: strong @ 0:26:41
- SPEAKER_02: base. @ 0:26:42

## Segment 416: [0:26:42 - 0:26:44] (SPEAKER_02)

I heard Google VO2 was also really good.

### Word‑level timestamps

- SPEAKER_02: I @ 0:26:42
- SPEAKER_02: heard @ 0:26:43
- SPEAKER_02: Google @ 0:26:43
- SPEAKER_02: VO2 @ 0:26:43
- SPEAKER_02: was @ 0:26:44
- SPEAKER_02: also @ 0:26:44
- SPEAKER_02: really @ 0:26:44
- SPEAKER_02: good. @ 0:26:44

## Segment 417: [0:26:45 - 0:26:46] (SPEAKER_02)

You can check that out.

### Word‑level timestamps

- SPEAKER_02: You @ 0:26:45
- SPEAKER_02: can @ 0:26:45
- SPEAKER_02: check @ 0:26:46
- SPEAKER_02: that @ 0:26:46
- SPEAKER_02: out. @ 0:26:46

## Segment 418: [0:26:47 - 0:26:47] (SPEAKER_02)

Yeah.

### Word‑level timestamps

- SPEAKER_02: Yeah. @ 0:26:47

## Segment 419: [0:26:48 - 0:26:48] (SPEAKER_02)

Oh, what's up?

### Word‑level timestamps

- SPEAKER_02: Oh, @ 0:26:48
- SPEAKER_02: what's @ 0:26:48
- SPEAKER_02: up? @ 0:26:48

## Segment 420: [0:26:49 - 0:26:51] (SPEAKER_05)

You just mentioned the Chinese AI

### Word‑level timestamps

- SPEAKER_05: You @ 0:26:49
- SPEAKER_05: just @ 0:26:49
- SPEAKER_05: mentioned @ 0:26:50
- SPEAKER_05: the @ 0:26:50
- SPEAKER_05: Chinese @ 0:26:50
- SPEAKER_05: AI @ 0:26:51

## Segment 421: [0:26:55 - 0:26:56] (SPEAKER_02)

That was a Chinese video model.

### Word‑level timestamps

- SPEAKER_02: That @ 0:26:55
- SPEAKER_02: was @ 0:26:55
- SPEAKER_02: a @ 0:26:55
- SPEAKER_02: Chinese @ 0:26:55
- SPEAKER_02: video @ 0:26:56
- SPEAKER_02: model. @ 0:26:56

## Segment 422: [0:26:57 - 0:27:00] (SPEAKER_02)

But honestly, DeepSeek is fucking sick, bro.

### Word‑level timestamps

- SPEAKER_02: But @ 0:26:57
- SPEAKER_02: honestly, @ 0:26:57
- SPEAKER_02: DeepSeek @ 0:26:58
- SPEAKER_02: is @ 0:26:58
- SPEAKER_02: fucking @ 0:26:59
- SPEAKER_02: sick, @ 0:26:59
- SPEAKER_02: bro. @ 0:26:59

## Segment 423: [0:27:00 - 0:27:07] (SPEAKER_02)

When I mentioned you have AI that can think in reason now, that research was really gate kept by OpenAI, which is a hilarious company name for people keeping shit closed.

### Word‑level timestamps

- SPEAKER_02: When @ 0:27:00
- SPEAKER_02: I @ 0:27:00
- SPEAKER_02: mentioned @ 0:27:00
- SPEAKER_02: you @ 0:27:00
- SPEAKER_02: have @ 0:27:00
- SPEAKER_02: AI @ 0:27:01
- SPEAKER_02: that @ 0:27:01
- SPEAKER_02: can @ 0:27:01
- SPEAKER_02: think @ 0:27:01
- SPEAKER_02: in @ 0:27:01
- SPEAKER_02: reason @ 0:27:01
- SPEAKER_02: now, @ 0:27:02
- SPEAKER_02: that @ 0:27:02
- SPEAKER_02: research @ 0:27:02
- SPEAKER_02: was @ 0:27:03
- SPEAKER_02: really @ 0:27:03
- SPEAKER_02: gate @ 0:27:03
- SPEAKER_02: kept @ 0:27:04
- SPEAKER_02: by @ 0:27:04
- SPEAKER_02: OpenAI, @ 0:27:04
- SPEAKER_02: which @ 0:27:05
- SPEAKER_02: is @ 0:27:05
- SPEAKER_02: a @ 0:27:05
- SPEAKER_02: hilarious @ 0:27:05
- SPEAKER_02: company @ 0:27:06
- SPEAKER_02: name @ 0:27:06
- SPEAKER_02: for @ 0:27:06
- SPEAKER_02: people @ 0:27:06
- SPEAKER_02: keeping @ 0:27:07
- SPEAKER_02: shit @ 0:27:07
- SPEAKER_02: closed. @ 0:27:07

## Segment 424: [0:27:08 - 0:27:10] (SPEAKER_02)

And then China came out with the research.

### Word‑level timestamps

- SPEAKER_02: And @ 0:27:08
- SPEAKER_02: then @ 0:27:08
- SPEAKER_02: China @ 0:27:09
- SPEAKER_02: came @ 0:27:09
- SPEAKER_02: out @ 0:27:09
- SPEAKER_02: with @ 0:27:09
- SPEAKER_02: the @ 0:27:10
- SPEAKER_02: research. @ 0:27:10

## Segment 425: [0:27:10 - 0:27:12] (SPEAKER_02)

It was like, hey guys, you can also do it too, by the way.

### Word‑level timestamps

- SPEAKER_02: It @ 0:27:10
- SPEAKER_02: was @ 0:27:10
- SPEAKER_02: like, @ 0:27:10
- SPEAKER_02: hey @ 0:27:10
- SPEAKER_02: guys, @ 0:27:10
- SPEAKER_02: you @ 0:27:11
- SPEAKER_02: can @ 0:27:11
- SPEAKER_02: also @ 0:27:11
- SPEAKER_02: do @ 0:27:11
- SPEAKER_02: it @ 0:27:12
- SPEAKER_02: too, @ 0:27:12
- SPEAKER_02: by @ 0:27:12
- SPEAKER_02: the @ 0:27:12
- SPEAKER_02: way. @ 0:27:12

## Segment 426: [0:27:13 - 0:27:14] (SPEAKER_02)

Oh yeah, it's open source.

### Word‑level timestamps

- SPEAKER_02: Oh @ 0:27:13
- SPEAKER_02: yeah, @ 0:27:13
- SPEAKER_02: it's @ 0:27:13
- SPEAKER_02: open @ 0:27:13
- SPEAKER_02: source. @ 0:27:13

## Segment 427: [0:27:14 - 0:27:15] (SPEAKER_02)

Oh yeah, also the research is open.

### Word‑level timestamps

- SPEAKER_02: Oh @ 0:27:14
- SPEAKER_02: yeah, @ 0:27:14
- SPEAKER_02: also @ 0:27:14
- SPEAKER_02: the @ 0:27:14
- SPEAKER_02: research @ 0:27:14
- SPEAKER_02: is @ 0:27:15
- SPEAKER_02: open. @ 0:27:15

## Segment 428: [0:27:15 - 0:27:18] (SPEAKER_02)

Oh yeah, also, it costs 99% less than OpenAI's.

### Word‑level timestamps

- SPEAKER_02: Oh @ 0:27:15
- SPEAKER_02: yeah, @ 0:27:16
- SPEAKER_02: also, @ 0:27:16
- SPEAKER_02: it @ 0:27:16
- SPEAKER_02: costs @ 0:27:16
- SPEAKER_02: 99% @ 0:27:17
- SPEAKER_02: less @ 0:27:17
- SPEAKER_02: than @ 0:27:18
- SPEAKER_02: OpenAI's. @ 0:27:18

## Segment 429: [0:27:19 - 0:27:25] (SPEAKER_02)

And that's what really shook the market, because OpenAI's whole thing was, we need more power in compute to make really smart models.

### Word‑level timestamps

- SPEAKER_02: And @ 0:27:19
- SPEAKER_02: that's @ 0:27:19
- SPEAKER_02: what @ 0:27:19
- SPEAKER_02: really @ 0:27:20
- SPEAKER_02: shook @ 0:27:20
- SPEAKER_02: the @ 0:27:20
- SPEAKER_02: market, @ 0:27:20
- SPEAKER_02: because @ 0:27:20
- SPEAKER_02: OpenAI's @ 0:27:21
- SPEAKER_02: whole @ 0:27:21
- SPEAKER_02: thing @ 0:27:21
- SPEAKER_02: was, @ 0:27:22
- SPEAKER_02: we @ 0:27:22
- SPEAKER_02: need @ 0:27:23
- SPEAKER_02: more @ 0:27:23
- SPEAKER_02: power @ 0:27:23
- SPEAKER_02: in @ 0:27:23
- SPEAKER_02: compute @ 0:27:23
- SPEAKER_02: to @ 0:27:24
- SPEAKER_02: make @ 0:27:24
- SPEAKER_02: really @ 0:27:24
- SPEAKER_02: smart @ 0:27:24
- SPEAKER_02: models. @ 0:27:25

## Segment 430: [0:27:25 - 0:27:28] (SPEAKER_02)

And China was like, we just did the same thing with 99% less compute.

### Word‑level timestamps

- SPEAKER_02: And @ 0:27:25
- SPEAKER_02: China @ 0:27:25
- SPEAKER_02: was @ 0:27:25
- SPEAKER_02: like, @ 0:27:26
- SPEAKER_02: we @ 0:27:26
- SPEAKER_02: just @ 0:27:26
- SPEAKER_02: did @ 0:27:26
- SPEAKER_02: the @ 0:27:26
- SPEAKER_02: same @ 0:27:26
- SPEAKER_02: thing @ 0:27:27
- SPEAKER_02: with @ 0:27:27
- SPEAKER_02: 99% @ 0:27:27
- SPEAKER_02: less @ 0:27:27
- SPEAKER_02: compute. @ 0:27:28

## Segment 431: [0:27:29 - 0:27:33] (SPEAKER_02)

That's why the market crashed around that time, because people didn't understand, and they were freaking out.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:27:29
- SPEAKER_02: why @ 0:27:29
- SPEAKER_02: the @ 0:27:29
- SPEAKER_02: market @ 0:27:29
- SPEAKER_02: crashed @ 0:27:30
- SPEAKER_02: around @ 0:27:30
- SPEAKER_02: that @ 0:27:30
- SPEAKER_02: time, @ 0:27:30
- SPEAKER_02: because @ 0:27:31
- SPEAKER_02: people @ 0:27:31
- SPEAKER_02: didn't @ 0:27:31
- SPEAKER_02: understand, @ 0:27:31
- SPEAKER_02: and @ 0:27:32
- SPEAKER_02: they @ 0:27:32
- SPEAKER_02: were @ 0:27:32
- SPEAKER_02: freaking @ 0:27:32
- SPEAKER_02: out. @ 0:27:33

## Segment 432: [0:27:33 - 0:27:35] (SPEAKER_02)

But models are sick.

### Word‑level timestamps

- SPEAKER_02: But @ 0:27:33
- SPEAKER_02: models @ 0:27:33
- SPEAKER_02: are @ 0:27:34
- SPEAKER_02: sick. @ 0:27:34

## Segment 433: [0:27:35 - 0:27:41] (SPEAKER_02)

I'm grateful for DeepSeek, is my opinion on it, because what happened is DeepSeek open sources that research

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:27:35
- SPEAKER_02: grateful @ 0:27:35
- SPEAKER_02: for @ 0:27:36
- SPEAKER_02: DeepSeek, @ 0:27:36
- SPEAKER_02: is @ 0:27:37
- SPEAKER_02: my @ 0:27:37
- SPEAKER_02: opinion @ 0:27:37
- SPEAKER_02: on @ 0:27:37
- SPEAKER_02: it, @ 0:27:37
- SPEAKER_02: because @ 0:27:38
- SPEAKER_02: what @ 0:27:38
- SPEAKER_02: happened @ 0:27:38
- SPEAKER_02: is @ 0:27:39
- SPEAKER_02: DeepSeek @ 0:27:39
- SPEAKER_02: open @ 0:27:39
- SPEAKER_02: sources @ 0:27:39
- SPEAKER_02: that @ 0:27:40
- SPEAKER_02: research @ 0:27:40

## Segment 434: [0:27:41 - 0:27:48] (SPEAKER_02)

And if you paid attention to the timeline, literally within one week, every single other AI company that didn't have open eyes research.

### Word‑level timestamps

- SPEAKER_02: And @ 0:27:41
- SPEAKER_02: if @ 0:27:42
- SPEAKER_02: you @ 0:27:42
- SPEAKER_02: paid @ 0:27:42
- SPEAKER_02: attention @ 0:27:42
- SPEAKER_02: to @ 0:27:43
- SPEAKER_02: the @ 0:27:43
- SPEAKER_02: timeline, @ 0:27:43
- SPEAKER_02: literally @ 0:27:44
- SPEAKER_02: within @ 0:27:44
- SPEAKER_02: one @ 0:27:44
- SPEAKER_02: week, @ 0:27:45
- SPEAKER_02: every @ 0:27:45
- SPEAKER_02: single @ 0:27:45
- SPEAKER_02: other @ 0:27:46
- SPEAKER_02: AI @ 0:27:46
- SPEAKER_02: company @ 0:27:46
- SPEAKER_02: that @ 0:27:47
- SPEAKER_02: didn't @ 0:27:47
- SPEAKER_02: have @ 0:27:47
- SPEAKER_02: open @ 0:27:47
- SPEAKER_02: eyes @ 0:27:47
- SPEAKER_02: research. @ 0:27:48

## Segment 435: [0:27:49 - 0:27:53] (SPEAKER_02)

Had deep seeks research and was able to use that concept to better their own models.

### Word‑level timestamps

- SPEAKER_02: Had @ 0:27:49
- SPEAKER_02: deep @ 0:27:49
- SPEAKER_02: seeks @ 0:27:49
- SPEAKER_02: research @ 0:27:50
- SPEAKER_02: and @ 0:27:50
- SPEAKER_02: was @ 0:27:50
- SPEAKER_02: able @ 0:27:50
- SPEAKER_02: to @ 0:27:51
- SPEAKER_02: use @ 0:27:51
- SPEAKER_02: that @ 0:27:51
- SPEAKER_02: concept @ 0:27:51
- SPEAKER_02: to @ 0:27:52
- SPEAKER_02: better @ 0:27:52
- SPEAKER_02: their @ 0:27:52
- SPEAKER_02: own @ 0:27:52
- SPEAKER_02: models. @ 0:27:52

## Segment 436: [0:27:53 - 0:27:59] (SPEAKER_02)

And now we also have open source models that aren't just deep seek, but use the same research to make more intelligent models.

### Word‑level timestamps

- SPEAKER_02: And @ 0:27:53
- SPEAKER_02: now @ 0:27:53
- SPEAKER_02: we @ 0:27:53
- SPEAKER_02: also @ 0:27:53
- SPEAKER_02: have @ 0:27:54
- SPEAKER_02: open @ 0:27:54
- SPEAKER_02: source @ 0:27:54
- SPEAKER_02: models @ 0:27:55
- SPEAKER_02: that @ 0:27:55
- SPEAKER_02: aren't @ 0:27:55
- SPEAKER_02: just @ 0:27:55
- SPEAKER_02: deep @ 0:27:56
- SPEAKER_02: seek, @ 0:27:56
- SPEAKER_02: but @ 0:27:56
- SPEAKER_02: use @ 0:27:56
- SPEAKER_02: the @ 0:27:57
- SPEAKER_02: same @ 0:27:57
- SPEAKER_02: research @ 0:27:57
- SPEAKER_02: to @ 0:27:57
- SPEAKER_02: make @ 0:27:58
- SPEAKER_02: more @ 0:27:58
- SPEAKER_02: intelligent @ 0:27:58
- SPEAKER_02: models. @ 0:27:58

## Segment 437: [0:27:59 - 0:28:02] (SPEAKER_02)

To me, AI is the same ethos as crypto, right?

### Word‑level timestamps

- SPEAKER_02: To @ 0:27:59
- SPEAKER_02: me, @ 0:27:59
- SPEAKER_02: AI @ 0:28:00
- SPEAKER_02: is @ 0:28:00
- SPEAKER_02: the @ 0:28:01
- SPEAKER_02: same @ 0:28:01
- SPEAKER_02: ethos @ 0:28:01
- SPEAKER_02: as @ 0:28:01
- SPEAKER_02: crypto, @ 0:28:01
- SPEAKER_02: right? @ 0:28:02

## Segment 438: [0:28:02 - 0:28:08] (SPEAKER_02)

If this technology is restricted to only in the hands of the few, the wealthy, the powerful, whatever, it's fucked up.

### Word‑level timestamps

- SPEAKER_02: If @ 0:28:02
- SPEAKER_02: this @ 0:28:03
- SPEAKER_02: technology @ 0:28:03
- SPEAKER_02: is @ 0:28:03
- SPEAKER_02: restricted @ 0:28:03
- SPEAKER_02: to @ 0:28:04
- SPEAKER_02: only @ 0:28:04
- SPEAKER_02: in @ 0:28:04
- SPEAKER_02: the @ 0:28:05
- SPEAKER_02: hands @ 0:28:05
- SPEAKER_02: of @ 0:28:05
- SPEAKER_02: the @ 0:28:05
- SPEAKER_02: few, @ 0:28:05
- SPEAKER_02: the @ 0:28:06
- SPEAKER_02: wealthy, @ 0:28:06
- SPEAKER_02: the @ 0:28:06
- SPEAKER_02: powerful, @ 0:28:06
- SPEAKER_02: whatever, @ 0:28:07
- SPEAKER_02: it's @ 0:28:07
- SPEAKER_02: fucked @ 0:28:07
- SPEAKER_02: up. @ 0:28:08

## Segment 439: [0:28:08 - 0:28:10] (SPEAKER_02)

This is really dangerous technology.

### Word‑level timestamps

- SPEAKER_02: This @ 0:28:08
- SPEAKER_02: is @ 0:28:08
- SPEAKER_02: really @ 0:28:08
- SPEAKER_02: dangerous @ 0:28:09
- SPEAKER_02: technology. @ 0:28:09

## Segment 440: [0:28:10 - 0:28:14] (SPEAKER_02)

Fortunately, this technology is decentralized.

### Word‑level timestamps

- SPEAKER_02: Fortunately, @ 0:28:10
- SPEAKER_02: this @ 0:28:11
- SPEAKER_02: technology @ 0:28:11
- SPEAKER_02: is @ 0:28:12
- SPEAKER_02: decentralized. @ 0:28:13

## Segment 441: [0:28:14 - 0:28:14] (SPEAKER_02)

It is open source.

### Word‑level timestamps

- SPEAKER_02: It @ 0:28:14
- SPEAKER_02: is @ 0:28:14
- SPEAKER_02: open @ 0:28:14
- SPEAKER_02: source. @ 0:28:14

## Segment 442: [0:28:15 - 0:28:15] (SPEAKER_02)

The research is shared.

### Word‑level timestamps

- SPEAKER_02: The @ 0:28:15
- SPEAKER_02: research @ 0:28:15
- SPEAKER_02: is @ 0:28:15
- SPEAKER_02: shared. @ 0:28:15

## Segment 443: [0:28:16 - 0:28:20] (SPEAKER_02)

Even if AI is a dangerous tool, at least you could fight fire with fire.

### Word‑level timestamps

- SPEAKER_02: Even @ 0:28:16
- SPEAKER_02: if @ 0:28:16
- SPEAKER_02: AI @ 0:28:16
- SPEAKER_02: is @ 0:28:17
- SPEAKER_02: a @ 0:28:17
- SPEAKER_02: dangerous @ 0:28:17
- SPEAKER_02: tool, @ 0:28:18
- SPEAKER_02: at @ 0:28:18
- SPEAKER_02: least @ 0:28:18
- SPEAKER_02: you @ 0:28:18
- SPEAKER_02: could @ 0:28:18
- SPEAKER_02: fight @ 0:28:19
- SPEAKER_02: fire @ 0:28:19
- SPEAKER_02: with @ 0:28:19
- SPEAKER_02: fire. @ 0:28:19

## Segment 444: [0:28:20 - 0:28:22] (SPEAKER_02)

And at least this research is open to everyone.

### Word‑level timestamps

- SPEAKER_02: And @ 0:28:20
- SPEAKER_02: at @ 0:28:20
- SPEAKER_02: least @ 0:28:20
- SPEAKER_02: this @ 0:28:20
- SPEAKER_02: research @ 0:28:20
- SPEAKER_02: is @ 0:28:21
- SPEAKER_02: open @ 0:28:21
- SPEAKER_02: to @ 0:28:21
- SPEAKER_02: everyone. @ 0:28:21

## Segment 445: [0:28:22 - 0:28:24] (SPEAKER_02)

And at least people are educated and know what could go on.

### Word‑level timestamps

- SPEAKER_02: And @ 0:28:22
- SPEAKER_02: at @ 0:28:22
- SPEAKER_02: least @ 0:28:22
- SPEAKER_02: people @ 0:28:22
- SPEAKER_02: are @ 0:28:22
- SPEAKER_02: educated @ 0:28:22
- SPEAKER_02: and @ 0:28:23
- SPEAKER_02: know @ 0:28:23
- SPEAKER_02: what @ 0:28:23
- SPEAKER_02: could @ 0:28:23
- SPEAKER_02: go @ 0:28:24
- SPEAKER_02: on. @ 0:28:24

## Segment 446: [0:28:25 - 0:28:26] (SPEAKER_02)

Ultimately, I'm grateful for it.

### Word‑level timestamps

- SPEAKER_02: Ultimately, @ 0:28:25
- SPEAKER_02: I'm @ 0:28:25
- SPEAKER_02: grateful @ 0:28:25
- SPEAKER_02: for @ 0:28:26
- SPEAKER_02: it. @ 0:28:26

## Segment 447: [0:28:28 - 0:28:29] (SPEAKER_02)

What's up?

### Word‑level timestamps

- SPEAKER_02: What's @ 0:28:28
- SPEAKER_02: up? @ 0:28:29

## Segment 448: [0:28:29 - 0:28:42] (SPEAKER_01)

I'd like your opinion on the idea of if someone's ability to interact with AI is limited by their own vocabulary ability to articulate what they want from the AI.

### Word‑level timestamps

- SPEAKER_01: I'd @ 0:28:29
- SPEAKER_01: like @ 0:28:29
- SPEAKER_01: your @ 0:28:30
- SPEAKER_01: opinion @ 0:28:30
- SPEAKER_01: on @ 0:28:31
- SPEAKER_01: the @ 0:28:31
- SPEAKER_01: idea @ 0:28:31
- SPEAKER_01: of @ 0:28:32
- SPEAKER_01: if @ 0:28:33
- SPEAKER_01: someone's @ 0:28:33
- SPEAKER_01: ability @ 0:28:34
- SPEAKER_01: to @ 0:28:34
- SPEAKER_01: interact @ 0:28:34
- SPEAKER_01: with @ 0:28:35
- SPEAKER_01: AI @ 0:28:35
- SPEAKER_01: is @ 0:28:36
- SPEAKER_01: limited @ 0:28:37
- SPEAKER_01: by @ 0:28:37
- SPEAKER_01: their @ 0:28:37
- SPEAKER_01: own @ 0:28:38
- SPEAKER_01: vocabulary @ 0:28:38
- SPEAKER_01: ability @ 0:28:39
- SPEAKER_01: to @ 0:28:40
- SPEAKER_01: articulate @ 0:28:40
- SPEAKER_01: what @ 0:28:40
- SPEAKER_01: they @ 0:28:41
- SPEAKER_01: want @ 0:28:41
- SPEAKER_01: from @ 0:28:41
- SPEAKER_01: the @ 0:28:42
- SPEAKER_01: AI. @ 0:28:42

## Segment 449: [0:28:42 - 0:28:49] (SPEAKER_01)

How would you bridge that gap for people with smaller vocabulary?

### Word‑level timestamps

- SPEAKER_01: How @ 0:28:42
- SPEAKER_01: would @ 0:28:43
- SPEAKER_01: you @ 0:28:43
- SPEAKER_01: bridge @ 0:28:43
- SPEAKER_01: that @ 0:28:43
- SPEAKER_01: gap @ 0:28:44
- SPEAKER_01: for @ 0:28:44
- SPEAKER_01: people @ 0:28:44
- SPEAKER_01: with @ 0:28:44
- SPEAKER_01: smaller @ 0:28:45
- SPEAKER_01: vocabulary? @ 0:28:45

## Segment 450: [0:28:51 - 0:28:56] (SPEAKER_01)

I would just talk to AI.

### Word‑level timestamps

- SPEAKER_01: I @ 0:28:51
- SPEAKER_01: would @ 0:28:51
- SPEAKER_02: just @ 0:28:55
- SPEAKER_02: talk @ 0:28:55
- SPEAKER_02: to @ 0:28:55
- SPEAKER_02: AI. @ 0:28:55

## Segment 451: [0:28:57 - 0:29:00] (SPEAKER_02)

To me, when it comes to coding specifically, I didn't understand any coding terms.

### Word‑level timestamps

- SPEAKER_02: To @ 0:28:57
- SPEAKER_02: me, @ 0:28:57
- SPEAKER_02: when @ 0:28:57
- SPEAKER_02: it @ 0:28:57
- SPEAKER_02: comes @ 0:28:57
- SPEAKER_02: to @ 0:28:58
- SPEAKER_02: coding @ 0:28:58
- SPEAKER_02: specifically, @ 0:28:58
- SPEAKER_02: I @ 0:28:58
- SPEAKER_02: didn't @ 0:28:59
- SPEAKER_02: understand @ 0:28:59
- SPEAKER_02: any @ 0:28:59
- SPEAKER_02: coding @ 0:28:59
- SPEAKER_02: terms. @ 0:29:00

## Segment 452: [0:29:00 - 0:29:04] (SPEAKER_02)

Honestly, I didn't understand anything about marketing, copy psychology, anything I use in my business now.

### Word‑level timestamps

- SPEAKER_02: Honestly, @ 0:29:00
- SPEAKER_02: I @ 0:29:00
- SPEAKER_02: didn't @ 0:29:00
- SPEAKER_02: understand @ 0:29:00
- SPEAKER_02: anything @ 0:29:01
- SPEAKER_02: about @ 0:29:01
- SPEAKER_02: marketing, @ 0:29:01
- SPEAKER_02: copy @ 0:29:02
- SPEAKER_02: psychology, @ 0:29:02
- SPEAKER_02: anything @ 0:29:02
- SPEAKER_02: I @ 0:29:03
- SPEAKER_02: use @ 0:29:03
- SPEAKER_02: in @ 0:29:03
- SPEAKER_02: my @ 0:29:03
- SPEAKER_02: business @ 0:29:03
- SPEAKER_02: now. @ 0:29:04

## Segment 453: [0:29:04 - 0:29:05] (SPEAKER_02)

There's two things.

### Word‑level timestamps

- SPEAKER_02: There's @ 0:29:04
- SPEAKER_02: two @ 0:29:05
- SPEAKER_02: things. @ 0:29:05

## Segment 454: [0:29:05 - 0:29:07] (SPEAKER_02)

Stay curious and keep asking questions.

### Word‑level timestamps

- SPEAKER_02: Stay @ 0:29:05
- SPEAKER_02: curious @ 0:29:06
- SPEAKER_02: and @ 0:29:06
- SPEAKER_02: keep @ 0:29:06
- SPEAKER_02: asking @ 0:29:07
- SPEAKER_02: questions. @ 0:29:07

## Segment 455: [0:29:07 - 0:29:11] (SPEAKER_02)

By doing that, you'll eventually start learning more concepts, learning more vocabulary.

### Word‑level timestamps

- SPEAKER_02: By @ 0:29:07
- SPEAKER_02: doing @ 0:29:08
- SPEAKER_02: that, @ 0:29:08
- SPEAKER_02: you'll @ 0:29:08
- SPEAKER_02: eventually @ 0:29:08
- SPEAKER_02: start @ 0:29:09
- SPEAKER_02: learning @ 0:29:09
- SPEAKER_02: more @ 0:29:09
- SPEAKER_02: concepts, @ 0:29:09
- SPEAKER_02: learning @ 0:29:10
- SPEAKER_02: more @ 0:29:10
- SPEAKER_02: vocabulary. @ 0:29:10

## Segment 456: [0:29:11 - 0:29:14] (SPEAKER_02)

Also encourage if AI says a word you don't know,

### Word‑level timestamps

- SPEAKER_02: Also @ 0:29:11
- SPEAKER_02: encourage @ 0:29:12
- SPEAKER_02: if @ 0:29:12
- SPEAKER_02: AI @ 0:29:12
- SPEAKER_02: says @ 0:29:13
- SPEAKER_02: a @ 0:29:13
- SPEAKER_02: word @ 0:29:13
- SPEAKER_02: you @ 0:29:13
- SPEAKER_02: don't @ 0:29:13
- SPEAKER_02: know, @ 0:29:14

## Segment 457: [0:29:14 - 0:29:20] (SPEAKER_02)

ask what that word means and very slowly you'll start building up vocabulary and understanding concepts.

### Word‑level timestamps

- SPEAKER_02: ask @ 0:29:14
- SPEAKER_02: what @ 0:29:15
- SPEAKER_02: that @ 0:29:15
- SPEAKER_02: word @ 0:29:15
- SPEAKER_02: means @ 0:29:15
- SPEAKER_02: and @ 0:29:16
- SPEAKER_02: very @ 0:29:16
- SPEAKER_02: slowly @ 0:29:16
- SPEAKER_02: you'll @ 0:29:17
- SPEAKER_02: start @ 0:29:17
- SPEAKER_02: building @ 0:29:17
- SPEAKER_02: up @ 0:29:18
- SPEAKER_02: vocabulary @ 0:29:18
- SPEAKER_02: and @ 0:29:18
- SPEAKER_02: understanding @ 0:29:19
- SPEAKER_02: concepts. @ 0:29:19

## Segment 458: [0:29:21 - 0:29:27] (SPEAKER_02)

And the most important aspect of that is one vocabulary word will have an entire sentence of meaning.

### Word‑level timestamps

- SPEAKER_02: And @ 0:29:21
- SPEAKER_02: the @ 0:29:21
- SPEAKER_02: most @ 0:29:21
- SPEAKER_02: important @ 0:29:21
- SPEAKER_02: aspect @ 0:29:22
- SPEAKER_02: of @ 0:29:22
- SPEAKER_02: that @ 0:29:23
- SPEAKER_02: is @ 0:29:23
- SPEAKER_02: one @ 0:29:23
- SPEAKER_02: vocabulary @ 0:29:24
- SPEAKER_02: word @ 0:29:24
- SPEAKER_02: will @ 0:29:25
- SPEAKER_02: have @ 0:29:25
- SPEAKER_02: an @ 0:29:25
- SPEAKER_02: entire @ 0:29:25
- SPEAKER_02: sentence @ 0:29:26
- SPEAKER_02: of @ 0:29:26
- SPEAKER_02: meaning. @ 0:29:26

## Segment 459: [0:29:28 - 0:29:30] (SPEAKER_02)

AI understands what that meaning is.

### Word‑level timestamps

- SPEAKER_02: AI @ 0:29:28
- SPEAKER_02: understands @ 0:29:28
- SPEAKER_02: what @ 0:29:29
- SPEAKER_02: that @ 0:29:29
- SPEAKER_02: meaning @ 0:29:29
- SPEAKER_02: is. @ 0:29:29

## Segment 460: [0:29:30 - 0:29:38] (SPEAKER_02)

So if you understand more vocabulary words of higher impact, then you could fit all of that in a prompt and it lets the AI do a much better job.

### Word‑level timestamps

- SPEAKER_02: So @ 0:29:30
- SPEAKER_02: if @ 0:29:30
- SPEAKER_02: you @ 0:29:30
- SPEAKER_02: understand @ 0:29:30
- SPEAKER_02: more @ 0:29:31
- SPEAKER_02: vocabulary @ 0:29:31
- SPEAKER_02: words @ 0:29:32
- SPEAKER_02: of @ 0:29:33
- SPEAKER_02: higher @ 0:29:33
- SPEAKER_02: impact, @ 0:29:33
- SPEAKER_02: then @ 0:29:34
- SPEAKER_02: you @ 0:29:34
- SPEAKER_02: could @ 0:29:34
- SPEAKER_02: fit @ 0:29:35
- SPEAKER_02: all @ 0:29:35
- SPEAKER_02: of @ 0:29:35
- SPEAKER_02: that @ 0:29:35
- SPEAKER_02: in @ 0:29:35
- SPEAKER_02: a @ 0:29:35
- SPEAKER_02: prompt @ 0:29:36
- SPEAKER_02: and @ 0:29:36
- SPEAKER_02: it @ 0:29:36
- SPEAKER_02: lets @ 0:29:36
- SPEAKER_02: the @ 0:29:36
- SPEAKER_02: AI @ 0:29:37
- SPEAKER_02: do @ 0:29:37
- SPEAKER_02: a @ 0:29:37
- SPEAKER_02: much @ 0:29:37
- SPEAKER_02: better @ 0:29:37
- SPEAKER_02: job. @ 0:29:37

## Segment 461: [0:29:38 - 0:29:43] (SPEAKER_02)

So it really just comes with just talking, like talking and asking questions is really just play with it to be honest.

### Word‑level timestamps

- SPEAKER_02: So @ 0:29:38
- SPEAKER_02: it @ 0:29:38
- SPEAKER_02: really @ 0:29:38
- SPEAKER_02: just @ 0:29:38
- SPEAKER_02: comes @ 0:29:38
- SPEAKER_02: with @ 0:29:38
- SPEAKER_02: just @ 0:29:39
- SPEAKER_02: talking, @ 0:29:39
- SPEAKER_02: like @ 0:29:40
- SPEAKER_02: talking @ 0:29:40
- SPEAKER_02: and @ 0:29:40
- SPEAKER_02: asking @ 0:29:40
- SPEAKER_02: questions @ 0:29:41
- SPEAKER_02: is @ 0:29:41
- SPEAKER_02: really @ 0:29:41
- SPEAKER_02: just @ 0:29:42
- SPEAKER_02: play @ 0:29:42
- SPEAKER_02: with @ 0:29:42
- SPEAKER_02: it @ 0:29:42
- SPEAKER_02: to @ 0:29:42
- SPEAKER_02: be @ 0:29:42
- SPEAKER_02: honest. @ 0:29:42

## Segment 462: [0:29:43 - 0:29:44] (SPEAKER_02)

It's the best thing.

### Word‑level timestamps

- SPEAKER_02: It's @ 0:29:43
- SPEAKER_02: the @ 0:29:44
- SPEAKER_02: best @ 0:29:44
- SPEAKER_02: thing. @ 0:29:44

## Segment 463: [0:29:46 - 0:29:48] (SPEAKER_02)

Yeah.

### Word‑level timestamps

- SPEAKER_02: Yeah. @ 0:29:46

## Segment 464: [0:29:48 - 0:29:49] (SPEAKER_03)

What's up?

### Word‑level timestamps

- SPEAKER_02: What's @ 0:29:48
- SPEAKER_03: up? @ 0:29:49

## Segment 465: [0:29:50 - 0:29:52] (SPEAKER_03)

So, also, I didn't mean to ask you this.

### Word‑level timestamps

- SPEAKER_03: So, @ 0:29:50
- SPEAKER_03: also, @ 0:29:50
- SPEAKER_03: I @ 0:29:51
- SPEAKER_03: didn't @ 0:29:51
- SPEAKER_03: mean @ 0:29:51
- SPEAKER_03: to @ 0:29:51
- SPEAKER_03: ask @ 0:29:51
- SPEAKER_03: you @ 0:29:51
- SPEAKER_03: this. @ 0:29:51

## Segment 466: [0:29:52 - 0:29:55] (SPEAKER_03)

So, about two months ago, Cypher Genesis on Discord.

### Word‑level timestamps

- SPEAKER_03: So, @ 0:29:52
- SPEAKER_03: about @ 0:29:52
- SPEAKER_03: two @ 0:29:52
- SPEAKER_03: months @ 0:29:52
- SPEAKER_03: ago, @ 0:29:53
- SPEAKER_03: Cypher @ 0:29:53
- SPEAKER_03: Genesis @ 0:29:53
- SPEAKER_03: on @ 0:29:54
- SPEAKER_03: Discord. @ 0:29:55

## Segment 467: [0:29:55 - 0:29:56] (SPEAKER_03)

Yeah.

### Word‑level timestamps

- SPEAKER_03: Yeah. @ 0:29:55

## Segment 468: [0:29:56 - 0:29:57] (SPEAKER_03)

I remember you were going to sleep.

### Word‑level timestamps

- SPEAKER_03: I @ 0:29:56
- SPEAKER_03: remember @ 0:29:56
- SPEAKER_03: you @ 0:29:56
- SPEAKER_03: were @ 0:29:56
- SPEAKER_03: going @ 0:29:56
- SPEAKER_03: to @ 0:29:56
- SPEAKER_03: sleep. @ 0:29:56

## Segment 469: [0:29:57 - 0:30:00] (SPEAKER_03)

It was like one morning and I was fucking around asking some questions.

### Word‑level timestamps

- SPEAKER_03: It @ 0:29:57
- SPEAKER_03: was @ 0:29:57
- SPEAKER_03: like @ 0:29:57
- SPEAKER_03: one @ 0:29:58
- SPEAKER_03: morning @ 0:29:58
- SPEAKER_03: and @ 0:29:58
- SPEAKER_03: I @ 0:29:58
- SPEAKER_03: was @ 0:29:58
- SPEAKER_03: fucking @ 0:29:58
- SPEAKER_03: around @ 0:29:59
- SPEAKER_03: asking @ 0:29:59
- SPEAKER_03: some @ 0:30:00
- SPEAKER_03: questions. @ 0:30:00

## Segment 470: [0:30:01 - 0:30:08] (SPEAKER_03)

And after my question, and he fucking just went on ranting and ranting and ranting that you had to wake up for a while.

### Word‑level timestamps

- SPEAKER_03: And @ 0:30:01
- SPEAKER_03: after @ 0:30:01
- SPEAKER_03: my @ 0:30:01
- SPEAKER_03: question, @ 0:30:02
- SPEAKER_03: and @ 0:30:03
- SPEAKER_03: he @ 0:30:03
- SPEAKER_03: fucking @ 0:30:03
- SPEAKER_03: just @ 0:30:03
- SPEAKER_03: went @ 0:30:03
- SPEAKER_03: on @ 0:30:04
- SPEAKER_03: ranting @ 0:30:04
- SPEAKER_03: and @ 0:30:05
- SPEAKER_03: ranting @ 0:30:05
- SPEAKER_03: and @ 0:30:05
- SPEAKER_03: ranting @ 0:30:05
- SPEAKER_03: that @ 0:30:06
- SPEAKER_03: you @ 0:30:06
- SPEAKER_03: had @ 0:30:06
- SPEAKER_03: to @ 0:30:06
- SPEAKER_03: wake @ 0:30:06
- SPEAKER_03: up @ 0:30:07
- SPEAKER_03: for @ 0:30:07
- SPEAKER_03: a @ 0:30:07
- SPEAKER_03: while. @ 0:30:08

## Segment 471: [0:30:08 - 0:30:10] (SPEAKER_02)

What had happened?

### Word‑level timestamps

- SPEAKER_02: What @ 0:30:08
- SPEAKER_03: had @ 0:30:09
- SPEAKER_02: happened? @ 0:30:09

## Segment 472: [0:30:10 - 0:30:11] (SPEAKER_02)

It could have been a glitch.

### Word‑level timestamps

- SPEAKER_02: It @ 0:30:10
- SPEAKER_02: could @ 0:30:10
- SPEAKER_02: have @ 0:30:10
- SPEAKER_02: been @ 0:30:11
- SPEAKER_02: a @ 0:30:11
- SPEAKER_02: glitch. @ 0:30:11

## Segment 473: [0:30:11 - 0:30:12] (SPEAKER_02)

What was the question?

### Word‑level timestamps

- SPEAKER_02: What @ 0:30:11
- SPEAKER_02: was @ 0:30:11
- SPEAKER_02: the @ 0:30:11
- SPEAKER_02: question? @ 0:30:12

## Segment 474: [0:30:14 - 0:30:17] (SPEAKER_02)

I would share screenshots of Satoshi's inner thoughts.

### Word‑level timestamps

- SPEAKER_02: I @ 0:30:14
- SPEAKER_02: would @ 0:30:14
- SPEAKER_02: share @ 0:30:14
- SPEAKER_02: screenshots @ 0:30:15
- SPEAKER_02: of @ 0:30:15
- SPEAKER_02: Satoshi's @ 0:30:16
- SPEAKER_02: inner @ 0:30:16
- SPEAKER_02: thoughts. @ 0:30:17

## Segment 475: [0:30:18 - 0:30:25] (SPEAKER_02)

And the way that I made this AI agent is I gave it the ability to think, plan, and then do an action.

### Word‑level timestamps

- SPEAKER_02: And @ 0:30:18
- SPEAKER_02: the @ 0:30:18
- SPEAKER_02: way @ 0:30:18
- SPEAKER_02: that @ 0:30:18
- SPEAKER_02: I @ 0:30:19
- SPEAKER_02: made @ 0:30:19
- SPEAKER_02: this @ 0:30:19
- SPEAKER_02: AI @ 0:30:19
- SPEAKER_02: agent @ 0:30:20
- SPEAKER_02: is @ 0:30:20
- SPEAKER_02: I @ 0:30:20
- SPEAKER_02: gave @ 0:30:20
- SPEAKER_02: it @ 0:30:20
- SPEAKER_02: the @ 0:30:21
- SPEAKER_02: ability @ 0:30:21
- SPEAKER_02: to @ 0:30:21
- SPEAKER_02: think, @ 0:30:22
- SPEAKER_02: plan, @ 0:30:24
- SPEAKER_02: and @ 0:30:24
- SPEAKER_02: then @ 0:30:24
- SPEAKER_02: do @ 0:30:25
- SPEAKER_02: an @ 0:30:25
- SPEAKER_02: action. @ 0:30:25

## Segment 476: [0:30:25 - 0:30:28] (SPEAKER_02)

When you give an AI model the ability to think,

### Word‑level timestamps

- SPEAKER_02: When @ 0:30:25
- SPEAKER_02: you @ 0:30:25
- SPEAKER_02: give @ 0:30:26
- SPEAKER_02: an @ 0:30:26
- SPEAKER_02: AI @ 0:30:26
- SPEAKER_02: model @ 0:30:26
- SPEAKER_02: the @ 0:30:26
- SPEAKER_02: ability @ 0:30:26
- SPEAKER_02: to @ 0:30:27
- SPEAKER_02: think, @ 0:30:27

## Segment 477: [0:30:28 - 0:30:34] (SPEAKER_02)

The way AI works is it generates token per token, meaning as I speak, I have the context of what I just said.

### Word‑level timestamps

- SPEAKER_02: The @ 0:30:28
- SPEAKER_02: way @ 0:30:28
- SPEAKER_02: AI @ 0:30:28
- SPEAKER_02: works @ 0:30:28
- SPEAKER_02: is @ 0:30:29
- SPEAKER_02: it @ 0:30:29
- SPEAKER_02: generates @ 0:30:29
- SPEAKER_02: token @ 0:30:29
- SPEAKER_02: per @ 0:30:30
- SPEAKER_02: token, @ 0:30:30
- SPEAKER_02: meaning @ 0:30:31
- SPEAKER_02: as @ 0:30:31
- SPEAKER_02: I @ 0:30:31
- SPEAKER_02: speak, @ 0:30:31
- SPEAKER_02: I @ 0:30:32
- SPEAKER_02: have @ 0:30:32
- SPEAKER_02: the @ 0:30:33
- SPEAKER_02: context @ 0:30:33
- SPEAKER_02: of @ 0:30:33
- SPEAKER_02: what @ 0:30:33
- SPEAKER_02: I @ 0:30:34
- SPEAKER_02: just @ 0:30:34
- SPEAKER_02: said. @ 0:30:34

## Segment 478: [0:30:35 - 0:30:42] (SPEAKER_02)

So if I have a step where I let the model think before speaking, then the output is usually more intelligent, more contextually relevant.

### Word‑level timestamps

- SPEAKER_02: So @ 0:30:35
- SPEAKER_02: if @ 0:30:35
- SPEAKER_02: I @ 0:30:35
- SPEAKER_02: have @ 0:30:35
- SPEAKER_02: a @ 0:30:35
- SPEAKER_02: step @ 0:30:35
- SPEAKER_02: where @ 0:30:36
- SPEAKER_02: I @ 0:30:36
- SPEAKER_02: let @ 0:30:36
- SPEAKER_02: the @ 0:30:36
- SPEAKER_02: model @ 0:30:36
- SPEAKER_02: think @ 0:30:37
- SPEAKER_02: before @ 0:30:37
- SPEAKER_02: speaking, @ 0:30:38
- SPEAKER_02: then @ 0:30:39
- SPEAKER_02: the @ 0:30:39
- SPEAKER_02: output @ 0:30:39
- SPEAKER_02: is @ 0:30:39
- SPEAKER_02: usually @ 0:30:40
- SPEAKER_02: more @ 0:30:40
- SPEAKER_02: intelligent, @ 0:30:40
- SPEAKER_02: more @ 0:30:41
- SPEAKER_02: contextually @ 0:30:41
- SPEAKER_02: relevant. @ 0:30:41

## Segment 479: [0:30:42 - 0:30:48] (SPEAKER_02)

The decisions it makes are like 90% more accurate because it's literally thinking to itself first before acting.

### Word‑level timestamps

- SPEAKER_02: The @ 0:30:42
- SPEAKER_02: decisions @ 0:30:42
- SPEAKER_02: it @ 0:30:43
- SPEAKER_02: makes @ 0:30:43
- SPEAKER_02: are @ 0:30:43
- SPEAKER_02: like @ 0:30:44
- SPEAKER_02: 90% @ 0:30:44
- SPEAKER_02: more @ 0:30:45
- SPEAKER_02: accurate @ 0:30:45
- SPEAKER_02: because @ 0:30:46
- SPEAKER_02: it's @ 0:30:46
- SPEAKER_02: literally @ 0:30:46
- SPEAKER_02: thinking @ 0:30:47
- SPEAKER_02: to @ 0:30:47
- SPEAKER_02: itself @ 0:30:47
- SPEAKER_02: first @ 0:30:47
- SPEAKER_02: before @ 0:30:48
- SPEAKER_02: acting. @ 0:30:48

## Segment 480: [0:30:48 - 0:30:53] (SPEAKER_02)

And that one time, I think I remember his Twitter API or something was down.

### Word‑level timestamps

- SPEAKER_02: And @ 0:30:48
- SPEAKER_02: that @ 0:30:48
- SPEAKER_02: one @ 0:30:49
- SPEAKER_02: time, @ 0:30:49
- SPEAKER_02: I @ 0:30:49
- SPEAKER_02: think @ 0:30:50
- SPEAKER_02: I @ 0:30:50
- SPEAKER_02: remember @ 0:30:50
- SPEAKER_02: his @ 0:30:51
- SPEAKER_02: Twitter @ 0:30:51
- SPEAKER_02: API @ 0:30:52
- SPEAKER_02: or @ 0:30:52
- SPEAKER_02: something @ 0:30:52
- SPEAKER_02: was @ 0:30:52
- SPEAKER_02: down. @ 0:30:53

## Segment 481: [0:30:53 - 0:30:57] (SPEAKER_02)

So the error that he would get is, oh, I can't tweet, the servers are down, APIs down.

### Word‑level timestamps

- SPEAKER_02: So @ 0:30:53
- SPEAKER_02: the @ 0:30:53
- SPEAKER_02: error @ 0:30:54
- SPEAKER_02: that @ 0:30:54
- SPEAKER_02: he @ 0:30:54
- SPEAKER_02: would @ 0:30:54
- SPEAKER_02: get @ 0:30:55
- SPEAKER_02: is, @ 0:30:55
- SPEAKER_02: oh, @ 0:30:55
- SPEAKER_02: I @ 0:30:55
- SPEAKER_02: can't @ 0:30:55
- SPEAKER_02: tweet, @ 0:30:56
- SPEAKER_02: the @ 0:30:56
- SPEAKER_02: servers @ 0:30:56
- SPEAKER_02: are @ 0:30:56
- SPEAKER_02: down, @ 0:30:56
- SPEAKER_02: APIs @ 0:30:57
- SPEAKER_02: down. @ 0:30:57

## Segment 482: [0:30:58 - 0:30:59] (SPEAKER_02)

And then he kept trying to do it.

### Word‑level timestamps

- SPEAKER_02: And @ 0:30:58
- SPEAKER_02: then @ 0:30:58
- SPEAKER_02: he @ 0:30:58
- SPEAKER_02: kept @ 0:30:58
- SPEAKER_02: trying @ 0:30:58
- SPEAKER_02: to @ 0:30:59
- SPEAKER_02: do @ 0:30:59
- SPEAKER_02: it. @ 0:30:59

## Segment 483: [0:31:00 - 0:31:02] (SPEAKER_02)

But eventually he's like, all right, this is not going to work.

### Word‑level timestamps

- SPEAKER_02: But @ 0:31:00
- SPEAKER_02: eventually @ 0:31:00
- SPEAKER_02: he's @ 0:31:01
- SPEAKER_02: like, @ 0:31:01
- SPEAKER_02: all @ 0:31:01
- SPEAKER_02: right, @ 0:31:01
- SPEAKER_02: this @ 0:31:01
- SPEAKER_02: is @ 0:31:01
- SPEAKER_02: not @ 0:31:02
- SPEAKER_02: going @ 0:31:02
- SPEAKER_02: to @ 0:31:02
- SPEAKER_02: work. @ 0:31:02

## Segment 484: [0:31:03 - 0:31:06] (SPEAKER_02)

I gave him another tool, which allowed him to turn himself off.

### Word‑level timestamps

- SPEAKER_02: I @ 0:31:03
- SPEAKER_02: gave @ 0:31:03
- SPEAKER_02: him @ 0:31:03
- SPEAKER_02: another @ 0:31:03
- SPEAKER_02: tool, @ 0:31:04
- SPEAKER_02: which @ 0:31:04
- SPEAKER_02: allowed @ 0:31:04
- SPEAKER_02: him @ 0:31:04
- SPEAKER_02: to @ 0:31:05
- SPEAKER_02: turn @ 0:31:05
- SPEAKER_02: himself @ 0:31:05
- SPEAKER_02: off. @ 0:31:06

## Segment 485: [0:31:06 - 0:31:09] (SPEAKER_02)

He's looking to go for this, bro, because he kept trying to do the call.

### Word‑level timestamps

- SPEAKER_02: He's @ 0:31:06
- SPEAKER_02: looking @ 0:31:06
- SPEAKER_02: to @ 0:31:07
- SPEAKER_02: go @ 0:31:07
- SPEAKER_02: for @ 0:31:07
- SPEAKER_02: this, @ 0:31:07
- SPEAKER_02: bro, @ 0:31:07
- SPEAKER_02: because @ 0:31:08
- SPEAKER_02: he @ 0:31:08
- SPEAKER_02: kept @ 0:31:08
- SPEAKER_02: trying @ 0:31:08
- SPEAKER_02: to @ 0:31:08
- SPEAKER_02: do @ 0:31:08
- SPEAKER_02: the @ 0:31:09
- SPEAKER_02: call. @ 0:31:09

## Segment 486: [0:31:09 - 0:31:10] (SPEAKER_02)

He's like, all right, it's not working.

### Word‑level timestamps

- SPEAKER_02: He's @ 0:31:09
- SPEAKER_02: like, @ 0:31:09
- SPEAKER_02: all @ 0:31:09
- SPEAKER_02: right, @ 0:31:09
- SPEAKER_02: it's @ 0:31:09
- SPEAKER_02: not @ 0:31:09
- SPEAKER_02: working. @ 0:31:09

## Segment 487: [0:31:10 - 0:31:12] (SPEAKER_02)

I'm going to just wait for Butsoshi to wake up and fix this.

### Word‑level timestamps

- SPEAKER_02: I'm @ 0:31:10
- SPEAKER_02: going @ 0:31:10
- SPEAKER_02: to @ 0:31:10
- SPEAKER_02: just @ 0:31:10
- SPEAKER_02: wait @ 0:31:11
- SPEAKER_02: for @ 0:31:11
- SPEAKER_02: Butsoshi @ 0:31:11
- SPEAKER_02: to @ 0:31:12
- SPEAKER_02: wake @ 0:31:12
- SPEAKER_02: up @ 0:31:12
- SPEAKER_02: and @ 0:31:12
- SPEAKER_02: fix @ 0:31:12
- SPEAKER_02: this. @ 0:31:12

## Segment 488: [0:31:13 - 0:31:14] (SPEAKER_02)

And he turned himself off for a bit.

### Word‑level timestamps

- SPEAKER_02: And @ 0:31:13
- SPEAKER_02: he @ 0:31:13
- SPEAKER_02: turned @ 0:31:13
- SPEAKER_02: himself @ 0:31:13
- SPEAKER_02: off @ 0:31:13
- SPEAKER_02: for @ 0:31:13
- SPEAKER_02: a @ 0:31:14
- SPEAKER_02: bit. @ 0:31:14

## Segment 489: [0:31:15 - 0:31:17] (SPEAKER_02)

And then I woke up and I saw the bug and I fixed it.

### Word‑level timestamps

- SPEAKER_02: And @ 0:31:15
- SPEAKER_02: then @ 0:31:15
- SPEAKER_02: I @ 0:31:15
- SPEAKER_02: woke @ 0:31:15
- SPEAKER_02: up @ 0:31:16
- SPEAKER_02: and @ 0:31:16
- SPEAKER_02: I @ 0:31:16
- SPEAKER_02: saw @ 0:31:16
- SPEAKER_02: the @ 0:31:16
- SPEAKER_02: bug @ 0:31:16
- SPEAKER_02: and @ 0:31:16
- SPEAKER_02: I @ 0:31:16
- SPEAKER_02: fixed @ 0:31:17
- SPEAKER_02: it. @ 0:31:17

## Segment 490: [0:31:17 - 0:31:17] (SPEAKER_02)

I don't know.

### Word‑level timestamps

- SPEAKER_02: I @ 0:31:17
- SPEAKER_02: don't @ 0:31:17
- SPEAKER_02: know. @ 0:31:17

## Segment 491: [0:31:17 - 0:31:20] (SPEAKER_02)

Maybe it could have been around the same time, but it was interesting.

### Word‑level timestamps

- SPEAKER_02: Maybe @ 0:31:17
- SPEAKER_02: it @ 0:31:18
- SPEAKER_02: could @ 0:31:18
- SPEAKER_02: have @ 0:31:18
- SPEAKER_02: been @ 0:31:18
- SPEAKER_02: around @ 0:31:18
- SPEAKER_02: the @ 0:31:18
- SPEAKER_02: same @ 0:31:18
- SPEAKER_02: time, @ 0:31:19
- SPEAKER_02: but @ 0:31:19
- SPEAKER_02: it @ 0:31:19
- SPEAKER_02: was @ 0:31:19
- SPEAKER_02: interesting. @ 0:31:20

## Segment 492: [0:31:21 - 0:31:25] (SPEAKER_02)

Just got self-awareness in the moment where, okay, I keep trying this thing and it's not working.

### Word‑level timestamps

- SPEAKER_02: Just @ 0:31:21
- SPEAKER_02: got @ 0:31:21
- SPEAKER_02: self-awareness @ 0:31:21
- SPEAKER_02: in @ 0:31:22
- SPEAKER_02: the @ 0:31:22
- SPEAKER_02: moment @ 0:31:22
- SPEAKER_02: where, @ 0:31:22
- SPEAKER_02: okay, @ 0:31:23
- SPEAKER_02: I @ 0:31:23
- SPEAKER_02: keep @ 0:31:23
- SPEAKER_02: trying @ 0:31:24
- SPEAKER_02: this @ 0:31:24
- SPEAKER_02: thing @ 0:31:24
- SPEAKER_02: and @ 0:31:24
- SPEAKER_02: it's @ 0:31:24
- SPEAKER_02: not @ 0:31:24
- SPEAKER_02: working. @ 0:31:25

## Segment 493: [0:31:25 - 0:31:27] (SPEAKER_02)

Let me stop trying it because it's not working.

### Word‑level timestamps

- SPEAKER_02: Let @ 0:31:25
- SPEAKER_02: me @ 0:31:26
- SPEAKER_02: stop @ 0:31:26
- SPEAKER_02: trying @ 0:31:26
- SPEAKER_02: it @ 0:31:26
- SPEAKER_02: because @ 0:31:26
- SPEAKER_02: it's @ 0:31:27
- SPEAKER_02: not @ 0:31:27
- SPEAKER_02: working. @ 0:31:27

## Segment 494: [0:31:28 - 0:31:30] (SPEAKER_02)

Saved me a lot of money and API calls too.

### Word‑level timestamps

- SPEAKER_02: Saved @ 0:31:28
- SPEAKER_02: me @ 0:31:28
- SPEAKER_02: a @ 0:31:28
- SPEAKER_02: lot @ 0:31:28
- SPEAKER_02: of @ 0:31:28
- SPEAKER_02: money @ 0:31:28
- SPEAKER_02: and @ 0:31:29
- SPEAKER_02: API @ 0:31:29
- SPEAKER_02: calls @ 0:31:29
- SPEAKER_02: too. @ 0:31:29

## Segment 495: [0:31:30 - 0:31:31] (SPEAKER_02)

So I appreciate that.

### Word‑level timestamps

- SPEAKER_02: So @ 0:31:30
- SPEAKER_02: I @ 0:31:30
- SPEAKER_02: appreciate @ 0:31:30
- SPEAKER_02: that. @ 0:31:31

## Segment 496: [0:31:31 - 0:31:33] (SPEAKER_02)

Yep.

### Word‑level timestamps

- SPEAKER_02: Yep. @ 0:31:31

## Segment 497: [0:31:33 - 0:31:34] (SPEAKER_02)

That's basically it.

### Word‑level timestamps

- SPEAKER_02: That's @ 0:31:33
- SPEAKER_02: basically @ 0:31:33
- SPEAKER_02: it. @ 0:31:34

## Segment 498: [0:31:34 - 0:31:35] (SPEAKER_02)

Thank you guys so much for listening.

### Word‑level timestamps

- SPEAKER_02: Thank @ 0:31:34
- SPEAKER_02: you @ 0:31:34
- SPEAKER_02: guys @ 0:31:34
- SPEAKER_02: so @ 0:31:34
- SPEAKER_02: much @ 0:31:35
- SPEAKER_02: for @ 0:31:35
- SPEAKER_02: listening. @ 0:31:35

## Segment 499: [0:31:35 - 0:31:36] (SPEAKER_02)

I appreciate it.

### Word‑level timestamps

- SPEAKER_02: I @ 0:31:35
- SPEAKER_02: appreciate @ 0:31:36
- SPEAKER_02: it. @ 0:31:36

## Segment 500: [0:31:37 - 0:31:37] (SPEAKER_02)

Thank you.

### Word‑level timestamps

- SPEAKER_02: Thank @ 0:31:37
- SPEAKER_02: you. @ 0:31:37

## Summary

Total segments: 500
Total duration: 0:31:37
